{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJHjlbSGtcYF"
      },
      "source": [
        "## HW1\n",
        "### 주어진 ./data/minidata안의 파일 안에서 64x64 사이즈의 고양이 한마리와 128X128 사이즈의 강아지 한마리, 그리고 각각의 파일 명을 내 뱉는 Dataloader를 만드시오\n",
        "### Data augmentation은 train일 경우 Horizon Flip, 랜덤90도 rotation, 랜덤 Crop을, train이 아닌 경우 하지 않도록 작성하시오"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NErcZMplgDpN",
        "outputId": "7186cd1b-4509-42cf-a309-b21f61ee0996"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "bjDYPJ4TtcYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf315a9e-93f0-416d-bef8-c1dd9c7f793c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset의 개수 20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.HwDataset at 0x7fcef2388710>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "class HwDataset(Dataset):\n",
        "    def __init__(self, train_dir = '/content/drive/MyDrive/CNN_MNC_211224-20211224T050700Z-001/CNN_MNC_211224/data/minidata/train', train = False):\n",
        "        self.train = train\n",
        "        self.train_dir = train_dir\n",
        "        self.train_data = glob(os.path.join(self.train_dir, '*', '*'))\n",
        "        self.transform_cat = transforms.Compose([transforms.Resize((64, 64)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             ])\n",
        "        self.transform_dog = transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             ])\n",
        "        self.transform = transforms.Compose([\n",
        "                         transforms.RandomResizedCrop((224, 224)),\n",
        "                         transforms.RandomRotation((-90, 90)),\n",
        "                         transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ToTensor(),                                \n",
        "                              ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.train_data)\n",
        "    \n",
        "    #  슬라이싱을 구현할 수 있도록 돕는 메소드\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.train_data[index]).convert('RGB')\n",
        "        # train 이면 transform()\n",
        "        if self.train :\n",
        "            image = self.transform()\n",
        "        else :\n",
        "            return None\n",
        "\n",
        "        print(self.train_data[index])\n",
        "\n",
        "        image_name = self.train_data[index].split('/')[-1] # Linux\n",
        "\n",
        "\n",
        "\n",
        "        if self.train_data[index].split('/')[-2] == 'cat':\n",
        "            transforms.Compose([transforms.Resize((64, 64)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             ])\n",
        "\n",
        "\n",
        "        elif self.train_data[index].split('/')[-2] =='dog': # Linux\n",
        "            transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             ])\n",
        "            image = self.transform_dog\n",
        "\n",
        "        return image, image_name\n",
        "\n",
        "mydataset = HwDataset()\n",
        "print('Dataset의 개수',len(mydataset))\n",
        "mydataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8O4B-Svgwo0n"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Boe9Di23tcYK"
      },
      "outputs": [],
      "source": [
        "train_dataset = HwDataset('/content/drive/MyDrive/CNN_MNC_211224-20211224T050700Z-001/CNN_MNC_211224/data/minidata/train',train=True)\n",
        "val_dataset = HwDataset('/content/drive/MyDrive/CNN_MNC_211224-20211224T050700Z-001/CNN_MNC_211224/data/minidata/val',train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN4-X3sAtcYK"
      },
      "source": [
        "## HW2\n",
        "### 2_NeuralNetwork.ipynb의 Let's Do It 코드를 작성해서 결과를 확인하시오\n",
        "(10000개 이하의 파라미터로 99%의 성능 달성)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "h_sgS56KtcYL"
      },
      "outputs": [],
      "source": [
        "# 필요한 train test코드를 다 작성하세요\n",
        "import torch \n",
        "import torch.nn as nn #\n",
        "import torch.nn.functional as F # 각종 activation 함수\n",
        "import torchvision # 이미지 관련 처리, Pretrained Model 관련된 Package 입니다. \n",
        "import torchvision.datasets as vision_dsets\n",
        "import torchvision.transforms as T # 이미지 처리 (Vison) 관련된 transformation이 정의 되어 있습니다.\n",
        "import torch.optim as optim # pytorch 에서 정의한 수 많은 optimization function 들이 들어 있습니다.\n",
        "from torch.utils import data\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MNIST_DATA(root='/content/drive/MyDrive/CNN_MNC_211224-20211224T050700Z-001/CNN_MNC_211224/data',train =True,transforms=None ,download =True,batch_size = 32,num_worker = 1):\n",
        "    print (\"[+] Get the MNIST DATA\")\n",
        "    \"\"\"\n",
        "    torchvision.dataset 에는 우리가 많이 사용하는 데이터들을 쉽게 사용할 수 있도록 되어 있습니다. \n",
        "    Mchine Learning 에서 Hello world 라고 불리는 Mnist 데이터를 사용해 보겠습니다. \n",
        "    \"\"\"\n",
        "    mnist_train = vision_dsets.MNIST(root = root,  #root 는 데이터의 저장 위치 입니다. \n",
        "                                    train = True, #Train 은 이 데이터가 train 데이터인지 아닌지에 대한 정보입니다. \n",
        "                                    transform = T.ToTensor(), # 얻어낸 데이터를 pytorch가 계산 할 수 있는 Tensor 로 변환해 줍니다. \n",
        "                                    download = True)  # 데이터를 다운로드 할지 여부를 물어봅니다. \n",
        "    mnist_test = vision_dsets.MNIST(root = root,\n",
        "                                    train = False,  # Test Data를 가져오기에 Train =False 를 줘야 합니다. \n",
        "                                    transform = T.ToTensor(),\n",
        "                                    download = True)\n",
        "    \"\"\"\n",
        "    Data Loader 는 데이터와 batch size의 정보를 바탕으로 매 iteration 마다 주어진 데이터를 원하는 batch size 만큼 반환해주는 iterator입니다. \n",
        "    * Practical Guide : Batch size 는 어느정도가 좋나요? -- 클 수록 좋다는 소리가 있습니다. 하지만 gpu memeory 사이즈 한계에 의해 기본적으로 batch size 가 \n",
        "      커질 수록 학습에 사용되는 gpu memory 사이즈가 큽니다. (Activation map을 저장해야 하기 때문입니다.) 기본적으로 2의 배수로 저장하는 것이 좋습니다.(Bit size 관련) \n",
        "    \"\"\"\n",
        "    trainDataLoader = data.DataLoader(dataset = mnist_train,  # DataSet은 어떤 Data를 제공해 줄지에 대한 정보입니다. 여기서는 Training DATA를 제공합니다. \n",
        "                                      batch_size = batch_size, # batch size 정보를 꼭 줘야 합니다. 한 Batch 당 몇 개의 Data 를 제공할지에 대한 정보입니다. \n",
        "                                      shuffle =True, # Training의 경우 Shuffling 을 해주는 것이 성능에 지대한 영향을 끼칩니다. 꼭 True 를 줘야 합니다. \n",
        "                                      num_workers = 1) # num worker의 경우 데이터를 로드하는데 worker를 얼마나 추가하겠는가에 대한 정보입니다. \n",
        "\n",
        "    testDataLoader = data.DataLoader(dataset = mnist_test, # Test Data Loader 이므로 Test Data를 인자로 전달해줍니다.\n",
        "                                    batch_size = batch_size, # 마찬가지로 Batch size 를 넣어줍니다. \n",
        "                                    shuffle = False, # shuffling 이 굳이 필요하지 않으므로 false를 줍니다. \n",
        "                                    num_workers = 1) #\n",
        "    print (\"[+] Finished loading data & Preprocessing\")\n",
        "    return mnist_train,mnist_test,trainDataLoader,testDataLoader"
      ],
      "metadata": {
        "id": "TIFRJJwuygW2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDset,testDset,trainDataLoader,testDataLoader= MNIST_DATA(batch_size = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0_sRgYD0uDy",
        "outputId": "1ca2bafe-3e97-4268-8fd2-58b59da01343"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Get the MNIST DATA\n",
            "[+] Finished loading data & Preprocessing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self, trainloader, testloader, net, optimizer, criterion):\n",
        "        \"\"\"\n",
        "        trainloader: train data의 loader 입니다\n",
        "        testloader: test data의 loader 입니다\n",
        "        net: 학습시킬 모델입니다\n",
        "        optimizer: 모델의 파라미터를 업데이트할 최적화 함수입니다\n",
        "        criterion: 모델의 loss function 입니다.\n",
        "        \"\"\"\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.net = net\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        \n",
        "    def train(self, epoch = 1):\n",
        "        \"\"\"\n",
        "        epoch: 전체 학습 데이터의 사용횟수입니다.\n",
        "        \"\"\"\n",
        "        self.net.train()\n",
        "        for e in range(epoch):\n",
        "            running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
        "            for i, data in enumerate(self.trainloader, 0): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
        "                # get the inputs\n",
        "                inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "                # zero the parameter gradients\n",
        "                self.optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다. \n",
        "                                              #  Q) 이걸 안 한다면?\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = self.net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
        "                loss = self.criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
        "                loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
        "                self.optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if (i+1) % 500 == 0:    # print every 2000 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' % (e + 1, i + 1, running_loss / 500))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished Training')\n",
        "        \n",
        "    def test(self):\n",
        "        self.net.eval() # Eval Mode 왜 해야 할까요?  \n",
        "                        # --> nn.Dropout BatchNorm 등의 Regularization 들이 test 모드로 들어가게 되기 때문입니다. \n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        for inputs, labels in self.testloader:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda() \n",
        "            output = self.net(inputs) \n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item() # 정답 데이터의 갯수를 반환합니다. \n",
        "\n",
        "            test_loss /= len(self.testloader.dataset)\n",
        "        print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.\n",
        "                format(correct, len(self.testloader.dataset),\n",
        "                100.* correct / len(self.testloader.dataset)))"
      ],
      "metadata": {
        "id": "ynr06j9k0u0A"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(in_channels = 1,\n",
        "                               out_channels = 8,\n",
        "                               kernel_size = 6,\n",
        "                               stride = 2) # Layer 1\n",
        "        self.conv0_bn = nn.InstanceNorm2d(8)  # Image에서는 2d batchnorm이 사용됩니다\n",
        "        self.pool0 = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(8*6*6, 10) # Layer 2 (왜 input이 8 * 11 * 11 일까요?)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv0(x)\n",
        "        x = self.conv0_bn(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool0(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lUX05OPz3--0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_net = MNIST_Net().cuda() # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=0.001) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "metadata": {
        "id": "sSrJwIFF4E21"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(trainloader = trainDataLoader,\n",
        "                  testloader = testDataLoader,\n",
        "                  net = mnist_net,\n",
        "                  criterion = criterion,\n",
        "                  optimizer = optimizer)"
      ],
      "metadata": {
        "id": "FRKa3_aX4HZK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(epoch = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NxEAwGD4JV8",
        "outputId": "ff34d794-da87-4379-8025-a36efc052a6f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   500] loss: 0.577\n",
            "[1,  1000] loss: 0.226\n",
            "[1,  1500] loss: 0.170\n",
            "[2,   500] loss: 0.131\n",
            "[2,  1000] loss: 0.127\n",
            "[2,  1500] loss: 0.110\n",
            "[3,   500] loss: 0.097\n",
            "[3,  1000] loss: 0.091\n",
            "[3,  1500] loss: 0.090\n",
            "[4,   500] loss: 0.080\n",
            "[4,  1000] loss: 0.082\n",
            "[4,  1500] loss: 0.076\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1vd8vYM4Et3",
        "outputId": "1af16210-752d-41d0-f006-84c253880508"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set:  Accuracy: 9778/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(mnist_net)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwWlCOAn0usQ",
        "outputId": "54150e3f-205a-4f75-e0bc-d9aa0abbca16"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3186"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UefJHyHDtcYL"
      },
      "source": [
        "## (Optional) HW3\n",
        "### 3_VGG.ipynb를 참조해 VGG16을 구현하세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7msKciJStcYL"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "45d64d8f19a3a5b7048eaedc346d295eb6474eab36a46e2bd6124f8b3a721145"
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit ('t': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "HW_1224.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}