{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_bias_seperate.ipynb","provenance":[{"file_id":"1J5RZY_o54NFTidm1EO6rlITJyLw8MsPm","timestamp":1645668899382}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOAaRRga28vbvaWnDNFpPTV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMS_xuKqPnVq","executionInfo":{"status":"ok","timestamp":1646028255252,"user_tz":-540,"elapsed":26148,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"d9db474d-0a79-430f-feb3-ce892bfb690e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"9vsko_OEPple","executionInfo":{"status":"ok","timestamp":1646028306085,"user_tz":-540,"elapsed":12,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["PATH =  '/content/drive/MyDrive/AIConnect/NLP_classificaiton/data'\n","\n","train = pd.read_csv(os.path.join(PATH, 'train.csv'), encoding='utf-8')\n","test = pd.read_csv(os.path.join(PATH, 'test.csv'), encoding='utf-8')\n"],"metadata":{"id":"oDMvBV0kQjTo","executionInfo":{"status":"ok","timestamp":1646031523805,"user_tz":-540,"elapsed":297,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"vIv-t3KLWrBe"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On945wBGWdEO","executionInfo":{"status":"ok","timestamp":1646028521069,"user_tz":-540,"elapsed":8483,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"e6f008ca-d9a3-4da4-e85e-4e5daaf47d09"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 7.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 52.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 51.6 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 36.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n","from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer"],"metadata":{"id":"U0Z3LuAnWlqA","executionInfo":{"status":"ok","timestamp":1646029395914,"user_tz":-540,"elapsed":908,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["!pip install wandb\n","!wandb login"],"metadata":{"id":"wiXk4fzH8cgy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","from transformers import TrainingArguments, Trainer\n","\n","wandb.init(project=\"4week_NLP\", entity=\"team-5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"QyXH0b5o8Zgy","executionInfo":{"status":"ok","timestamp":1646028538531,"user_tz":-540,"elapsed":8360,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"162159a4-9f6a-4768-855d-51dfba2b0164"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtjkim\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/team-5/4week_NLP/runs/171lh99u\" target=\"_blank\">azure-bee-1</a></strong> to <a href=\"https://wandb.ai/team-5/4week_NLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_run.Run at 0x7fd78a95f6d0>"],"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/team-5/4week_NLP/runs/171lh99u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# seed 고정, gpu 고정\n","def seed_everything(seed:int = 1004):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything(2022)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fwfpImdWwLZ","executionInfo":{"status":"ok","timestamp":1646028557192,"user_tz":-540,"elapsed":299,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"91786c07-e459-4d82-a22d-7202b72518af"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# Load Tokenizer, Model\n","Hugging Face Hub에 존재하는 Pretrained Tokenizer와 Model 및 Model Config 불러오기\n","\n","이 때, Classification은 num_labels가 2로 Default되어있기 때문에 Model Config의 Parameter를  6으로 변경"],"metadata":{"id":"4eED-rnBXNFt"}},{"cell_type":"code","source":["bias_model = 'beomi/beep-KcELECTRA-base-bias' # 보통 tokenizer도 같은거 씀. 이거만 바꾸면 모델, tokenizer 변경 가능.\n","hate_model = 'beomi/beep-KcELECTRA-base-hate'"],"metadata":{"id":"Zl-1CpwF_X5v","executionInfo":{"status":"ok","timestamp":1646028959393,"user_tz":-540,"elapsed":281,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = bias_model\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","config.num_labels = 3 # other, gender, \n","\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n","\n","print(model)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kp9qC9ZaXWh_","executionInfo":{"status":"ok","timestamp":1646029254150,"user_tz":-540,"elapsed":4070,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"1d46df42-7872-4819-a0b5-1d2d83b56064"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")\n","ElectraConfig {\n","  \"_name_or_path\": \"beomi/beep-KcELECTRA-base-bias\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"none\",\n","    \"1\": \"others\",\n","    \"2\": \"gender\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"gender\": 2,\n","    \"none\": 0,\n","    \"others\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50135\n","}\n","\n"]}]},{"cell_type":"markdown","source":["# Tokenizing"],"metadata":{"id":"b9ScKe5TXsnM"}},{"cell_type":"code","source":["train.rename(columns = {'bias':'label'},inplace=True) # column 명이 label  이 아니면 학습이 안되길래 바꿔줌."],"metadata":{"id":"N6ELIlDljmC6","executionInfo":{"status":"ok","timestamp":1646029255222,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["train.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"cKPpYYMqkCiS","executionInfo":{"status":"ok","timestamp":1646029256008,"user_tz":-540,"elapsed":390,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"54b1ef0b-e791-4cdf-f131-2c36ccd6ecd6"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0bf3792a-7d77-4d22-b4b0-ab9c494b61a1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf3792a-7d77-4d22-b4b0-ab9c494b61a1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0bf3792a-7d77-4d22-b4b0-ab9c494b61a1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0bf3792a-7d77-4d22-b4b0-ab9c494b61a1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ...  hate\n","0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"  ...  none\n","1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...  ...  hate\n","2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"  ...  hate\n","\n","[3 rows x 4 columns]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["train_dataset, eval_dataset = train_test_split(train, test_size=0.1, shuffle=True, stratify=train['label'])\n","\n","tokenized_train = tokenizer(\n","    list(train_dataset['title']),\n","    list(train_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256, # Max_Length = 138  tokenizing 하면 길이가 줄어들어서 128로 해도 무관한듯 ?\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","tokenized_eval = tokenizer(\n","    list(eval_dataset['title']),\n","    list(eval_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","print(tokenized_train['input_ids'][0])\n","print(tokenizer.decode(tokenized_train['input_ids'][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vc3OEAEcXkXZ","executionInfo":{"status":"ok","timestamp":1646029256682,"user_tz":-540,"elapsed":676,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"4b6166b1-517e-4563-84ad-6a4f449785e5"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([    2,     6,    61, 18398,    63,    11, 14734,  4172,  4178,  8018,\n","           11,  8929, 38390,  4215,  4151, 33984,  4166,    16, 11464,  8934,\n","         4027,  4529, 27064,  4628,  4424,  4276, 14734,  4331,    11, 12401,\n","           11,     6,     3, 17870,  2434,  8622, 17979, 12055,    18,  8426,\n","        12140, 35915,  8082,    18,  8022, 23845,  8485,  8004,    18,    18,\n","           18,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0])\n","[CLS] \" [ 종합 ]'조카면족하다'결혼14년차 김원희, 출산 진심고백→홍석천 조카와'갈등'\" [SEP] 몸이 안 따라준거였네. 마음고생 심했겠다. 그냥 솔직하게 얘기하지... [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["\n","class BERTDataset(torch.utils.data.Dataset):\n","    def __init__(self, pair_dataset, label):\n","        self.pair_dataset = pair_dataset\n","        self.label = label\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n","        item['label'] = torch.tensor(self.label[idx])\n","        \n","        return item\n","\n","    def __len__(self):\n","        return len(self.label)"],"metadata":{"id":"lpyGY8GjdC1L","executionInfo":{"status":"ok","timestamp":1646029277919,"user_tz":-540,"elapsed":318,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["\n","def label_to_num(label): \n","    label_dict = {\"none\": 0, \"others\": 1, \"gender\": 2}  #여기   answer 는 의미 없는거임 참고한 코드에 있어서 그냥 놔둠\n","    num_label = []\n","\n","    for v in label: \n","        num_label.append(label_dict[v])\n","    \n","    return num_label\n","\n","\n","train_label = label_to_num(train_dataset['label'].values)\n","eval_label = label_to_num(eval_dataset['label'].values)"],"metadata":{"id":"uVZRF495dvDS","executionInfo":{"status":"ok","timestamp":1646029278239,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["train_dataset = BERTDataset(tokenized_train, train_label)\n","eval_dataset = BERTDataset(tokenized_eval, eval_label)\n","\n","print(train_dataset.__len__())\n","print(train_dataset.__getitem__(7529))\n","print(tokenizer.decode(train_dataset.__getitem__(7529)['input_ids'])) # 메서드 호출하면 이렇게 생겼구나 .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS6OZupre0v-","executionInfo":{"status":"ok","timestamp":1646029278542,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a1b0785e-4874-4219-a4df-8ffdeb57d09b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["7530\n","{'input_ids': tensor([    2,     6,    11, 16003,  4878,  4008,  4075,    11, 10019,  4192,\n","           16, 34264,  4230, 44225,  3192, 16003,  4169,  9181, 28816,  4058,\n","           61, 18398,    63,     6,     3,   519,  5751, 39853, 11061,   519,\n","         5751,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] \"'호텔델루나'이지은, 여진구 남겨둔 채 호텔과 함께 사라졌다 [ 종합 ] \" [SEP] 꿀잼 아이유 연기 꿀잼 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","  \"\"\" validation을 위한 metrics function \"\"\"\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  probs = pred.predictions\n","\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n","  f1_macro = f1_score(labels, preds, average='macro')\n","  return {\n","      'accuracy': acc,\n","      'f1_macro': f1_macro,\n","  }"],"metadata":{"id":"WXoFRpiSe-Zm","executionInfo":{"status":"ok","timestamp":1646029487477,"user_tz":-540,"elapsed":274,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["training_ars = TrainingArguments(\n","\n","    # 항상바꿔주자. checkpoint 마다 모델이 해당 경로에 저장됨.\n","    output_dir='/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04',\n","    num_train_epochs=20,\n","    per_device_train_batch_size=32,\n","    save_total_limit=5, # 성능 상위 5개 모델만 저장.  이거 용량 꽤 커서 제한 해줘야댐.\n","    save_strategy = 'epoch',\n","    evaluation_strategy='epoch',\n","    load_best_model_at_end = True, # parameter들 의미를 정확히 모름 알아보고 바꿔주면 성능 올라갈듯.\n","    metric_for_best_model= 'f1_macro',\n","    greater_is_better= True,\n","    fp16 = True,\n","\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_ars,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEjCbsBt_vL4","executionInfo":{"status":"ok","timestamp":1646029550349,"user_tz":-540,"elapsed":11417,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"afb66716-447e-40b7-9770-e3957383047d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Using amp half precision backend\n"]}]},{"cell_type":"code","source":["trainer.train()\n","model.save_pretrained('/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/best_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aKdBZZk_gtTy","executionInfo":{"status":"ok","timestamp":1646030295892,"user_tz":-540,"elapsed":745551,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"bdb8a29f-9f66-42a5-8a69-0edabf65b00f"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 7530\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4720\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1888' max='4720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1888/4720 12:22 < 18:35, 2.54 it/s, Epoch 8/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.154766</td>\n","      <td>0.968937</td>\n","      <td>0.955543</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.108461</td>\n","      <td>0.978495</td>\n","      <td>0.973487</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.092600</td>\n","      <td>0.113813</td>\n","      <td>0.982079</td>\n","      <td>0.976133</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.092600</td>\n","      <td>0.148388</td>\n","      <td>0.970131</td>\n","      <td>0.959560</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.029700</td>\n","      <td>0.157224</td>\n","      <td>0.977300</td>\n","      <td>0.968762</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.029700</td>\n","      <td>0.167681</td>\n","      <td>0.976105</td>\n","      <td>0.965828</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.009400</td>\n","      <td>0.154440</td>\n","      <td>0.977300</td>\n","      <td>0.970229</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.009400</td>\n","      <td>0.173000</td>\n","      <td>0.978495</td>\n","      <td>0.969782</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1180\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1180/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1180/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1180/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1180/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1416\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1416/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1416/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1416/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1416/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-236] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-472] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1888\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1888/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1888/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1888/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1888/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-944] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-708 (score: 0.9761334248808083).\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/best_model/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/best_model/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","Tokenizer_NAME = bias_model\n","tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n","\n","MODEL_NAME = '/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652'  # checkpoint 마다 미리 지정해둔 경로에 모델 저장됨 ㅇㅇ\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","model.resize_token_embeddings(tokenizer.vocab_size) # load_best_model = true 라서 그냥 모델쓰면댐 ㅇㅇ\n","model.to(device)\n","\n","print(tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2niFtb8Tg7NZ","executionInfo":{"status":"ok","timestamp":1646033244876,"user_tz":-540,"elapsed":5362,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"d9371ab8-16f1-4f6f-81ed-7b2e26e8b1a1"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/beomi/beep-KcELECTRA-base-bias/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/69fdbef31e3e81dc248c7cf959d7c4e20bc3541ac6991ec073938a51e64151ea.a59cda3abc7fe9224f5b3344b4ac76b515bb2d86124f7ab6cfd6f7be710361c3\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-bias/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/63868885a8c2d98e7fdc35996d9382cea91058406924a6ae8db658bb5ac9b263.4952cacdcbbd2176992883f3375706d756af20e3e4d3337a2884539239fdf20c\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-bias/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-bias/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/640ba04c8ce4ee7851648b0c532ef666015efacb011e5a285cd5601228f6e5f6.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-bias/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6a3ade6eea9766b57ec2701e11f41b50361c9f8200153be9fd6caa45871d40e4.3f9d767de7f1e5d203a4674c0ad002907e8a22d6ab991a2ee363c487ba8ee99b\n","loading configuration file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/config.json\n","Model config ElectraConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"none\",\n","    \"1\": \"others\",\n","    \"2\": \"gender\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"gender\": 2,\n","    \"none\": 0,\n","    \"others\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50135\n","}\n","\n","loading weights file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652/pytorch_model.bin\n","All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n","\n","All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/checkpoint-1652.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["PreTrainedTokenizerFast(name_or_path='beomi/beep-KcELECTRA-base-bias', vocab_size=50135, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"]}]},{"cell_type":"code","source":["test['label'] = 'none'"],"metadata":{"id":"fXwBBjU7eEsi","executionInfo":{"status":"ok","timestamp":1646033248226,"user_tz":-540,"elapsed":300,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["test.tail(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"vkSb4mR8eOqM","executionInfo":{"status":"ok","timestamp":1646033248512,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"cc99c6b9-a9d0-4cf8-f06e-1e54cfc0156c"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9e45b41c-e78c-431c-9be6-ea70c6034d67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>506</th>\n","      <td>506</td>\n","      <td>[N이슈] 최율, 조재현 성추행 의혹 폭로… 소속사 \"상황 파악 중\"</td>\n","      <td>얜 그냥 봐도 아니다 ㅋ 고소당하면 어마어마한 금액 물어줘야할껄?</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>507</td>\n","      <td>해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"날씨가 좋아서\" [SC컷]</td>\n","      <td>대박 게스트... 꼭 봐야징~ 컨셉이 바뀌니깐 재미지넹</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>[SS인터뷰①]박민영 \"'김비서' 행복했다..열애설엔 당당..미소였으니까\"</td>\n","      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>[POP이슈]\"사실무근\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '핫'(종합)</td>\n","      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'</td>\n","      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e45b41c-e78c-431c-9be6-ea70c6034d67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e45b41c-e78c-431c-9be6-ea70c6034d67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e45b41c-e78c-431c-9be6-ea70c6034d67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  ... label\n","506  506  ...  none\n","507  507  ...  none\n","508  508  ...  none\n","509  509  ...  none\n","510  510  ...  none\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["test_label = label_to_num(test['label'].values)\n","\n","tokenized_test = tokenizer(\n","    list(test['title']),\n","    list(test['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","test_dataset = BERTDataset(tokenized_test, test_label)\n","\n","print(test_dataset.__len__())\n","print(test_dataset.__getitem__(510))\n","print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ32SmdTr1uB","executionInfo":{"status":"ok","timestamp":1646033254527,"user_tz":-540,"elapsed":279,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"8341c073-b44d-4cbd-f5e4-0471e3ad44a3"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["511\n","{'input_ids': tensor([    2,  2571,  4473,  4424, 27048,    11, 42252,  4192,    16, 31895,\n","        12869,    33,    18,    18,    18,  2155,  4529,  4041, 29372, 12634,\n","           11, 31971,    11,     3, 11010,  2111,  4050,  5222,  4012,  8229,\n","         4010,  8842, 23704,     3,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] [ SS리뷰 ]'골목식당'신흥시장 변화 이끈 백종원의'진심'[SEP] 골목살리고 지가하는 체인점 다입점해서. 때돈벌고. 피디 술사주고. 지가 음식점 체인사업을 때려쳐야 진정성이보이는거지 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","model.eval()\n","output_pred = []\n","output_prob = []\n","\n","for i, data in enumerate(tqdm(dataloader)):\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids=data['input_ids'].to(device),\n","            attention_mask=data['attention_mask'].to(device),\n","            token_type_ids=data['token_type_ids'].to(device)\n","        )\n","    logits = outputs[0]\n","    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n","    logits = logits.detach().cpu().numpy()\n","    result = np.argmax(logits, axis=-1)\n","\n","    output_pred.append(result)\n","    output_prob.append(prob)\n","  \n","pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n","print(pred_answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psDdVv-LedCG","executionInfo":{"status":"ok","timestamp":1646033267054,"user_tz":-540,"elapsed":1921,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"150bfda6-cca2-4579-9e1a-2c46db354b7c"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 10.29it/s]"]},{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 2, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 1, 0, 2, 0, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def num_to_label(label):\n","    label_dict = {0: \"none\", 1: \"others\", 2: \"gender\"}\n","    str_label = []\n","\n","    for i, v in enumerate(label):\n","        str_label.append([i,label_dict[v]])\n","    \n","    return str_label\n","\n","answer = num_to_label(pred_answer)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3XbTA96e1c-","executionInfo":{"status":"ok","timestamp":1646033271470,"user_tz":-540,"elapsed":287,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"18e3639f-27ba-485f-db53-f1042935b78a"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 'none'], [1, 'none'], [2, 'none'], [3, 'others'], [4, 'others'], [5, 'others'], [6, 'others'], [7, 'none'], [8, 'gender'], [9, 'none'], [10, 'none'], [11, 'gender'], [12, 'none'], [13, 'others'], [14, 'none'], [15, 'gender'], [16, 'none'], [17, 'gender'], [18, 'others'], [19, 'none'], [20, 'gender'], [21, 'none'], [22, 'others'], [23, 'none'], [24, 'none'], [25, 'none'], [26, 'gender'], [27, 'none'], [28, 'none'], [29, 'none'], [30, 'others'], [31, 'gender'], [32, 'none'], [33, 'others'], [34, 'none'], [35, 'gender'], [36, 'none'], [37, 'none'], [38, 'none'], [39, 'none'], [40, 'others'], [41, 'none'], [42, 'others'], [43, 'none'], [44, 'none'], [45, 'none'], [46, 'none'], [47, 'none'], [48, 'none'], [49, 'gender'], [50, 'others'], [51, 'none'], [52, 'others'], [53, 'gender'], [54, 'none'], [55, 'gender'], [56, 'gender'], [57, 'none'], [58, 'none'], [59, 'none'], [60, 'others'], [61, 'gender'], [62, 'none'], [63, 'gender'], [64, 'none'], [65, 'none'], [66, 'none'], [67, 'none'], [68, 'none'], [69, 'others'], [70, 'others'], [71, 'none'], [72, 'none'], [73, 'none'], [74, 'gender'], [75, 'none'], [76, 'gender'], [77, 'others'], [78, 'gender'], [79, 'gender'], [80, 'none'], [81, 'none'], [82, 'others'], [83, 'none'], [84, 'none'], [85, 'none'], [86, 'none'], [87, 'others'], [88, 'others'], [89, 'none'], [90, 'none'], [91, 'others'], [92, 'none'], [93, 'none'], [94, 'none'], [95, 'gender'], [96, 'none'], [97, 'others'], [98, 'none'], [99, 'none'], [100, 'none'], [101, 'none'], [102, 'none'], [103, 'none'], [104, 'gender'], [105, 'none'], [106, 'others'], [107, 'none'], [108, 'none'], [109, 'none'], [110, 'none'], [111, 'none'], [112, 'others'], [113, 'none'], [114, 'others'], [115, 'others'], [116, 'others'], [117, 'none'], [118, 'others'], [119, 'none'], [120, 'none'], [121, 'none'], [122, 'none'], [123, 'others'], [124, 'none'], [125, 'none'], [126, 'gender'], [127, 'gender'], [128, 'none'], [129, 'gender'], [130, 'none'], [131, 'none'], [132, 'none'], [133, 'gender'], [134, 'none'], [135, 'none'], [136, 'none'], [137, 'none'], [138, 'none'], [139, 'none'], [140, 'none'], [141, 'none'], [142, 'gender'], [143, 'others'], [144, 'none'], [145, 'none'], [146, 'none'], [147, 'none'], [148, 'none'], [149, 'none'], [150, 'others'], [151, 'none'], [152, 'none'], [153, 'gender'], [154, 'gender'], [155, 'none'], [156, 'others'], [157, 'others'], [158, 'none'], [159, 'none'], [160, 'none'], [161, 'gender'], [162, 'none'], [163, 'none'], [164, 'gender'], [165, 'gender'], [166, 'none'], [167, 'others'], [168, 'none'], [169, 'none'], [170, 'gender'], [171, 'none'], [172, 'none'], [173, 'none'], [174, 'gender'], [175, 'others'], [176, 'gender'], [177, 'none'], [178, 'gender'], [179, 'none'], [180, 'none'], [181, 'others'], [182, 'gender'], [183, 'others'], [184, 'others'], [185, 'none'], [186, 'none'], [187, 'others'], [188, 'none'], [189, 'none'], [190, 'none'], [191, 'others'], [192, 'others'], [193, 'none'], [194, 'none'], [195, 'none'], [196, 'gender'], [197, 'others'], [198, 'others'], [199, 'others'], [200, 'none'], [201, 'none'], [202, 'none'], [203, 'none'], [204, 'others'], [205, 'others'], [206, 'none'], [207, 'none'], [208, 'none'], [209, 'others'], [210, 'none'], [211, 'others'], [212, 'none'], [213, 'none'], [214, 'none'], [215, 'gender'], [216, 'gender'], [217, 'none'], [218, 'others'], [219, 'others'], [220, 'none'], [221, 'none'], [222, 'gender'], [223, 'none'], [224, 'none'], [225, 'none'], [226, 'others'], [227, 'none'], [228, 'others'], [229, 'others'], [230, 'gender'], [231, 'none'], [232, 'none'], [233, 'others'], [234, 'others'], [235, 'gender'], [236, 'none'], [237, 'none'], [238, 'none'], [239, 'others'], [240, 'gender'], [241, 'gender'], [242, 'gender'], [243, 'none'], [244, 'none'], [245, 'others'], [246, 'none'], [247, 'none'], [248, 'none'], [249, 'none'], [250, 'none'], [251, 'none'], [252, 'none'], [253, 'none'], [254, 'none'], [255, 'none'], [256, 'none'], [257, 'none'], [258, 'gender'], [259, 'gender'], [260, 'none'], [261, 'none'], [262, 'others'], [263, 'none'], [264, 'others'], [265, 'none'], [266, 'none'], [267, 'gender'], [268, 'none'], [269, 'none'], [270, 'others'], [271, 'gender'], [272, 'none'], [273, 'none'], [274, 'none'], [275, 'none'], [276, 'others'], [277, 'none'], [278, 'none'], [279, 'others'], [280, 'none'], [281, 'gender'], [282, 'gender'], [283, 'none'], [284, 'none'], [285, 'none'], [286, 'none'], [287, 'gender'], [288, 'none'], [289, 'gender'], [290, 'others'], [291, 'none'], [292, 'others'], [293, 'none'], [294, 'others'], [295, 'none'], [296, 'none'], [297, 'none'], [298, 'none'], [299, 'none'], [300, 'gender'], [301, 'gender'], [302, 'none'], [303, 'none'], [304, 'none'], [305, 'none'], [306, 'none'], [307, 'none'], [308, 'none'], [309, 'none'], [310, 'none'], [311, 'others'], [312, 'gender'], [313, 'gender'], [314, 'gender'], [315, 'none'], [316, 'none'], [317, 'gender'], [318, 'others'], [319, 'none'], [320, 'none'], [321, 'none'], [322, 'none'], [323, 'others'], [324, 'none'], [325, 'others'], [326, 'none'], [327, 'none'], [328, 'gender'], [329, 'none'], [330, 'others'], [331, 'none'], [332, 'none'], [333, 'others'], [334, 'none'], [335, 'none'], [336, 'others'], [337, 'gender'], [338, 'none'], [339, 'none'], [340, 'others'], [341, 'others'], [342, 'gender'], [343, 'none'], [344, 'none'], [345, 'none'], [346, 'none'], [347, 'none'], [348, 'gender'], [349, 'none'], [350, 'none'], [351, 'others'], [352, 'none'], [353, 'none'], [354, 'none'], [355, 'none'], [356, 'none'], [357, 'others'], [358, 'gender'], [359, 'others'], [360, 'none'], [361, 'others'], [362, 'none'], [363, 'none'], [364, 'none'], [365, 'gender'], [366, 'none'], [367, 'others'], [368, 'none'], [369, 'none'], [370, 'others'], [371, 'none'], [372, 'none'], [373, 'none'], [374, 'gender'], [375, 'none'], [376, 'gender'], [377, 'none'], [378, 'none'], [379, 'others'], [380, 'none'], [381, 'none'], [382, 'none'], [383, 'none'], [384, 'none'], [385, 'none'], [386, 'none'], [387, 'none'], [388, 'gender'], [389, 'none'], [390, 'none'], [391, 'none'], [392, 'none'], [393, 'gender'], [394, 'others'], [395, 'none'], [396, 'gender'], [397, 'none'], [398, 'none'], [399, 'none'], [400, 'others'], [401, 'gender'], [402, 'none'], [403, 'none'], [404, 'others'], [405, 'others'], [406, 'none'], [407, 'gender'], [408, 'none'], [409, 'none'], [410, 'none'], [411, 'others'], [412, 'gender'], [413, 'others'], [414, 'others'], [415, 'gender'], [416, 'others'], [417, 'none'], [418, 'others'], [419, 'others'], [420, 'others'], [421, 'others'], [422, 'none'], [423, 'none'], [424, 'gender'], [425, 'none'], [426, 'none'], [427, 'others'], [428, 'none'], [429, 'gender'], [430, 'others'], [431, 'none'], [432, 'gender'], [433, 'none'], [434, 'none'], [435, 'none'], [436, 'none'], [437, 'others'], [438, 'gender'], [439, 'none'], [440, 'none'], [441, 'none'], [442, 'others'], [443, 'others'], [444, 'none'], [445, 'others'], [446, 'gender'], [447, 'gender'], [448, 'none'], [449, 'gender'], [450, 'none'], [451, 'none'], [452, 'none'], [453, 'none'], [454, 'others'], [455, 'gender'], [456, 'others'], [457, 'none'], [458, 'gender'], [459, 'others'], [460, 'none'], [461, 'none'], [462, 'none'], [463, 'none'], [464, 'gender'], [465, 'none'], [466, 'others'], [467, 'none'], [468, 'others'], [469, 'none'], [470, 'gender'], [471, 'gender'], [472, 'others'], [473, 'none'], [474, 'gender'], [475, 'none'], [476, 'gender'], [477, 'others'], [478, 'others'], [479, 'none'], [480, 'none'], [481, 'none'], [482, 'others'], [483, 'gender'], [484, 'none'], [485, 'none'], [486, 'none'], [487, 'none'], [488, 'none'], [489, 'none'], [490, 'none'], [491, 'others'], [492, 'none'], [493, 'others'], [494, 'none'], [495, 'gender'], [496, 'none'], [497, 'none'], [498, 'gender'], [499, 'others'], [500, 'none'], [501, 'others'], [502, 'none'], [503, 'none'], [504, 'others'], [505, 'others'], [506, 'none'], [507, 'none'], [508, 'others'], [509, 'others'], [510, 'others']]\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(answer, columns=['ID', 'bias'])\n","\n","df.to_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/seperated_submit01.csv', index=False) # 매번 파일 이름 바꿔주자\n","\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRwDbvC7fTI-","executionInfo":{"status":"ok","timestamp":1646033275369,"user_tz":-540,"elapsed":384,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"9ac2fc8c-12f8-4d75-b1a8-f83604fce7b0"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["      ID    bias\n","0      0    none\n","1      1    none\n","2      2    none\n","3      3  others\n","4      4  others\n","..   ...     ...\n","506  506    none\n","507  507    none\n","508  508  others\n","509  509  others\n","510  510  others\n","\n","[511 rows x 2 columns]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"TQmIbGoAL2ie"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# bias 끝"],"metadata":{"id":"Z3zDCpTFtXLE"}},{"cell_type":"markdown","source":["# 이제 hate 모델을 만들어 보자\n","bias 와 똑같이 진행 하되, Number of classes 를 2로 바꾸고 label column 을 바꿔주자"],"metadata":{"id":"BoHcitU6g_AT"}},{"cell_type":"code","source":["# tokenizer 는 위에서 이미 load 되어 있으므로 생략 해도됨(아마도)\n","MODEL_NAME = hate_model  # 위에 test 할때 MODEL_NAME 변수에 checkpoint-1500 모델로 저장되어 있어서 새로 불러옴 ㅇㅇ\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","config.num_labels = 3 # 오류나길레 그냥 3으로 해줌.  기존 학습 데이터 라벨 : none, hate, offensive\n","\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n","\n","print(model)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3L9DUf0Ygjby","executionInfo":{"status":"ok","timestamp":1646033285978,"user_tz":-540,"elapsed":4044,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"9a8c4611-9ede-42b6-f8f6-3c9ce66593d7"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/013e359d5e8b3c38b2b1f7016ddc0c5a6e82edb1e42d78aee92f070a0e775326.a59cda3abc7fe9224f5b3344b4ac76b515bb2d86124f7ab6cfd6f7be710361c3\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/97b99140595f8ed0b06385019dacdded5dd5aa062c53686325d3d466bee4aac5.4952cacdcbbd2176992883f3375706d756af20e3e4d3337a2884539239fdf20c\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/22b31305287f4dd412eda7755af5342128d3c2bf168efc682db44f2027d127d2.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/abdfe5a4b55614fd59218d81474027d6321ef1f268ea96172d5b83e8f2bc62f0.3f9d767de7f1e5d203a4674c0ad002907e8a22d6ab991a2ee363c487ba8ee99b\n","loading configuration file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a564196f71087715afaaeef769916f83971f3f94349e4ae92bd68b553bf473a4.45b091cabe5232290517931d191ef47f65df2bdb17b19cdd366ab390164abecf\n","Model config ElectraConfig {\n","  \"_name_or_path\": \"beomi/beep-KcELECTRA-base-hate\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"none\",\n","    \"1\": \"offensive\",\n","    \"2\": \"hate\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"hate\": 2,\n","    \"none\": 0,\n","    \"offensive\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50135\n","}\n","\n","loading weights file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0aeeb6ff3ca4a3021f330295bf473df02278a04ab59dda8ae6443cda0f7ab5b8.a6bd5b8f69e4a76a3beaea3af782d5c71e6f0bdd21fff02eee9f468ae19a5e0d\n","All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n","\n","All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at beomi/beep-KcELECTRA-base-hate.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")\n","ElectraConfig {\n","  \"_name_or_path\": \"beomi/beep-KcELECTRA-base-hate\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"none\",\n","    \"1\": \"offensive\",\n","    \"2\": \"hate\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"hate\": 2,\n","    \"none\": 0,\n","    \"offensive\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50135\n","}\n","\n"]}]},{"cell_type":"code","source":["train.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"Jdi3gDunjFEz","executionInfo":{"status":"ok","timestamp":1646033296936,"user_tz":-540,"elapsed":284,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"ec1232c4-0fba-4652-d88f-d313c39187a3"},"execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-e1b087dc-2921-4ea3-864a-cdf70e08dbe4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1b087dc-2921-4ea3-864a-cdf70e08dbe4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e1b087dc-2921-4ea3-864a-cdf70e08dbe4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e1b087dc-2921-4ea3-864a-cdf70e08dbe4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                        title         comment  bias label\n","0  \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"  김태리 정말 연기잘해 진짜  none  none"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["train.rename(columns = {'label':'bias', 'hate':'label'},inplace=True) # label -> bias ,  hate -> label   아니면 train dataset 새로 불러오던가."],"metadata":{"id":"TcCSTjMriRf8","executionInfo":{"status":"ok","timestamp":1646031670171,"user_tz":-540,"elapsed":285,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["train.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563},"id":"e08WxC-vjg4C","executionInfo":{"status":"ok","timestamp":1646031670468,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"17cbd668-f693-49ec-f325-5712bc32e5db"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d45ba94f-fe44-44ac-8caa-6cdbf8a44157\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n","      <td>일본 축구 져라</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n","      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>\"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"</td>\n","      <td>만진건 변하지 않는다 아이돌은 아이돌 좋아하는 여자들한테 이미지가 생명인데 얜 바닥...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>\"[POP이슈]'프듀2' 김사무엘 父, 멕시코서 숨진 채 발견→타살 의혹 제기→애도...</td>\n","      <td>연예계에 외국인노동자 많네..</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>\"슈, 동안미모+아찔한 수영복 자태로 시선강탈 \"\"밥을 먹을 수가 없네\"\"\"</td>\n","      <td>아이는 대부분 엄마가 원해서낳고 독박육아하고남편은 그냥 따라고는 수준!싫은 내색도 ...</td>\n","      <td>gender</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>\"AOA 지민, 앙상한 몸매·건강이상설 직접 해명 \"\"건강합니다\"\" [공식입장]\"</td>\n","      <td>먼기사를 기대하고 사진을 올리는지....관종</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>\"\"\"이 정도면 신드롬\"\"..'연예인들의 연예인' 양준일, 이지혜→김이나→신현준도 ...</td>\n","      <td>개그맨 김경민 닮은다고 나만 느낌?</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d45ba94f-fe44-44ac-8caa-6cdbf8a44157')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d45ba94f-fe44-44ac-8caa-6cdbf8a44157 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d45ba94f-fe44-44ac-8caa-6cdbf8a44157');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ... label\n","0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"  ...  none\n","1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...  ...  hate\n","2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"  ...  hate\n","3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"  ...  none\n","4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...  ...  none\n","5                     \"샤이니 온유, 클럽 강제추행 '무혐의' 처분 받았다\"  ...  hate\n","6  \"[POP이슈]'프듀2' 김사무엘 父, 멕시코서 숨진 채 발견→타살 의혹 제기→애도...  ...  hate\n","7         \"슈, 동안미모+아찔한 수영복 자태로 시선강탈 \"\"밥을 먹을 수가 없네\"\"\"  ...  hate\n","8      \"AOA 지민, 앙상한 몸매·건강이상설 직접 해명 \"\"건강합니다\"\" [공식입장]\"  ...  hate\n","9  \"\"\"이 정도면 신드롬\"\"..'연예인들의 연예인' 양준일, 이지혜→김이나→신현준도 ...  ...  none\n","\n","[10 rows x 4 columns]"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["train_dataset, eval_dataset = train_test_split(train, test_size=0.1, shuffle=True, stratify=train['label'])\n","\n","tokenized_train = tokenizer(\n","    list(train_dataset['title']),\n","    list(train_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256, # Max_Length = 138\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","tokenized_eval = tokenizer(\n","    list(eval_dataset['title']),\n","    list(eval_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","print(tokenized_train['input_ids'][0])\n","print(tokenizer.decode(tokenized_train['input_ids'][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3EgAkwjjj5K","executionInfo":{"status":"ok","timestamp":1646031692440,"user_tz":-540,"elapsed":1174,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"47b96799-001e-4de6-f3d1-811832c82d22"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([    2,    61, 12081,  4231,  4231,    63,    11,  2836,  4194,  4486,\n","         9464,    11,  2571,  4782,  8254,    33,    18,    18,    26,  4107,\n","        28877,  3775,  4230,  4379, 10657,     3,  9092,  2836,  4194,  4486,\n","         8045, 13738, 12466,  4268,     3,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0])\n","[CLS] [ 스타톡톡 ]'정소영 남편'오협 누구?.. 6세 연상 학구파 배우 [SEP] 일단 정소영부터 누군지 모르겠음 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["# hate label 에 맞게 바꿔주자   # 좀더 깔끔한 방법이 있을거같은데 일단 ㄱ\n","def hate_to_num(label): \n","    label_dict = {\"none\": 0, \"hate\": 1, 'offensive': 1}\n","    num_label = []\n","\n","    for v in label: \n","        num_label.append(label_dict[v])\n","    \n","    return num_label\n","\n","\n","train_label = hate_to_num(train_dataset['label'].values)\n","eval_label = hate_to_num(eval_dataset['label'].values)"],"metadata":{"id":"aUTVAXVFj8C2","executionInfo":{"status":"ok","timestamp":1646032176351,"user_tz":-540,"elapsed":285,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["train_dataset = BERTDataset(tokenized_train, train_label)\n","eval_dataset = BERTDataset(tokenized_eval, eval_label)\n","\n","print(train_dataset.__len__())\n","print(train_dataset.__getitem__(7529))\n","print(tokenizer.decode(train_dataset.__getitem__(7529)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGYsPDqikkLe","executionInfo":{"status":"ok","timestamp":1646032179412,"user_tz":-540,"elapsed":296,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"760768d8-6a21-4497-8da1-ddec46d3404f"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["7530\n","{'input_ids': tensor([    2,     6, 25048,  3481, 33381,  4499,  4591,    16, 28719, 12433,\n","        27404, 25049,    18,    18, 25046,  3389,  4562,  4265, 25047,   335,\n","         4156,  4376,    16, 19412, 11751,   820, 19744,    12, 18398,    13,\n","            6,     3,  3001,  4336, 10460,  8340,  2434,  4675,  4095,     3,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] \" “ 키 182cm, 농구선수 제의 ”.. ‘ 컬투쇼 ’ 권상우, 바둑빼고 다 잘하네 ( 종합 ) \" [SEP] 지달 180 절대 안넘으 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["training_ars = TrainingArguments(\n","\n","    # 항상바꿔주자. checkpoint 마다 모델이 해당 경로에 저장됨.\n","    output_dir='/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate',\n","    num_train_epochs=20,\n","    per_device_train_batch_size=32,\n","    save_total_limit=5, # 성능 상위 5개 모델만 저장.  이거 용량 꽤 커서 제한 해줘야댐.\n","    save_strategy = 'epoch',\n","    evaluation_strategy='epoch',\n","    load_best_model_at_end = True, # parameter들 의미를 정확히 모름 알아보고 바꿔주면 성능 올라갈듯.\n","    metric_for_best_model= 'f1_macro',\n","    greater_is_better= True,\n","    fp16 = True,\n","\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_ars,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tLp8X2zksCs","executionInfo":{"status":"ok","timestamp":1646032269154,"user_tz":-540,"elapsed":711,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"442c3585-d658-4d2f-d9bd-b927de4b3921"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using amp half precision backend\n"]}]},{"cell_type":"code","source":["trainer.train()\n","model.save_pretrained('/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/best_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_5NB1aQ_lcoD","executionInfo":{"status":"error","timestamp":1646032869810,"user_tz":-540,"elapsed":473873,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"37cdd880-7dfb-4ba8-db48-2ff8270e6b2d"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 7530\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4720\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1204' max='4720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1204/4720 07:52 < 23:02, 2.54 it/s, Epoch 5.10/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Macro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.123256</td>\n","      <td>0.962963</td>\n","      <td>0.962212</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.164667</td>\n","      <td>0.952210</td>\n","      <td>0.951639</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.140900</td>\n","      <td>0.204515</td>\n","      <td>0.947431</td>\n","      <td>0.946591</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.140900</td>\n","      <td>0.302450</td>\n","      <td>0.943847</td>\n","      <td>0.942823</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.038100</td>\n","      <td>0.315342</td>\n","      <td>0.941458</td>\n","      <td>0.940890</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-472\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-472/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-472/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-472/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-472/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-708\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-708/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-708/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-708/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-708/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-944\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-944/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-944/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-944/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-944/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-1180\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-1180/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-1180/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-1180/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-1180/special_tokens_map.json\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-fe8d9a840c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1951\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","Tokenizer_NAME = hate_model\n","tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n","\n","MODEL_NAME = '/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236'  # checkpoint 마다 미리 지정해둔 경로에 모델 저장됨 ㅇㅇ\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","model.resize_token_embeddings(tokenizer.vocab_size)\n","model.to(device)\n","\n","print(tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzEze2bTluMI","executionInfo":{"status":"ok","timestamp":1646033348522,"user_tz":-540,"elapsed":4408,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"53748115-1c17-4797-f776-2f620f79f975"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/013e359d5e8b3c38b2b1f7016ddc0c5a6e82edb1e42d78aee92f070a0e775326.a59cda3abc7fe9224f5b3344b4ac76b515bb2d86124f7ab6cfd6f7be710361c3\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/97b99140595f8ed0b06385019dacdded5dd5aa062c53686325d3d466bee4aac5.4952cacdcbbd2176992883f3375706d756af20e3e4d3337a2884539239fdf20c\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/22b31305287f4dd412eda7755af5342128d3c2bf168efc682db44f2027d127d2.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","loading file https://huggingface.co/beomi/beep-KcELECTRA-base-hate/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/abdfe5a4b55614fd59218d81474027d6321ef1f268ea96172d5b83e8f2bc62f0.3f9d767de7f1e5d203a4674c0ad002907e8a22d6ab991a2ee363c487ba8ee99b\n","loading configuration file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/config.json\n","Model config ElectraConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236\",\n","  \"architectures\": [\n","    \"ElectraForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 768,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"none\",\n","    \"1\": \"offensive\",\n","    \"2\": \"hate\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"hate\": 2,\n","    \"none\": 0,\n","    \"offensive\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"electra\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"summary_activation\": \"gelu\",\n","  \"summary_last_dropout\": 0.1,\n","  \"summary_type\": \"first\",\n","  \"summary_use_proj\": true,\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50135\n","}\n","\n","loading weights file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236/pytorch_model.bin\n","All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n","\n","All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/kcelectra04/hate/checkpoint-236.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["PreTrainedTokenizerFast(name_or_path='beomi/beep-KcELECTRA-base-hate', vocab_size=50135, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"]}]},{"cell_type":"code","source":["test['label'] = 'none' # label colum}n 생성 아무값으로 ㄱ"],"metadata":{"id":"ygUjBUnjteAL","executionInfo":{"status":"ok","timestamp":1646033351969,"user_tz":-540,"elapsed":275,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["test.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"jYisOEXftlKQ","executionInfo":{"status":"ok","timestamp":1646033353918,"user_tz":-540,"elapsed":385,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"fd69f219-7ecf-419c-985f-81403b71944c"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-905d30a5-85af-4dc2-bd29-5d7ff83d718e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>[SS인터뷰①]박민영 \"'김비서' 행복했다..열애설엔 당당..미소였으니까\"</td>\n","      <td>성형으로 다 뜯어고쳐놓고 예쁜척. 성형 전 니 얼굴 다 알고있다. 순자처럼 된장냄새...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>[POP이슈]\"사실무근\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '핫'(종합)</td>\n","      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'</td>\n","      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-905d30a5-85af-4dc2-bd29-5d7ff83d718e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-905d30a5-85af-4dc2-bd29-5d7ff83d718e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-905d30a5-85af-4dc2-bd29-5d7ff83d718e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  ... label\n","508  508  ...  none\n","509  509  ...  none\n","510  510  ...  none\n","\n","[3 rows x 4 columns]"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["test_label = label_to_num(test['label'].values)\n","\n","tokenized_test = tokenizer(\n","    list(test['title']),\n","    list(test['comment']),\n","    return_tensors=\"pt\",\n","    max_length=256,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","test_dataset = BERTDataset(tokenized_test, test_label)\n","\n","print(test_dataset.__len__())\n","print(test_dataset.__getitem__(510))\n","print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuVzWbwutmXn","executionInfo":{"status":"ok","timestamp":1646033358340,"user_tz":-540,"elapsed":306,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"0f39fa60-8959-4cff-d2f1-b181445752d7"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["511\n","{'input_ids': tensor([    2,  2571,  4473,  4424, 27048,    11, 42252,  4192,    16, 31895,\n","        12869,    33,    18,    18,    18,  2155,  4529,  4041, 29372, 12634,\n","           11, 31971,    11,     3, 11010,  2111,  4050,  5222,  4012,  8229,\n","         4010,  8842, 23704,     3,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] [ SS리뷰 ]'골목식당'신흥시장 변화 이끈 백종원의'진심'[SEP] 골목살리고 지가하는 체인점 다입점해서. 때돈벌고. 피디 술사주고. 지가 음식점 체인사업을 때려쳐야 진정성이보이는거지 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","model.eval()\n","output_pred = []\n","output_prob = []\n","\n","for i, data in enumerate(tqdm(dataloader)):\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids=data['input_ids'].to(device),\n","            attention_mask=data['attention_mask'].to(device),\n","            token_type_ids=data['token_type_ids'].to(device)\n","        )\n","    logits = outputs[0]\n","    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n","    logits = logits.detach().cpu().numpy()\n","    result = np.argmax(logits, axis=-1)\n","\n","    output_pred.append(result)\n","    output_prob.append(prob)\n","  \n","pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n","print(pred_answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1dKn7gZtpFo","executionInfo":{"status":"ok","timestamp":1646033362951,"user_tz":-540,"elapsed":1874,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"ce92cbf0-5444-4d35-ec56-9af468ecc1f6"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:01<00:00, 10.30it/s]"]},{"output_type":"stream","name":"stdout","text":["[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["print(output_prob) # 오.. 이거 확률값.. threshold 가능 할듯 ?"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsR_LdYtt5Of","executionInfo":{"status":"ok","timestamp":1646032969322,"user_tz":-540,"elapsed":343,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"083d8985-d4b2-44d5-d9a3-bcf7cb22ab03"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.9995812773704529, 0.0003982054768130183, 2.048896931228228e-05], [0.9994189739227295, 0.0005688293604180217, 1.2244440767972264e-05], [0.0001859772455645725, 0.9998078942298889, 6.1965461100044195e-06], [4.6412831579800695e-05, 0.9999257326126099, 2.781898911052849e-05], [0.0001295139518333599, 0.9998600482940674, 1.037426136463182e-05], [0.000117712355859112, 0.9998735189437866, 8.707782399142161e-06], [9.49262102949433e-05, 0.9998925924301147, 1.2460885045584291e-05], [0.0005477132508531213, 0.9994468092918396, 5.474116733239498e-06], [9.783659334061667e-05, 0.9998915195465088, 1.0587494216451887e-05], [0.999524712562561, 0.0004592344048433006, 1.6083748050732538e-05], [0.000938570883590728, 0.9990563988685608, 5.090661943540908e-06], [8.981704013422132e-05, 0.9998996257781982, 1.049213096848689e-05], [0.9995023012161255, 0.00048382760724052787, 1.383178368996596e-05], [5.286551095196046e-05, 0.9999244213104248, 2.2693477149005048e-05], [0.9995619654655457, 0.00042054959340021014, 1.756387428031303e-05], [5.646839417750016e-05, 0.9999250173568726, 1.8518232536735013e-05], [0.00021302045206539333, 0.9997789263725281, 8.040373359108344e-06], [0.0003213162999600172, 0.999672532081604, 6.174696409289027e-06], [0.999395489692688, 0.0005938467220403254, 1.0579174158920068e-05], [0.9995836615562439, 0.00039746297989040613, 1.8842381905415095e-05], [4.738027200801298e-05, 0.9999250173568726, 2.7558080546441488e-05], [0.00017249677330255508, 0.9998202919960022, 7.21244123269571e-06], [0.00016739922284614295, 0.9998239874839783, 8.605742550571449e-06], [4.18949312006589e-05, 0.9999098777770996, 4.81911665701773e-05], [0.00032245964393951, 0.9996721744537354, 5.432984835351817e-06], [0.034241970628499985, 0.9657511115074158, 6.889708402013639e-06], [5.5364416766678914e-05, 0.9999258518218994, 1.8818029275280423e-05], [0.9995342493057251, 0.0004500443465076387, 1.5707453712821007e-05], [0.007097957190126181, 0.9928968548774719, 5.233512638369575e-06], [0.999531626701355, 0.0004535943444352597, 1.4785598068556283e-05], [0.00012747118307743222, 0.9998632669448853, 9.275145202991553e-06], [4.2641691834433004e-05, 0.9999163150787354, 4.0977269236464053e-05], [0.00019832821271847934, 0.9997957348823547, 6.004582701280015e-06], [0.00022565464314538985, 0.9997678399085999, 6.474180736404378e-06], [0.9994940757751465, 0.0004908715491183102, 1.5029721907922067e-05], [0.00015592393174301833, 0.9998335838317871, 1.0486376595508773e-05], [0.002172991633415222, 0.9978224039077759, 4.616277237801114e-06], [0.9974656105041504, 0.0025205991696566343, 1.3758073691860773e-05], [0.0009248743881471455, 0.9990702271461487, 4.885472208115971e-06], [0.9989145994186401, 0.0010757269337773323, 9.605728337191977e-06], [5.96745521761477e-05, 0.9999232292175293, 1.70405583048705e-05], [0.31395047903060913, 0.6860364675521851, 1.2998827514820732e-05], [0.0001048967897077091, 0.9998866319656372, 8.501101547153667e-06], [0.9993579983711243, 0.0006303787813521922, 1.1629545042524114e-05], [0.9995884299278259, 0.0003939413873013109, 1.761719977366738e-05], [7.66760713304393e-05, 0.9999091625213623, 1.4135977835394442e-05], [0.001988076837733388, 0.9980071187019348, 4.869422809861135e-06], [0.0009499717853032053, 0.9990454316139221, 4.599988642439712e-06], [0.0014387243427336216, 0.9985565543174744, 4.752578661282314e-06], [0.00016786897322162986, 0.9998233914375305, 8.786390026216395e-06], [0.00018377101514488459, 0.9998083710670471, 7.83173800300574e-06], [0.9992378950119019, 0.0007532108575105667, 8.915090802474879e-06], [0.00013093579036649317, 0.9998598098754883, 9.27325618249597e-06], [5.099267218611203e-05, 0.9999232292175293, 2.5794848625082523e-05], [0.04620027542114258, 0.9537931680679321, 6.605556336580776e-06], [6.367473542923108e-05, 0.9999135732650757, 2.27364926104201e-05], [8.063886343734339e-05, 0.9999061822891235, 1.3130381375958677e-05], [0.999570906162262, 0.0004129346925765276, 1.6239951946772635e-05], [0.006740241311490536, 0.9932546019554138, 5.132090336701367e-06], [6.992827547946945e-05, 0.9999164342880249, 1.366401011182461e-05], [4.0907605580287054e-05, 0.9999104738235474, 4.8607951612211764e-05], [0.9150919914245605, 0.08489318937063217, 1.4830214240646455e-05], [0.9994149208068848, 0.0005744895315729082, 1.0590858437353745e-05], [9.991333354264498e-05, 0.9998874664306641, 1.265664104721509e-05], [0.00011783203080995008, 0.9998739957809448, 8.152615919243544e-06], [0.00015211304707918316, 0.999839186668396, 8.709003850526642e-06], [0.00021349995222408324, 0.9997804760932922, 6.002830559737049e-06], [5.45078182767611e-05, 0.9999188184738159, 2.6666064513847232e-05], [0.9994751811027527, 0.0005129185155965388, 1.1924259524676017e-05], [7.309625652851537e-05, 0.9999147653579712, 1.216077998833498e-05], [0.9993222951889038, 0.0006679388461634517, 9.779204447113443e-06], [0.00010312875383533537, 0.9998862743377686, 1.056960263667861e-05], [0.7668290734291077, 0.23316042125225067, 1.053270807460649e-05], [9.059914737008512e-05, 0.9998971223831177, 1.2240617252246011e-05], [9.257504279958084e-05, 0.999897837638855, 9.632916771806777e-06], [0.999460756778717, 0.0005222681793384254, 1.7091875633923337e-05], [0.9984906911849976, 0.0014986346941441298, 1.0702227882575244e-05], [8.520086703356355e-05, 0.9999005794525146, 1.4194891264196485e-05], [6.993337592575699e-05, 0.9999130964279175, 1.7004544133669697e-05], [0.001097845146432519, 0.9988961219787598, 5.951585990260355e-06], [6.322148692561314e-05, 0.9999150037765503, 2.1735788322985172e-05], [7.129424921004102e-05, 0.9999129772186279, 1.5765235730214044e-05], [0.0002123812009813264, 0.9997804760932922, 7.208207080111606e-06], [0.9995468258857727, 0.00043895875569432974, 1.4194417417456862e-05], [0.0034033055417239666, 0.9965916872024536, 5.072730346000753e-06], [0.9995346069335938, 0.0004501426301430911, 1.5214685845421627e-05], [0.002918061800301075, 0.9970767498016357, 5.15341162099503e-06], [4.2884941649390385e-05, 0.9999197721481323, 3.736505095730536e-05], [6.79337972542271e-05, 0.9999172687530518, 1.4813070265518036e-05], [0.9995251893997192, 0.0004612072661984712, 1.3607554137706757e-05], [0.9995946288108826, 0.0003857961273752153, 1.9600836822064593e-05], [0.013355115428566933, 0.986639142036438, 5.814559244754491e-06], [7.161697431001812e-05, 0.9999157190322876, 1.265084483748069e-05], [0.9897621273994446, 0.010227058082818985, 1.0903004294959828e-05], [0.0003013096284121275, 0.9996930360794067, 5.661717750626849e-06], [4.9723614210961387e-05, 0.9999258518218994, 2.4432923964923248e-05], [0.0004103647661395371, 0.9995844960212708, 5.158333351573674e-06], [0.00017362854850944132, 0.9998196959495544, 6.68965321892756e-06], [0.5358824133872986, 0.46410393714904785, 1.3651861991093028e-05], [6.016979750711471e-05, 0.9999226331710815, 1.721739499771502e-05], [0.999555766582489, 0.0004278635897208005, 1.6283875083900057e-05], [5.772786244051531e-05, 0.9999244213104248, 1.781239734555129e-05], [0.00018795760115608573, 0.999804675579071, 7.414001174765872e-06], [0.9995806813240051, 0.00040266194264404476, 1.667108699621167e-05], [5.3791794925928116e-05, 0.9999250173568726, 2.1216701497905888e-05], [0.9977070093154907, 0.0022851647809147835, 7.888548680057283e-06], [0.9992910623550415, 0.000699627969879657, 9.283478902943898e-06], [0.997282862663269, 0.0027056976687163115, 1.1440310117905028e-05], [0.00016249749751295894, 0.9998301267623901, 7.344001005549217e-06], [0.006304822396486998, 0.9936901330947876, 5.025659902457846e-06], [0.9985937476158142, 0.0013971398584544659, 9.069197403732687e-06], [5.069379403721541e-05, 0.9999241828918457, 2.5119861675193533e-05], [0.00013790839875582606, 0.9998540878295898, 7.93397703091614e-06], [0.9623594284057617, 0.03763191029429436, 8.755117960390635e-06], [0.0001198136160383001, 0.9998705387115479, 9.680319635663182e-06], [0.00010127710265805945, 0.9998891353607178, 9.572692761139479e-06], [9.16252174647525e-05, 0.9998987913131714, 9.568933819537051e-06], [0.9993884563446045, 0.0006000961293466389, 1.1463219379947986e-05], [0.08829841017723083, 0.9116931557655334, 8.465004611935001e-06], [0.0002654508571140468, 0.9997267127037048, 7.823865416867193e-06], [0.9995379447937012, 0.00044845527736470103, 1.356771190330619e-05], [0.9995412826538086, 0.0004455668677110225, 1.3238933206594083e-05], [0.002875088481232524, 0.9971191883087158, 5.7312804528919514e-06], [0.00038623239379376173, 0.9996076226234436, 6.221219791768817e-06], [0.00024176487931981683, 0.9997513890266418, 6.8585050030378625e-06], [6.37359480606392e-05, 0.9999189376831055, 1.7317370293312706e-05], [4.230131526128389e-05, 0.9999148845672607, 4.275152969057672e-05], [4.283957605366595e-05, 0.9999160766601562, 4.105396510567516e-05], [0.9995869994163513, 0.00039583526086062193, 1.7186521290568635e-05], [0.9609578847885132, 0.03902985155582428, 1.2275498193048406e-05], [0.9937499165534973, 0.006239596754312515, 1.0417621524538845e-05], [0.00013118895003572106, 0.9998602867126465, 8.501056072418578e-06], [0.9994398951530457, 0.0005494342767633498, 1.0554482287261635e-05], [0.00016325648175552487, 0.9998283386230469, 8.323185284098145e-06], [9.652240260038525e-05, 0.9998939037322998, 9.530608622299042e-06], [0.9979612827301025, 0.0020300312899053097, 8.71333759278059e-06], [6.611448043258861e-05, 0.9999196529388428, 1.417315343132941e-05], [0.9962217807769775, 0.0037688249722123146, 9.425055395695381e-06], [0.0212013628333807, 0.9787927269935608, 5.93159211348393e-06], [0.0001326827477896586, 0.9998576641082764, 9.578729077475145e-06], [0.9995498061180115, 0.0004338162252679467, 1.6381814930355176e-05], [4.792544859810732e-05, 0.9999234676361084, 2.861917528207414e-05], [0.00025331656797789037, 0.9997394680976868, 7.227177320601186e-06], [0.9988582134246826, 0.0011326459934934974, 9.150180630967952e-06], [0.33711832761764526, 0.6628689765930176, 1.2699777471425477e-05], [0.0003302438708487898, 0.9996635913848877, 6.221461262612138e-06], [0.9992700219154358, 0.0007203596760518849, 9.629548912926111e-06], [0.7384986281394958, 0.26148754358291626, 1.3840952306054533e-05], [0.00026620246353559196, 0.9997274279594421, 6.38303890809766e-06], [0.00035706383641809225, 0.9996374845504761, 5.380097263696371e-06], [8.0632402386982e-05, 0.9999041557312012, 1.52111833813251e-05], [0.9995716214179993, 0.00041054681059904397, 1.7879336155601777e-05], [0.9995635151863098, 0.0004194743523839861, 1.707911360426806e-05], [9.840136772254482e-05, 0.9998911619186401, 1.0473087968421169e-05], [7.566047133877873e-05, 0.9999133348464966, 1.0960558938677423e-05], [0.9983974099159241, 0.001594243454746902, 8.321910172526259e-06], [0.00023940774553921074, 0.999752938747406, 7.603342965012416e-06], [0.00013756171392742544, 0.9998537302017212, 8.63054083310999e-06], [0.00036778542562387884, 0.9996262788772583, 5.938116373727098e-06], [0.9975008368492126, 0.0024847856257110834, 1.4329141777125187e-05], [0.9991037249565125, 0.0008873843471519649, 8.825568329484668e-06], [0.00010736227704910561, 0.9998823404312134, 1.0331325938750524e-05], [0.9995573163032532, 0.00042530614882707596, 1.7402961020707153e-05], [0.9924347400665283, 0.007553746458142996, 1.1594544048421085e-05], [6.134244904387742e-05, 0.9999178647994995, 2.0820021745748818e-05], [8.958234684541821e-05, 0.9999010562896729, 9.383221367897931e-06], [0.9118165373802185, 0.08817070722579956, 1.28017200040631e-05], [7.989889127202332e-05, 0.999908447265625, 1.1696886758727487e-05], [8.842135866871104e-05, 0.9998987913131714, 1.281164622923825e-05], [0.9995423555374146, 0.0004408601962495595, 1.6851550753926858e-05], [6.24386448180303e-05, 0.999922513961792, 1.5019798411231022e-05], [0.9990683197975159, 0.0009239011560566723, 7.855664989619981e-06], [0.999113142490387, 0.0008781573851592839, 8.657407306600362e-06], [0.9995630383491516, 0.0004185518773738295, 1.8393675418337807e-05], [7.651904888916761e-05, 0.9999029636383057, 2.0547877284116112e-05], [0.00014945694420021027, 0.9998416900634766, 8.839636393531691e-06], [5.1728122343774885e-05, 0.9999263286590576, 2.1965046471450478e-05], [0.021398227661848068, 0.9785958528518677, 5.952191258984385e-06], [4.7294128307839856e-05, 0.9999257326126099, 2.6931116735795513e-05], [0.9994511008262634, 0.000537266256287694, 1.1676048416120466e-05], [0.9994882345199585, 0.0004981125821359456, 1.3541470252675936e-05], [7.239905244205147e-05, 0.9999144077301025, 1.3191714970162138e-05], [0.0031436781864613295, 0.99685138463974, 4.957878445566166e-06], [0.0005015207570977509, 0.9994932413101196, 5.186525868339231e-06], [4.382791667012498e-05, 0.9999203681945801, 3.578382165869698e-05], [0.00013122473319526762, 0.9998601675033569, 8.617881576356012e-06], [0.9995203018188477, 0.0004646638117264956, 1.5011694813438226e-05], [5.4181728046387434e-05, 0.9999208450317383, 2.4989558369270526e-05], [0.9985120892524719, 0.0014751781709492207, 1.2679010978899896e-05], [0.9992281198501587, 0.0007603249396197498, 1.159304338216316e-05], [0.0001822003978304565, 0.9998108744621277, 7.005260613368591e-06], [0.0005334665765985847, 0.9994609951972961, 5.4948700380919036e-06], [7.10750900907442e-05, 0.9999154806137085, 1.3411524378170725e-05], [0.00012743836850859225, 0.9998624324798584, 1.0105871297128033e-05], [0.00027428354951553047, 0.9997197985649109, 5.957782832410885e-06], [0.9970360994338989, 0.002952071139588952, 1.188987516798079e-05], [0.0014508672757074237, 0.9985445737838745, 4.546232958091423e-06], [0.00010871299309656024, 0.9998801946640015, 1.112913105316693e-05], [9.908821812132373e-05, 0.9998898506164551, 1.0994670446962118e-05], [0.9957960844039917, 0.00419048685580492, 1.3440719158097636e-05], [0.9986900687217712, 0.0013005208456888795, 9.430475074623246e-06], [0.002336879028007388, 0.9976586103439331, 4.489135335461469e-06], [0.00014057179214432836, 0.9998500347137451, 9.392178071720991e-06], [0.00011456174252089113, 0.9998745918273926, 1.0856055268959608e-05], [6.453714013332501e-05, 0.9999198913574219, 1.5568022718071006e-05], [0.0001633982319617644, 0.9998284578323364, 8.10556775832083e-06], [0.998458981513977, 0.0015322905965149403, 8.689867172506638e-06], [0.00033495138632133603, 0.9996592998504639, 5.749317097070161e-06], [0.0005000338423997164, 0.9994946718215942, 5.267837423161836e-06], [0.00014711478434037417, 0.999845027923584, 7.88304805610096e-06], [0.9995081424713135, 0.00047700144932605326, 1.4952603123674635e-05], [5.6394055718556046e-05, 0.9999265670776367, 1.7081829355447553e-05], [0.9994589686393738, 0.0005290355184115469, 1.198885638586944e-05], [8.705465006642044e-05, 0.9999023675918579, 1.0515921530895866e-05], [0.9995224475860596, 0.000462715164758265, 1.4852647836960386e-05], [0.00018086281488649547, 0.999811589717865, 7.578963959531393e-06], [0.007560355123132467, 0.9924337863922119, 5.815432359668193e-06], [0.0013747918419539928, 0.9986202716827393, 4.953426469000988e-06], [0.0002612404932733625, 0.9997325539588928, 6.210816081875237e-06], [0.0001960827794391662, 0.9997971653938293, 6.76013769407291e-06], [0.00014949077740311623, 0.9998430013656616, 7.473106052202638e-06], [0.00019942720246035606, 0.9997933506965637, 7.193322744569741e-06], [0.9994704127311707, 0.0005172915407456458, 1.2285413504287135e-05], [0.00038089073495939374, 0.9996137022972107, 5.409433470049407e-06], [0.00010046439274447039, 0.9998897314071655, 9.81902667263057e-06], [0.9994939565658569, 0.0004925422836095095, 1.3428711099550128e-05], [5.4655454732710496e-05, 0.9999266862869263, 1.86609395314008e-05], [0.9992814660072327, 0.0007087354897521436, 9.73377245827578e-06], [0.00019373715622350574, 0.9997981190681458, 8.197024726541713e-06], [0.000520151574164629, 0.9994742274284363, 5.622430762741715e-06], [0.00016891527047846466, 0.9998236298561096, 7.487785296689253e-06], [0.9995137453079224, 0.00047148551675491035, 1.4788451153435744e-05], [0.9995579123497009, 0.0004260143614374101, 1.612601408851333e-05], [6.054263940313831e-05, 0.9999231100082397, 1.6382742614950985e-05], [4.344806802691892e-05, 0.999919056892395, 3.7511908885790035e-05], [6.24093518126756e-05, 0.9999204874038696, 1.704912938294001e-05], [0.9994874000549316, 0.0004904855159111321, 2.1985493731335737e-05], [0.0006355014047585428, 0.9993589520454407, 5.6017879614955746e-06], [0.9995589852333069, 0.0004227709141559899, 1.821168916649185e-05], [8.261577022494748e-05, 0.9999046325683594, 1.26877848742879e-05], [0.0001223034196300432, 0.9998693466186523, 8.340126441908069e-06], [5.982115908409469e-05, 0.9999184608459473, 2.171481537516229e-05], [0.008271965198218822, 0.9917213320732117, 6.722629223077092e-06], [0.9995003938674927, 0.0004859610344283283, 1.356988195766462e-05], [0.9994254112243652, 0.0005603266763500869, 1.4293860658654012e-05], [0.00025862231268547475, 0.9997344613075256, 6.928831680852454e-06], [5.912798587814905e-05, 0.9999229907989502, 1.7909515008796006e-05], [6.313225458143279e-05, 0.9999197721481323, 1.7070786270778626e-05], [0.9976121187210083, 0.0023769282270222902, 1.0902512258326169e-05], [0.9995667338371277, 0.0004129341396037489, 2.0319515897426754e-05], [0.9878891110420227, 0.01209880318492651, 1.2100112144253217e-05], [0.001013235654681921, 0.9989821314811707, 4.591869583236985e-06], [0.00018663836817722768, 0.9998058676719666, 7.5246252890792675e-06], [0.0001739252475090325, 0.9998189806938171, 7.1064259827835485e-06], [0.00014323047071229666, 0.9998480081558228, 8.721937774680555e-06], [0.9995655417442322, 0.0004184595600236207, 1.591156433278229e-05], [0.8933393955230713, 0.10664799064397812, 1.2549245184345637e-05], [0.9987891316413879, 0.0012018231209367514, 9.006502295960672e-06], [5.46229348401539e-05, 0.9999217987060547, 2.3536491426057182e-05], [0.0002833509643096477, 0.9997100234031677, 6.578425654879538e-06], [0.00013932143338024616, 0.999853253364563, 7.455869763361989e-06], [0.9979037046432495, 0.0020882785320281982, 7.956811714393552e-06], [5.6161366956075653e-05, 0.9999243021011353, 1.9520246496540494e-05], [0.9993851184844971, 0.0006035069236531854, 1.1353598893037997e-05], [0.9994255304336548, 0.0005635588313452899, 1.0916643987002317e-05], [0.9995812773704529, 0.00040180678479373455, 1.6894302461878397e-05], [0.0001530737499706447, 0.9998388290405273, 8.02141676103929e-06], [0.00014104857109487057, 0.9998503923416138, 8.595111467002425e-06], [0.00017889447917696089, 0.9998142123222351, 6.951020623091608e-06], [0.9995833039283752, 0.000397063180571422, 1.9672788766911253e-05], [5.652588515658863e-05, 0.999925971031189, 1.745614645187743e-05], [9.395607048645616e-05, 0.9998949766159058, 1.1109953447885346e-05], [0.0006222595111466944, 0.9993728995323181, 4.8087831601151265e-06], [0.9974621534347534, 0.0025292711798101664, 8.596835868956987e-06], [0.006821643561124802, 0.9931730628013611, 5.267992492008489e-06], [0.9989039897918701, 0.0010853526182472706, 1.0576865861366969e-05], [0.00010204561112914234, 0.9998879432678223, 1.0010207915911451e-05], [0.00021043374727014452, 0.9997820258140564, 7.502197604480898e-06], [0.003637131303548813, 0.9963578581809998, 4.9732298066373914e-06], [0.00018268644635099918, 0.9998095631599426, 7.78332741901977e-06], [0.7573608160018921, 0.24262797832489014, 1.1203301255591214e-05], [6.476519774878398e-05, 0.9999207258224487, 1.4536032722389791e-05], [5.0910359277622774e-05, 0.9999260902404785, 2.3050841264193878e-05], [0.9994246959686279, 0.0005639518494717777, 1.1391271073080134e-05], [0.999573290348053, 0.000407963729230687, 1.8756578356260434e-05], [0.9990548491477966, 0.0009358022944070399, 9.248796231986489e-06], [9.124264033744112e-05, 0.9998983144760132, 1.044728560373187e-05], [9.816859528655186e-05, 0.9998927116394043, 9.154330655292142e-06], [0.9995868802070618, 0.000395619950722903, 1.757379504851997e-05], [0.0020957505330443382, 0.9978995323181152, 4.747875664179446e-06], [0.00010246348392684013, 0.999886155128479, 1.1411833838792518e-05], [0.00012208634871058166, 0.9998695850372314, 8.304697075800505e-06], [5.783527376479469e-05, 0.9999227523803711, 1.9368620996829122e-05], [0.9995414018630981, 0.0004420701880007982, 1.6606200006208383e-05], [5.239812162471935e-05, 0.9999179840087891, 2.9611403078888543e-05], [0.00015696632908657193, 0.9998342990875244, 8.695441465533804e-06], [5.0413636927260086e-05, 0.9999279975891113, 2.1623060092679225e-05], [0.00017887128342408687, 0.9998142123222351, 6.992868748056935e-06], [0.9995254278182983, 0.00046022472088225186, 1.4434945114771836e-05], [0.0014823762467131019, 0.9985125660896301, 5.003749265597435e-06], [5.011101166019216e-05, 0.9999257326126099, 2.4160801331163384e-05], [0.00010607418516883627, 0.9998846054077148, 9.271088856621645e-06], [8.630750380689278e-05, 0.9999022483825684, 1.1475873179733753e-05], [0.000158160095452331, 0.9998328685760498, 8.928467650548555e-06], [0.6104192733764648, 0.3895655870437622, 1.511872233095346e-05], [0.998345136642456, 0.0016464786604046822, 8.302829883177765e-06], [0.9995790123939514, 0.00040137924952432513, 1.961182351806201e-05], [0.0001872272987384349, 0.9998063445091248, 6.461993962147972e-06], [0.9994329810142517, 0.0005560655263252556, 1.0948911040031817e-05], [6.745982682332397e-05, 0.9999188184738159, 1.3709191080124583e-05], [0.9851716160774231, 0.014819856733083725, 8.552916369808372e-06], [0.9887968301773071, 0.011188759468495846, 1.4361018656927627e-05], [4.854333747061901e-05, 0.999925971031189, 2.553452577558346e-05], [4.8334852181142196e-05, 0.999924898147583, 2.6704015908762813e-05], [5.78921171836555e-05, 0.9999257326126099, 1.6372994650737382e-05], [0.00019524978415574878, 0.9997981190681458, 6.607854629692156e-06], [0.9993463158607483, 0.000643165607471019, 1.0498672963876743e-05], [5.7737925089895725e-05, 0.9999251365661621, 1.711962431727443e-05], [6.326271977741271e-05, 0.9999222755432129, 1.4477010154223535e-05], [0.00014270869723986834, 0.9998490810394287, 8.171489753294736e-06], [0.0015938340220600367, 0.9984013438224792, 4.877431365457596e-06], [5.524231164599769e-05, 0.999923825263977, 2.0926743673044257e-05], [8.479702955810353e-05, 0.9999034404754639, 1.180628805741435e-05], [0.00032599762198515236, 0.9996684789657593, 5.5167110986076295e-06], [0.9993615746498108, 0.000627229455858469, 1.122754838434048e-05], [8.033698395593092e-05, 0.9999072551727295, 1.2371845514280722e-05], [0.00045563417370431125, 0.9995386600494385, 5.693599632650148e-06], [0.798678457736969, 0.20131023228168488, 1.124585196521366e-05], [6.285377457970753e-05, 0.999920129776001, 1.6977473933366127e-05], [8.826449629850686e-05, 0.9998998641967773, 1.1850792361656204e-05], [6.748957093805075e-05, 0.9999181032180786, 1.4382919289346319e-05], [0.9995007514953613, 0.0004861767520196736, 1.3153199688531458e-05], [6.6998356487602e-05, 0.9999172687530518, 1.5719349903520197e-05], [0.9967359900474548, 0.0032520864624530077, 1.1833568350994028e-05], [0.00021952539100311697, 0.9997740387916565, 6.455250058934325e-06], [0.9982663989067078, 0.0017211218364536762, 1.2515446542238351e-05], [0.0001256271352758631, 0.9998652935028076, 9.061281161848456e-06], [9.107952791964635e-05, 0.9998953342437744, 1.3602185390482191e-05], [0.0007299393182620406, 0.9992647767066956, 5.3027511057734955e-06], [0.000241909729084, 0.9997524619102478, 5.641722509608371e-06], [4.486048055696301e-05, 0.9999208450317383, 3.4234224585816264e-05], [0.0003837798722088337, 0.9996100068092346, 6.214847871888196e-06], [3.99082746298518e-05, 0.9999029636383057, 5.705947114620358e-05], [0.0007712914375588298, 0.9992225170135498, 6.18209014646709e-06], [5.6634293287061155e-05, 0.9999203681945801, 2.3046357455314137e-05], [5.810893708257936e-05, 0.9999226331710815, 1.9210599930374883e-05], [0.9986977577209473, 0.0012943973997607827, 7.814716809662059e-06], [0.00011299364268779755, 0.9998785257339478, 8.46163402457023e-06], [5.729801705456339e-05, 0.9999234676361084, 1.9193272237316705e-05], [0.0009900953155010939, 0.9990049004554749, 4.977367552783107e-06], [0.9995743632316589, 0.00040890913805924356, 1.671260906732641e-05], [7.953105523483828e-05, 0.9999098777770996, 1.0556011147855315e-05], [6.124880746938288e-05, 0.9999209642410278, 1.783461993909441e-05], [0.00048635154962539673, 0.9995077848434448, 5.807959041703725e-06], [0.9995726943016052, 0.00041135260835289955, 1.595101275597699e-05], [7.103782263584435e-05, 0.9999116659164429, 1.7250635210075416e-05], [0.999248206615448, 0.0007420274196192622, 9.755546670930926e-06], [0.00015940307639539242, 0.9998315572738647, 9.014699571707752e-06], [6.072389805922285e-05, 0.999923586845398, 1.566259925311897e-05], [5.292104833642952e-05, 0.9999244213104248, 2.2611600797972642e-05], [0.0002680408942978829, 0.9997262358665466, 5.6643793868715875e-06], [0.0002939446421805769, 0.9996997117996216, 6.413584287656704e-06], [0.9979812502861023, 0.002011528704315424, 7.204037501651328e-06], [0.9800416827201843, 0.01994800567626953, 1.0265071978210472e-05], [0.9992356300354004, 0.0007509473362006247, 1.3412633961706888e-05], [8.845201227813959e-05, 0.9998992681503296, 1.2257243724889122e-05], [0.0016957760090008378, 0.9982996582984924, 4.595161044562701e-06], [5.186815178603865e-05, 0.999925971031189, 2.2115935280453414e-05], [6.360183033393696e-05, 0.9999220371246338, 1.4337124412122648e-05], [0.9991965889930725, 0.0007941393996588886, 9.284141015086789e-06], [0.00012937256542500108, 0.999862551689148, 8.0835961853154e-06], [0.9995087385177612, 0.0004786513454746455, 1.2590076948981732e-05], [0.9994662404060364, 0.0005219297017902136, 1.1854071999550797e-05], [0.999180257320404, 0.0008091063937172294, 1.057955978467362e-05], [7.040428317850456e-05, 0.9999159574508667, 1.3665110600413755e-05], [7.399330934276804e-05, 0.9999129772186279, 1.2967684597242624e-05], [5.920827970840037e-05, 0.999924898147583, 1.5873491065576673e-05], [0.9994056224822998, 0.0005831691087223589, 1.1154869753227104e-05], [0.9894765615463257, 0.010511989705264568, 1.149496983998688e-05], [4.004023503512144e-05, 0.9999016523361206, 5.8269033615943044e-05], [0.9995360374450684, 0.0004486798425205052, 1.5241792425513268e-05], [0.9972220659255981, 0.002768579637631774, 9.336073162558023e-06], [0.999519944190979, 0.0004659912083297968, 1.4074902537686285e-05], [0.9987892508506775, 0.0012007767800241709, 9.9765293271048e-06], [0.9722145199775696, 0.027775071561336517, 1.0403350643173326e-05], [0.001998022897168994, 0.9979968667030334, 5.105614491185406e-06], [0.0006852115620858967, 0.9993096590042114, 5.0794346861948725e-06], [0.9995537400245667, 0.0004293026577215642, 1.6943502487265505e-05], [0.000279348052572459, 0.9997139573097229, 6.664692136837402e-06], [0.00020130432676523924, 0.9997891783714294, 9.54372535488801e-06], [0.9975137710571289, 0.0024750109296292067, 1.1173790881002788e-05], [0.00016976897313725203, 0.999821126461029, 9.128053534368519e-06], [0.9995551705360413, 0.00042793064494617283, 1.6860722098499537e-05], [7.354295667028055e-05, 0.9999105930328369, 1.5822963177924976e-05], [6.495508569059893e-05, 0.9999204874038696, 1.4573772205039859e-05], [0.006246604956686497, 0.9937485456466675, 4.898716269963188e-06], [4.957513010594994e-05, 0.9999258518218994, 2.4521439627278596e-05], [0.9995393753051758, 0.00044427887769415975, 1.63138556672493e-05], [0.9994439482688904, 0.0005423804395832121, 1.3752322956861462e-05], [0.00016968137060757726, 0.9998226761817932, 7.652854947082233e-06], [0.9890903830528259, 0.010899913497269154, 9.719332410895731e-06], [6.302473047981039e-05, 0.9999192953109741, 1.7711739928927273e-05], [0.998871386051178, 0.0011210002703592181, 7.582921625726158e-06], [0.00011077764065703377, 0.9998787641525269, 1.0457539246999659e-05], [0.00015414319932460785, 0.999839186668396, 6.614803169213701e-06], [0.0028938413597643375, 0.9971012473106384, 4.87909028379363e-06], [4.881144923274405e-05, 0.9999264478683472, 2.4771352400421165e-05], [0.9992289543151855, 0.0007618573145009577, 9.186187526211143e-06], [8.810873259790242e-05, 0.9998997449874878, 1.2079202861059457e-05], [0.9975860118865967, 0.0024054893292486668, 8.394033102376852e-06], [0.9995737671852112, 0.00040690507739782333, 1.9328654161654413e-05], [0.0008015938219614327, 0.9991936087608337, 4.800919668923598e-06], [7.429994730046019e-05, 0.9999067783355713, 1.888408041850198e-05], [0.00033948422060348094, 0.9996546506881714, 5.892949047847651e-06], [0.00016713679360691458, 0.9998248219490051, 8.117110155581031e-06], [7.714686944382265e-05, 0.9999040365219116, 1.8824674043571576e-05], [6.901489541633055e-05, 0.9999141693115234, 1.678892658674158e-05], [0.999578058719635, 0.0004050901625305414, 1.680099558143411e-05], [0.0001751391391735524, 0.9998170733451843, 7.849063877074514e-06], [0.0001236651005456224, 0.9998664855957031, 9.868015695246868e-06], [0.9411215782165527, 0.05886777117848396, 1.071373753802618e-05], [0.000271974946372211, 0.9997217059135437, 6.303418558673002e-06], [0.9995081424713135, 0.0004793979460373521, 1.2465243344195187e-05], [0.0002120085118804127, 0.9997817873954773, 6.164585556689417e-06], [0.00013625384599436074, 0.999855637550354, 8.145479114318732e-06], [9.80430340860039e-05, 0.9998906850814819, 1.1229979463678319e-05], [0.00010424688662169501, 0.9998859167098999, 9.812099051487166e-06], [4.292720404919237e-05, 0.9999176263809204, 3.9403672417392954e-05], [0.999491810798645, 0.0004950920701958239, 1.3162984032533132e-05], [0.0004428285756148398, 0.9995512366294861, 5.890946340514347e-06], [7.727220508968458e-05, 0.9999109506607056, 1.173584496427793e-05], [0.9995717406272888, 0.0004100500955246389, 1.825748404371552e-05], [6.272742029977962e-05, 0.9999209642410278, 1.6282259821309708e-05], [0.9992551207542419, 0.0007347782957367599, 1.0079950698127504e-05], [0.00037854319089092314, 0.9996157884597778, 5.592422894551419e-06], [0.002546643139794469, 0.9974491000175476, 4.2829169615288265e-06], [0.9983000159263611, 0.00168856221716851, 1.1406047633499838e-05], [0.9994753003120422, 0.0005128414486534894, 1.18639745778637e-05], [4.052071744808927e-05, 0.9998968839645386, 6.262638635234907e-05], [6.15129029029049e-05, 0.999921441078186, 1.7005755580612458e-05], [0.00013856141595169902, 0.9998524188995361, 9.04899752640631e-06], [0.00178307737223804, 0.9982123374938965, 4.619006176653784e-06], [6.508275691885501e-05, 0.9999185800552368, 1.635809530853294e-05], [6.598662002943456e-05, 0.9999151229858398, 1.8901211660704575e-05], [0.9988340735435486, 0.0011569258058443666, 9.01453950064024e-06], [4.4843502109870315e-05, 0.9999228715896606, 3.231576920370571e-05], [4.188083767076023e-05, 0.9999043941497803, 5.370508733903989e-05], [3.987905802205205e-05, 0.9998974800109863, 6.260570080485195e-05], [0.9995848536491394, 0.0003971732221543789, 1.8028087652055547e-05], [4.658153193304315e-05, 0.9999253749847412, 2.8061187549610622e-05], [0.9995778203010559, 0.00040325932786799967, 1.8930437363451347e-05], [0.9994472861289978, 0.0005407707649283111, 1.1919709322683048e-05], [0.0001930872822413221, 0.9998006224632263, 6.266764103202149e-06], [0.00042113495874218643, 0.9995737671852112, 5.12983979206183e-06], [0.9995250701904297, 0.00046185817336663604, 1.3093532288621645e-05], [7.074687164276838e-05, 0.9999169111251831, 1.2299484296818264e-05], [0.0014766419772058725, 0.9985173344612122, 5.994892035232624e-06], [0.00014030415331944823, 0.9998506307601929, 9.017382581077982e-06], [5.644670090987347e-05, 0.9999251365661621, 1.836846422520466e-05], [0.00011790834105340764, 0.9998729228973389, 9.177567335427739e-06], [0.9995384216308594, 0.00044567478471435606, 1.600507675902918e-05], [0.19267229735851288, 0.8073176145553589, 1.0107866728503723e-05], [6.348922761389986e-05, 0.9999200105667114, 1.643489667912945e-05], [9.29463712964207e-05, 0.9998973608016968, 9.673657586972695e-06], [8.511017222190276e-05, 0.9999046325683594, 1.0237567039439455e-05], [0.00011286202789051458, 0.9998774528503418, 9.669831342762336e-06], [0.0001123373003792949, 0.9998760223388672, 1.1606791304075159e-05], [0.9995412826538086, 0.0004448701220098883, 1.3854317330697086e-05], [0.00032432106672786176, 0.9996697902679443, 5.8800815168069676e-06], [0.0012593260034918785, 0.9987354874610901, 5.186999260331504e-06], [4.171521504758857e-05, 0.9999082088470459, 5.0098762585548684e-05], [5.55823280592449e-05, 0.9999250173568726, 1.9386978237889707e-05], [0.00019036773301195353, 0.9998027682304382, 6.825904165452812e-06], [9.673870954429731e-05, 0.9998921155929565, 1.109230379370274e-05], [5.944718577666208e-05, 0.9999244213104248, 1.6094907550723292e-05], [0.9987198114395142, 0.0012719299411401153, 8.280509064206854e-06], [7.584429840790108e-05, 0.9999121427536011, 1.205732496600831e-05], [7.014284346951172e-05, 0.9999130964279175, 1.6800728189991787e-05], [7.944051321828738e-05, 0.9999076128005981, 1.2935883205500431e-05], [8.574214007239789e-05, 0.9998990297317505, 1.5198229448287748e-05], [0.9963586926460266, 0.003627175698056817, 1.4167006156640127e-05], [9.993567073252052e-05, 0.9998897314071655, 1.026633344736183e-05], [6.861844303784892e-05, 0.9999160766601562, 1.534566399641335e-05], [0.0011616788106039166, 0.998832643032074, 5.715693077945616e-06], [0.005138063803315163, 0.9948573112487793, 4.638556674763095e-06], [0.0002376613992964849, 0.9997559189796448, 6.459979431383545e-06], [0.9988465309143066, 0.001143315457738936, 1.0174736416956875e-05], [8.214807894546539e-05, 0.9999057054519653, 1.2080612577847205e-05], [0.9994997978210449, 0.00048668283852748573, 1.348579735349631e-05], [0.9983674883842468, 0.0016224902356043458, 9.945258170773741e-06], [0.9995538592338562, 0.0004312269447837025, 1.4921675756340846e-05], [4.915728641208261e-05, 0.9999256134033203, 2.524063893361017e-05], [0.0001008991603157483, 0.9998887777328491, 1.0256479981762823e-05], [0.0004755011177621782, 0.9995193481445312, 5.139853783475701e-06], [0.999572217464447, 0.00041127708391286433, 1.6455007425975055e-05], [0.0010420512408018112, 0.998953104019165, 4.864217316935537e-06], [0.9995367527008057, 0.00044675430399365723, 1.66102108778432e-05], [0.0025754119269549847, 0.9974201917648315, 4.4390721996023785e-06], [7.123095565475523e-05, 0.9999145269393921, 1.4189377907314338e-05], [6.7873414081987e-05, 0.9999188184738159, 1.3321624464879278e-05], [8.939182589529082e-05, 0.9998996257781982, 1.095530933525879e-05], [0.00048436110955663025, 0.9995100498199463, 5.612442691926844e-06], [0.9993191957473755, 0.0006700858939439058, 1.0734576790127903e-05], [4.2736784962471575e-05, 0.9998703002929688, 8.698147576069459e-05], [6.336595834000036e-05, 0.9999182224273682, 1.836451883718837e-05], [0.00011289698886685073, 0.9998772144317627, 9.841872270044405e-06], [0.0006358330720104277, 0.9993587136268616, 5.415950454334961e-06], [0.9995802044868469, 0.0004014156584162265, 1.8391499907011166e-05], [5.7344492233823985e-05, 0.9999256134033203, 1.7084241335396655e-05], [0.0001798366429284215, 0.9998121857643127, 8.030509889067616e-06], [6.278346700128168e-05, 0.9999204874038696, 1.6700945707270876e-05]]\n"]}]},{"cell_type":"code","source":["def num_to_hate(label):\n","    label_dict = {0: \"none\", 1: \"hate\"}\n","    str_label = []\n","\n","    for i, v in enumerate(label):\n","        str_label.append([i,label_dict[v]])\n","    \n","    return str_label\n","\n","answer = num_to_hate(pred_answer)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYsIvdnUvVze","executionInfo":{"status":"ok","timestamp":1646033370306,"user_tz":-540,"elapsed":311,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"1b1836a3-e06f-4660-b10f-546869144fa9"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 'none'], [1, 'none'], [2, 'hate'], [3, 'hate'], [4, 'hate'], [5, 'hate'], [6, 'hate'], [7, 'hate'], [8, 'hate'], [9, 'none'], [10, 'hate'], [11, 'hate'], [12, 'none'], [13, 'hate'], [14, 'none'], [15, 'hate'], [16, 'hate'], [17, 'hate'], [18, 'none'], [19, 'none'], [20, 'hate'], [21, 'hate'], [22, 'hate'], [23, 'hate'], [24, 'hate'], [25, 'hate'], [26, 'hate'], [27, 'none'], [28, 'none'], [29, 'none'], [30, 'hate'], [31, 'hate'], [32, 'hate'], [33, 'hate'], [34, 'none'], [35, 'hate'], [36, 'hate'], [37, 'none'], [38, 'none'], [39, 'none'], [40, 'hate'], [41, 'hate'], [42, 'hate'], [43, 'none'], [44, 'none'], [45, 'hate'], [46, 'hate'], [47, 'hate'], [48, 'none'], [49, 'hate'], [50, 'hate'], [51, 'none'], [52, 'hate'], [53, 'hate'], [54, 'hate'], [55, 'hate'], [56, 'hate'], [57, 'none'], [58, 'none'], [59, 'hate'], [60, 'hate'], [61, 'none'], [62, 'none'], [63, 'hate'], [64, 'hate'], [65, 'hate'], [66, 'hate'], [67, 'hate'], [68, 'none'], [69, 'hate'], [70, 'none'], [71, 'hate'], [72, 'none'], [73, 'hate'], [74, 'hate'], [75, 'none'], [76, 'none'], [77, 'hate'], [78, 'hate'], [79, 'hate'], [80, 'hate'], [81, 'hate'], [82, 'hate'], [83, 'none'], [84, 'hate'], [85, 'none'], [86, 'hate'], [87, 'hate'], [88, 'hate'], [89, 'none'], [90, 'none'], [91, 'hate'], [92, 'hate'], [93, 'hate'], [94, 'hate'], [95, 'hate'], [96, 'hate'], [97, 'hate'], [98, 'none'], [99, 'hate'], [100, 'none'], [101, 'hate'], [102, 'hate'], [103, 'none'], [104, 'hate'], [105, 'none'], [106, 'hate'], [107, 'none'], [108, 'hate'], [109, 'none'], [110, 'none'], [111, 'hate'], [112, 'hate'], [113, 'hate'], [114, 'hate'], [115, 'hate'], [116, 'hate'], [117, 'none'], [118, 'none'], [119, 'hate'], [120, 'none'], [121, 'none'], [122, 'hate'], [123, 'hate'], [124, 'hate'], [125, 'hate'], [126, 'hate'], [127, 'hate'], [128, 'none'], [129, 'none'], [130, 'none'], [131, 'hate'], [132, 'none'], [133, 'hate'], [134, 'hate'], [135, 'hate'], [136, 'hate'], [137, 'none'], [138, 'none'], [139, 'hate'], [140, 'none'], [141, 'hate'], [142, 'none'], [143, 'none'], [144, 'none'], [145, 'hate'], [146, 'none'], [147, 'hate'], [148, 'hate'], [149, 'hate'], [150, 'hate'], [151, 'none'], [152, 'none'], [153, 'hate'], [154, 'hate'], [155, 'none'], [156, 'hate'], [157, 'hate'], [158, 'hate'], [159, 'none'], [160, 'none'], [161, 'hate'], [162, 'none'], [163, 'hate'], [164, 'hate'], [165, 'hate'], [166, 'hate'], [167, 'hate'], [168, 'hate'], [169, 'none'], [170, 'hate'], [171, 'none'], [172, 'none'], [173, 'none'], [174, 'hate'], [175, 'hate'], [176, 'hate'], [177, 'hate'], [178, 'hate'], [179, 'none'], [180, 'none'], [181, 'hate'], [182, 'hate'], [183, 'hate'], [184, 'hate'], [185, 'hate'], [186, 'none'], [187, 'hate'], [188, 'none'], [189, 'none'], [190, 'hate'], [191, 'hate'], [192, 'hate'], [193, 'hate'], [194, 'hate'], [195, 'hate'], [196, 'hate'], [197, 'hate'], [198, 'hate'], [199, 'none'], [200, 'none'], [201, 'hate'], [202, 'hate'], [203, 'hate'], [204, 'hate'], [205, 'hate'], [206, 'none'], [207, 'hate'], [208, 'hate'], [209, 'hate'], [210, 'none'], [211, 'hate'], [212, 'none'], [213, 'hate'], [214, 'none'], [215, 'hate'], [216, 'hate'], [217, 'hate'], [218, 'hate'], [219, 'hate'], [220, 'hate'], [221, 'hate'], [222, 'none'], [223, 'hate'], [224, 'hate'], [225, 'none'], [226, 'hate'], [227, 'none'], [228, 'hate'], [229, 'hate'], [230, 'hate'], [231, 'none'], [232, 'none'], [233, 'hate'], [234, 'hate'], [235, 'hate'], [236, 'none'], [237, 'none'], [238, 'none'], [239, 'hate'], [240, 'hate'], [241, 'hate'], [242, 'hate'], [243, 'none'], [244, 'none'], [245, 'hate'], [246, 'hate'], [247, 'hate'], [248, 'hate'], [249, 'none'], [250, 'hate'], [251, 'hate'], [252, 'hate'], [253, 'hate'], [254, 'hate'], [255, 'none'], [256, 'hate'], [257, 'hate'], [258, 'hate'], [259, 'hate'], [260, 'hate'], [261, 'none'], [262, 'hate'], [263, 'none'], [264, 'hate'], [265, 'none'], [266, 'hate'], [267, 'hate'], [268, 'hate'], [269, 'none'], [270, 'hate'], [271, 'hate'], [272, 'none'], [273, 'none'], [274, 'none'], [275, 'none'], [276, 'hate'], [277, 'hate'], [278, 'hate'], [279, 'hate'], [280, 'none'], [281, 'hate'], [282, 'hate'], [283, 'none'], [284, 'none'], [285, 'none'], [286, 'hate'], [287, 'hate'], [288, 'none'], [289, 'hate'], [290, 'hate'], [291, 'hate'], [292, 'hate'], [293, 'none'], [294, 'hate'], [295, 'hate'], [296, 'hate'], [297, 'hate'], [298, 'none'], [299, 'hate'], [300, 'hate'], [301, 'hate'], [302, 'hate'], [303, 'hate'], [304, 'hate'], [305, 'none'], [306, 'none'], [307, 'hate'], [308, 'none'], [309, 'hate'], [310, 'none'], [311, 'hate'], [312, 'hate'], [313, 'hate'], [314, 'hate'], [315, 'hate'], [316, 'none'], [317, 'hate'], [318, 'hate'], [319, 'hate'], [320, 'hate'], [321, 'hate'], [322, 'hate'], [323, 'hate'], [324, 'none'], [325, 'hate'], [326, 'hate'], [327, 'none'], [328, 'hate'], [329, 'hate'], [330, 'hate'], [331, 'none'], [332, 'hate'], [333, 'hate'], [334, 'hate'], [335, 'none'], [336, 'hate'], [337, 'hate'], [338, 'hate'], [339, 'hate'], [340, 'hate'], [341, 'hate'], [342, 'hate'], [343, 'hate'], [344, 'hate'], [345, 'hate'], [346, 'none'], [347, 'hate'], [348, 'hate'], [349, 'hate'], [350, 'none'], [351, 'hate'], [352, 'hate'], [353, 'hate'], [354, 'none'], [355, 'hate'], [356, 'none'], [357, 'hate'], [358, 'hate'], [359, 'hate'], [360, 'hate'], [361, 'hate'], [362, 'none'], [363, 'none'], [364, 'none'], [365, 'hate'], [366, 'hate'], [367, 'hate'], [368, 'hate'], [369, 'none'], [370, 'hate'], [371, 'none'], [372, 'none'], [373, 'hate'], [374, 'hate'], [375, 'hate'], [376, 'hate'], [377, 'none'], [378, 'none'], [379, 'hate'], [380, 'none'], [381, 'none'], [382, 'none'], [383, 'none'], [384, 'none'], [385, 'hate'], [386, 'hate'], [387, 'none'], [388, 'hate'], [389, 'none'], [390, 'hate'], [391, 'hate'], [392, 'none'], [393, 'hate'], [394, 'hate'], [395, 'none'], [396, 'hate'], [397, 'none'], [398, 'none'], [399, 'hate'], [400, 'hate'], [401, 'hate'], [402, 'none'], [403, 'hate'], [404, 'hate'], [405, 'hate'], [406, 'hate'], [407, 'none'], [408, 'hate'], [409, 'none'], [410, 'none'], [411, 'hate'], [412, 'hate'], [413, 'hate'], [414, 'hate'], [415, 'hate'], [416, 'hate'], [417, 'none'], [418, 'hate'], [419, 'hate'], [420, 'none'], [421, 'hate'], [422, 'none'], [423, 'hate'], [424, 'hate'], [425, 'hate'], [426, 'hate'], [427, 'hate'], [428, 'none'], [429, 'hate'], [430, 'hate'], [431, 'none'], [432, 'hate'], [433, 'none'], [434, 'hate'], [435, 'none'], [436, 'none'], [437, 'none'], [438, 'hate'], [439, 'hate'], [440, 'hate'], [441, 'hate'], [442, 'hate'], [443, 'hate'], [444, 'none'], [445, 'hate'], [446, 'hate'], [447, 'hate'], [448, 'none'], [449, 'hate'], [450, 'none'], [451, 'none'], [452, 'hate'], [453, 'hate'], [454, 'none'], [455, 'hate'], [456, 'hate'], [457, 'hate'], [458, 'hate'], [459, 'hate'], [460, 'none'], [461, 'hate'], [462, 'hate'], [463, 'hate'], [464, 'hate'], [465, 'hate'], [466, 'hate'], [467, 'none'], [468, 'hate'], [469, 'hate'], [470, 'hate'], [471, 'hate'], [472, 'hate'], [473, 'hate'], [474, 'hate'], [475, 'none'], [476, 'hate'], [477, 'hate'], [478, 'hate'], [479, 'hate'], [480, 'none'], [481, 'hate'], [482, 'hate'], [483, 'hate'], [484, 'hate'], [485, 'hate'], [486, 'none'], [487, 'hate'], [488, 'none'], [489, 'hate'], [490, 'none'], [491, 'hate'], [492, 'hate'], [493, 'hate'], [494, 'none'], [495, 'none'], [496, 'none'], [497, 'none'], [498, 'hate'], [499, 'hate'], [500, 'hate'], [501, 'hate'], [502, 'none'], [503, 'hate'], [504, 'hate'], [505, 'hate'], [506, 'hate'], [507, 'none'], [508, 'hate'], [509, 'hate'], [510, 'hate']]\n"]}]},{"cell_type":"code","source":["df_hate = pd.DataFrame(answer, columns=['ID', 'hate'])\n","df_hate.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"actbhBCbt8vG","executionInfo":{"status":"ok","timestamp":1646033377050,"user_tz":-540,"elapsed":324,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"fa872b8d-0c12-4964-8b88-5e83cefcf99b"},"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-bfb2e744-7d0c-4685-a18c-dc2a0967c233\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfb2e744-7d0c-4685-a18c-dc2a0967c233')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bfb2e744-7d0c-4685-a18c-dc2a0967c233 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bfb2e744-7d0c-4685-a18c-dc2a0967c233');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  hate\n","508  508  hate\n","509  509  hate\n","510  510  hate"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/seperated_submit01.csv') # 아까 저장한 bias csv 파일 load\n","df.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"rfmH140OvK51","executionInfo":{"status":"ok","timestamp":1646033389517,"user_tz":-540,"elapsed":279,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"c2e6d213-1e17-4201-9145-d2e1de74e020"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7fde870e-39b2-410c-9a92-8fc5e1b85dbe\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>bias</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>others</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>others</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>others</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fde870e-39b2-410c-9a92-8fc5e1b85dbe')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7fde870e-39b2-410c-9a92-8fc5e1b85dbe button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7fde870e-39b2-410c-9a92-8fc5e1b85dbe');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID    bias\n","508  508  others\n","509  509  others\n","510  510  others"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["df['hate'] = df_hate['hate']  # df 에 hate column 을 만들어서 hate 값 추가\n","df.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"jNJIbhMfvuVV","executionInfo":{"status":"ok","timestamp":1646033394498,"user_tz":-540,"elapsed":286,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a5b6e538-101d-4d8c-ccb2-7e86aa01a3fc"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a94c9aab-8043-4221-9315-8254722a4fcb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a94c9aab-8043-4221-9315-8254722a4fcb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a94c9aab-8043-4221-9315-8254722a4fcb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a94c9aab-8043-4221-9315-8254722a4fcb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID    bias  hate\n","508  508  others  hate\n","509  509  others  hate\n","510  510  others  hate"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["# bias, hate 값이 들어간 최종 csv 파일 \n","df.to_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/seperated_submit02.csv', index=False) # 매번 파일 이름 바꿔주자\n","\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9od45aJwV-U","executionInfo":{"status":"ok","timestamp":1646033401867,"user_tz":-540,"elapsed":292,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a591137d-c2a6-40b0-b966-beec8ab0aa47"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["      ID    bias  hate\n","0      0    none  none\n","1      1    none  none\n","2      2    none  hate\n","3      3  others  hate\n","4      4  others  hate\n","..   ...     ...   ...\n","506  506    none  hate\n","507  507    none  none\n","508  508  others  hate\n","509  509  others  hate\n","510  510  others  hate\n","\n","[511 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["# 이제 제출하러 ㄱㄱ "],"metadata":{"id":"uMdnneJHwqbv"},"execution_count":null,"outputs":[]}]}