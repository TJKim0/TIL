{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_mybaseline.ipynb","provenance":[{"file_id":"1e3Iz0qLzv23t7rRhsptpuB8TEowBKAyR","timestamp":1646028124658},{"file_id":"1J5RZY_o54NFTidm1EO6rlITJyLw8MsPm","timestamp":1645668899382}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP/vgjKawquQ1sjDgv7gT/p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2865cb4aeacb45a49fb2548799a27416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a916b56399a3456ebaefd7cc6ee3ec05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14962e30ce324e6bb54487cea9b45344","IPY_MODEL_7355b4c4ed3c44fc96420502a0ada722","IPY_MODEL_00516c747e6c404d969f84bdeb3155bb"]}},"a916b56399a3456ebaefd7cc6ee3ec05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14962e30ce324e6bb54487cea9b45344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9fa58be7bb344c38eb64a7dab857fc4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7621eb972214fb19b776286994a0226"}},"7355b4c4ed3c44fc96420502a0ada722":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a9e3ee9e8984bac95bb002dfffc35f9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":375,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":375,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fdf18814230f4892a35678c90d140fd8"}},"00516c747e6c404d969f84bdeb3155bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8a4bea7410cf42528627ed3c73f77602","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 375/375 [00:00&lt;00:00, 12.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b353b0fe55d4980b6b45d05f751c4f9"}},"e9fa58be7bb344c38eb64a7dab857fc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7621eb972214fb19b776286994a0226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a9e3ee9e8984bac95bb002dfffc35f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fdf18814230f4892a35678c90d140fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a4bea7410cf42528627ed3c73f77602":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b353b0fe55d4980b6b45d05f751c4f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abd235a1158942e6955f1c98e8373253":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf6204ff03064af9ab2513c71e12c380","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d024d61371db45e4b7bbada51e2a74a9","IPY_MODEL_1cf7fae32d2040509bf29f4910c88602","IPY_MODEL_00d01b315d584b02af40294ad35004d7"]}},"bf6204ff03064af9ab2513c71e12c380":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d024d61371db45e4b7bbada51e2a74a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_596ef140c93d426faabaafd52a9012ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9365fe7e0184db6a3ef986cd6f7ea5a"}},"1cf7fae32d2040509bf29f4910c88602":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c581fd142b3e478286bd153e38d28620","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":248477,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":248477,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aae9dd27487b422fa6ea57a5399cb123"}},"00d01b315d584b02af40294ad35004d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_564308e42f7f432585e986599477b330","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243k/243k [00:00&lt;00:00, 362kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2852007af9941a292206fdef588c391"}},"596ef140c93d426faabaafd52a9012ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9365fe7e0184db6a3ef986cd6f7ea5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c581fd142b3e478286bd153e38d28620":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aae9dd27487b422fa6ea57a5399cb123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"564308e42f7f432585e986599477b330":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2852007af9941a292206fdef588c391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"802923ca8baa4a019b0da040d68b9ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fd39f4c10a284dd9a76f6131b828e208","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa0f17a8214c40a6b5c6eccfcf36e5af","IPY_MODEL_8eb52fbba48b412a9692b68a8bf39c59","IPY_MODEL_0666d3cc60cf4699afd772eaaec83fa1"]}},"fd39f4c10a284dd9a76f6131b828e208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa0f17a8214c40a6b5c6eccfcf36e5af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be9d28fe595841be9d530f0a0975041f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_840511e242c64706a2d2252edb23c5c8"}},"8eb52fbba48b412a9692b68a8bf39c59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_067ff58f781745f1b013d4330909a928","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":751504,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":751504,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a9be92087304c7e99e2a5e509243a27"}},"0666d3cc60cf4699afd772eaaec83fa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_acaa34475dbc4fef83039e4a70b7d88e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 734k/734k [00:00&lt;00:00, 661kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e367890027024b948a2d7d685de26a51"}},"be9d28fe595841be9d530f0a0975041f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"840511e242c64706a2d2252edb23c5c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"067ff58f781745f1b013d4330909a928":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a9be92087304c7e99e2a5e509243a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acaa34475dbc4fef83039e4a70b7d88e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e367890027024b948a2d7d685de26a51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f74b50e82104dbcb84c96c5820f9b99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5916cb3116c94e339316a7fe9ced336f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_872a906a1bad4957b419c30d6335448b","IPY_MODEL_dbc480bd7aed483e8a53a238c1662c19","IPY_MODEL_33953cf3e56a4d3d962508a1e792098a"]}},"5916cb3116c94e339316a7fe9ced336f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"872a906a1bad4957b419c30d6335448b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d42131ca9696453d9f4ab967e92bf7c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59d56b929e114aa096c8d2fd6b9c513f"}},"dbc480bd7aed483e8a53a238c1662c19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_72360c6abd0e49d8a4d0b9db8298b581","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_680f5cc07b064552b5b78d51e2886fde"}},"33953cf3e56a4d3d962508a1e792098a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c48bf92044964de680da0ec2b853e039","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 173/173 [00:00&lt;00:00, 3.99kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2483e61cdea040dc9812fcfcc15da939"}},"d42131ca9696453d9f4ab967e92bf7c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"59d56b929e114aa096c8d2fd6b9c513f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72360c6abd0e49d8a4d0b9db8298b581":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"680f5cc07b064552b5b78d51e2886fde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c48bf92044964de680da0ec2b853e039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2483e61cdea040dc9812fcfcc15da939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a17a84fb1a6423f8b4068a4d163f9b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_550e1917b11442ba88970395338fca82","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dc4bf41c7fa84920875af28ba1856e7b","IPY_MODEL_3ec52688b66547f49038b085272d5fa3","IPY_MODEL_40ad55d90ddd4e648ccc59d079155571"]}},"550e1917b11442ba88970395338fca82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc4bf41c7fa84920875af28ba1856e7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8192228f4c5f4c929166a594ce1d4979","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66633ae2c00f4a4690294de4f30345b0"}},"3ec52688b66547f49038b085272d5fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76d8015269ea4d788bdc1111d20f1937","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":547,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":547,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be064cb9c5444196b95a1d4a74c79f5e"}},"40ad55d90ddd4e648ccc59d079155571":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7bc854e01b24793ba68384dc80b809d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 547/547 [00:00&lt;00:00, 17.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2b09c55be0542de98a1dbd187957f74"}},"8192228f4c5f4c929166a594ce1d4979":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"66633ae2c00f4a4690294de4f30345b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76d8015269ea4d788bdc1111d20f1937":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"be064cb9c5444196b95a1d4a74c79f5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7bc854e01b24793ba68384dc80b809d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2b09c55be0542de98a1dbd187957f74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6fa50f9ab95a4b77960eb8659ab2e84d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0749ad2437434583b70b121695123215","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91b18e9feb6346769de4dd1fbc3ae815","IPY_MODEL_6332b0788753401d8bb12fefe712fa38","IPY_MODEL_fb1e919f7ca5417c9234fb1a50f19471"]}},"0749ad2437434583b70b121695123215":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91b18e9feb6346769de4dd1fbc3ae815":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0e178031ff304a22885a58d882a62153","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dcfbdb82e54e42b29a6a57d2fdda4186"}},"6332b0788753401d8bb12fefe712fa38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52175a19024a4c8e9a822f66029117e8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1346930258,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1346930258,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f5dcf1641014848a6aa4f06601cbbdb"}},"fb1e919f7ca5417c9234fb1a50f19471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_281b92d2cf6b4d3994379abf68f42fa4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.25G/1.25G [00:23&lt;00:00, 54.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f096905ceb01456a936e55abbd7dee45"}},"0e178031ff304a22885a58d882a62153":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dcfbdb82e54e42b29a6a57d2fdda4186":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52175a19024a4c8e9a822f66029117e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0f5dcf1641014848a6aa4f06601cbbdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"281b92d2cf6b4d3994379abf68f42fa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f096905ceb01456a936e55abbd7dee45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMS_xuKqPnVq","executionInfo":{"status":"ok","timestamp":1645664465334,"user_tz":-540,"elapsed":25076,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"df49aaf6-4df4-4061-fbc3-b31bad33c11a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"9vsko_OEPple"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH =  '/content/drive/MyDrive/AIConnect/NLP_classificaiton/data'\n","\n","train = pd.read_csv(os.path.join(PATH, 'train.csv'), encoding='utf-8')\n","test = pd.read_csv(os.path.join(PATH, 'test.csv'), encoding='utf-8')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"oDMvBV0kQjTo","executionInfo":{"status":"ok","timestamp":1645664479730,"user_tz":-540,"elapsed":1473,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"3d3281f3-f840-44a6-88c7-753be5d26004"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6e370e6f-3d4e-40f6-9783-6ec0a3266f60\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n","      <td>일본 축구 져라</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n","      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e370e6f-3d4e-40f6-9783-6ec0a3266f60')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6e370e6f-3d4e-40f6-9783-6ec0a3266f60 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6e370e6f-3d4e-40f6-9783-6ec0a3266f60');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ...  hate\n","0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"  ...  none\n","1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...  ...  hate\n","2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"  ...  hate\n","3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"  ...  none\n","4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...  ...  none\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["test.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"3v_zIYaxRLFT","executionInfo":{"status":"ok","timestamp":1645664481560,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"428aa151-d1d1-49da-df55-4017f07e7677"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f9253355-2a9d-40fb-8322-208daa1c6bdd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]</td>\n","      <td>둘다 넘 좋다~행복하세요</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>\"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]</td>\n","      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]</td>\n","      <td>누군데 얘네?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"</td>\n","      <td>쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]</td>\n","      <td>안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9253355-2a9d-40fb-8322-208daa1c6bdd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f9253355-2a9d-40fb-8322-208daa1c6bdd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f9253355-2a9d-40fb-8322-208daa1c6bdd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   ID  ...                                            comment\n","0   0  ...                                      둘다 넘 좋다~행복하세요\n","1   1  ...               근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데\n","2   2  ...                                            누군데 얘네?\n","3   3  ...  쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...\n","4   4  ...  안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["print(train.info(), end='\\n\\n')\n","print(test.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4W-7WbKQzHb","executionInfo":{"status":"ok","timestamp":1645664488782,"user_tz":-540,"elapsed":320,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"3368e437-66bf-4bbd-db25-02d53f74843b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8367 entries, 0 to 8366\n","Data columns (total 4 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   title    8367 non-null   object\n"," 1   comment  8367 non-null   object\n"," 2   bias     8367 non-null   object\n"," 3   hate     8367 non-null   object\n","dtypes: object(4)\n","memory usage: 261.6+ KB\n","None\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 511 entries, 0 to 510\n","Data columns (total 3 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   ID       511 non-null    int64 \n"," 1   title    511 non-null    object\n"," 2   comment  511 non-null    object\n","dtypes: int64(1), object(2)\n","memory usage: 12.1+ KB\n","None\n"]}]},{"cell_type":"code","source":["print('Train Columns: ', train.columns)\n","print('Test Columns: ', test.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6qAcvbExREtL","executionInfo":{"status":"ok","timestamp":1645664495690,"user_tz":-540,"elapsed":323,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"d36b2a03-8811-45cb-ae09-6e6f7531bc6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Columns:  Index(['title', 'comment', 'bias', 'hate'], dtype='object')\n","Test Columns:  Index(['ID', 'title', 'comment'], dtype='object')\n"]}]},{"cell_type":"code","source":["print('Train Null: ', train.isnull().sum(), sep='\\n', end='\\n\\n')\n","print('Test Null: ', test.isnull().sum(), sep='\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsLKojYmRH46","executionInfo":{"status":"ok","timestamp":1645664498076,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"1e300dde-a659-4193-b21a-79c6dd9ad715"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Null: \n","title      0\n","comment    0\n","bias       0\n","hate       0\n","dtype: int64\n","\n","Test Null: \n","ID         0\n","title      0\n","comment    0\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["# bias 데이터 분포 확인"],"metadata":{"id":"ACFKDccATPnj"}},{"cell_type":"code","source":["feature = train['bias']\n","\n","plt.figure(figsize=(10,7.5))\n","plt.title('Label Count', fontsize=20)\n","\n","temp = feature.value_counts()\n","plt.bar(temp.keys(), temp.values, width=0.5, color='b', alpha=0.5)\n","plt.text(-0.05, temp.values[0]+20, s=temp.values[0])\n","plt.text(0.95, temp.values[1]+20, s=temp.values[1])\n","plt.text(1.95, temp.values[2]+20, s=temp.values[2])\n","\n","plt.xticks(temp.keys(), fontsize=12) # x축 값, 폰트 크기 설정\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n","plt.show() # 그래프 나타내기"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"H5YXFUQIRRHQ","executionInfo":{"status":"ok","timestamp":1645664506297,"user_tz":-540,"elapsed":904,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"46d92c64-2629-45f6-deec-14f5440d4e4a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x540 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# hate 데이터 분포 확인"],"metadata":{"id":"EcbWHf6kTSPo"}},{"cell_type":"code","source":["feature = train['hate']\n","\n","plt.figure(figsize=(10,7.5))\n","plt.title('Label Count', fontsize=20)\n","\n","temp = feature.value_counts()\n","plt.bar(temp.keys(), temp.values, width=0.5, color='b', alpha=0.5)\n","plt.text(-0.05, temp.values[0]+20, s=temp.values[0])\n","plt.text(0.95, temp.values[1]+20, s=temp.values[1])\n","\n","plt.xticks(temp.keys(), fontsize=12) # x축 값, 폰트 크기 설정\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n","plt.show() # 그래프 나타내기"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"EAMt0-WPRcPE","executionInfo":{"status":"ok","timestamp":1645664507392,"user_tz":-540,"elapsed":474,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"f507e87c-7773-42a7-cec9-3c3f37f860dc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x540 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"kU6Ym7NAaq31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# title, comment 길이 확인 (공백, 특수문자도 1개의 단위 길이로 측정됨)"],"metadata":{"id":"wfO_0PcoUiGw"}},{"cell_type":"code","source":["max_len = np.max(train['title'].str.len())\n","min_len = np.min(train['title'].str.len())\n","mean_len = np.mean(train['title'].str.len())\n","\n","print('Max title Length: ', max_len)\n","print('Min title Length: ', min_len)\n","print('Mean title Lenght: ', mean_len, '\\n')\n","\n","max_len = np.max(train['comment'].str.len())\n","min_len = np.min(train['comment'].str.len())\n","mean_len = np.mean(train['comment'].str.len())\n","\n","print('Max comment\t Length: ', max_len)\n","print('Min comment\t Length: ', min_len)\n","print('Mean comment\t Lenght: ', mean_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlSBC2F5ShqF","executionInfo":{"status":"ok","timestamp":1645664510517,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"992ec239-79a6-46b2-de18-c7feb3a1991c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max title Length:  63\n","Min title Length:  2\n","Mean title Lenght:  42.4844030118322 \n","\n","Max comment\t Length:  137\n","Min comment\t Length:  4\n","Mean comment\t Lenght:  38.72439345046014\n"]}]},{"cell_type":"code","source":["# comment 길이별 분포\n","from collections import Counter\n","\n","plt.figure(figsize=(10,7.5))\n","plt.title('comment', fontsize=20)\n","\n","plt.hist(train['comment'].str.len(), alpha=0.5, color='orange')\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # 레이아웃 설정\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"3IxntnzCUHvA","executionInfo":{"status":"ok","timestamp":1645664511194,"user_tz":-540,"elapsed":351,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"f840754d-4e73-4660-d64e-c111c3ee0cb9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsgAAAHpCAYAAACfs8p4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAar0lEQVR4nO3df/Bld13f8de7WcAiHRNIDJhEEzDTNtAYmBVj1RqlExLqmLS2FKoSERtbYQoOjhLQsv6gWn/RMtV0UNKEGQoyqCXWAGYiI6IGWQguAcRECCZpSBZDgkgFg+/+cc+Wt998v+xm9/tjszweM3fuvZ9z7rmf78nJd59799x7q7sDAACs/J2dngAAABxNBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyABsm6raU1VdVeft9FwANiKQAQBgEMgAADAIZIANVNWTq+pXqur2qvp0Vd1RVb9VVU9fs97Tq+ptVXVvVf3fqnpvVV1WVQ9bZ5u3LJdHVNXLq+rW5THvqaqLl3V2VdVLquqmqvqrqvrTqnreOts6bzldYU9V7a6qNy9z+HhV/WpVnbas99iqel1V7V+e661V9VUb/MwPX+b+nqr6y6r6ZFX9QVU98yDPf05V/WZV3VNVn6qq36mqf7z2Z0/y0uXuW5fHdlX1If4nAdgW1e33EsBaVfVvk1ye5LNJrk5yU5IvTbI7yT3dfd6y3n9KclmSjyV5Q5JPJrkwyeOT/E6S87v7M2O7tyR5SJI/S/LIJNcmeWiSZyZ5eJLzk3xfkq9J8qYkn07yr5bnfkZ3/8rY1nlJ3prkmiTfvDzfjUn+0bKdP0lyUZK3J/njJO9I8hVJ/sUy38d29yfH9o5P8ttJnpjk3Ul+P6sXUp6a5HFJXtbdP7zO8//m8vx/kOSGJF+e5NuSfCbJOd39wWX9FyS5OMk3JrkqyS0HttXdezb4TwGw/brbxcXFxWVckpyV5K+T3J3k8essP3W5/toknVXsPnos35XkN5ZlL17z2FuW8d9I8rAx/g3L+N1J3pnk+LHssVnF5g1rtnXe8phO8u1rlr1qbO8la5b9yLLs+WvGr1zGf3DN+BcleXOSv8kqeNd7/u9a85jvXcZ/cc34nmX8vJ3+7+zi4uKy0cUpFgD39++zitwf7+73rV3Y3bctN797uf6J7v7oWH5fkhdmFZTfs8FzvKC7Pz0e87tJPpzkhCQ/1N33jGUfSvJ7SZ5QVcets623d/dr1oxdtVzfm+Sn1ix79XJ9zoGBqnpUku9Isre7f3qu3N1/leSHklSSf7PO8/9ed1+5ZuyKJPclefI66wMc1Xbt9AQAjkLnLtdvOsh6T1quf3vtgu7+k6q6LckZVfUl3X3vWHxPd//pOtv7P0nOSPKudZbdntXv7Ecvt6e9G2wrSd7T3Z9dZ1tJcuoY++okxyXpqtqzzvYeslz/w3WW3e/5u/uvq+rOrIIf4EFFIAPc3/HL9doQXetLlus7Nlh+R1bn4x6f1Su5B9y7/uq5L0nWxPTfWpbPher0+da/37Luvq+q1m7rUcv1Vy+XjTxinbF71hk7MIf1XvEGOKo5xQLg/g4E3ykHWe9AfD56g+WPWbPe0ezAHF/e3fV5Lt+0o7ME2AYCGeD+rl+uLzzIejcs1+etXVBVX5nVKQwfnucTH8X+MKtzpr9hi5/nwOkeXlkGjloCGeD+Ls/q9IAfqaqz1i6sqgPn7l6xXP9wVZ00lh+X5Gez+h37qi2e66bo7ruSvCbJ7qr6kfXeDFhVj6uqM47wqf58uf7yI9wOwJZxDjLAGt39/qr6viT/PckNVfXGrD4H+VFZnZ/7iSTf1N2/X1U/neQHk9xYVW9I8pdZvfL8hKw+f/hnduJnOEzPS3Jmkh9L8p1V9fYkdyb5sqzenPfVWX1e84eP4DnemtUr1T9ZVU9I8vEk6e6fOIJtAmwqgQywju7+paq6MckPZHUKxcVZfbnGviS/PNb7oaq6Iau4fFZWb3z70yQ/nOTnenxJyNGuuz9RVd+Y5NKsPs7t27L6DOQ7s/oLwvdn9cUmR/IcH6iqS7Lar9+3bD9JBDJw1PBNegAAMDgHGQAABoEMAACDQAYAgEEgAwDAIJABAGA4qj/m7cQTT+zTTz99p6cBAMAx6F3vetfHuvukteNHdSCffvrp2bt3705PAwCAY1BVfWS9cadYAADAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGDYtdMT4Cixb89Oz2D7nb1np2cAAByFvIIMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgOGggVxVp1XVW6vq/VX1vqp6/jL+yKq6tqpuWq5PWMarql5RVTdX1b6qetLY1iXL+jdV1SVb92MBAMDhOZRXkO9L8sLuPivJuUmeW1VnJXlRkuu6+8wk1y33k+TCJGcul0uTXJ6sgjrJS5N8TZInJ3npgagGAICjxUEDubvv6O53L7f/IskHkpyS5KIkVy2rXZXk4uX2RUle3SvXJzm+qh6T5KlJru3uu7v740muTXLBpv40AABwhB7QOchVdXqSJyZ5R5KTu/uOZdFHk5y83D4lya3jYbctYxuNr32OS6tqb1Xt3b9//wOZHgAAHLFDDuSqekSSX03ygu7+xFzW3Z2kN2NC3f3K7t7d3btPOumkzdgkAAAcskMK5Kp6SFZx/Jru/rVl+M7l1Iks13ct47cnOW08/NRlbKNxAAA4ahzKp1hUklcl+UB3//xYdHWSA59EcUmSN47xZy2fZnFuknuXUzHekuT8qjpheXPe+csYAAAcNXYdwjpfl+Q7k7y3qt6zjL04yU8leX1VPSfJR5I8fVl2TZKnJbk5yaeSPDtJuvvuqvrxJO9c1vux7r57U34KAADYJAcN5O5+e5LaYPFT1lm/kzx3g21dkeSKBzLBHbNvz07PAACAHeCb9AAAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAACGgwZyVV1RVXdV1Y1jbE9V3V5V71kuTxvLLquqm6vqg1X11DF+wTJ2c1W9aPN/FAAAOHKH8grylUkuWGf85d19znK5Jkmq6qwkz0jy+OUxv1hVx1XVcUl+IcmFSc5K8sxlXQAAOKrsOtgK3f22qjr9ELd3UZLXdfenk3y4qm5O8uRl2c3d/aEkqarXLeu+/wHPGAAAttCRnIP8vKrat5yCccIydkqSW8c6ty1jG40DAMBR5XAD+fIkj0tyTpI7kvzcZk2oqi6tqr1VtXf//v2btVkAADgkhxXI3X1nd3+2u/8myS/lc6dR3J7ktLHqqcvYRuPrbfuV3b27u3efdNJJhzM9AAA4bIcVyFX1mHH3nyc58AkXVyd5RlU9rKrOSHJmkj9M8s4kZ1bVGVX10KzeyHf14U8bAAC2xkHfpFdVr01yXpITq+q2JC9Ncl5VnZOkk9yS5HuTpLvfV1Wvz+rNd/cleW53f3bZzvOSvCXJcUmu6O73bfpPAwAAR+hQPsXimesMv+rzrP+yJC9bZ/yaJNc8oNkBAMA28016AAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAMOunZ4A7Jh9e3Z6Btvr7D07PQMAeFDwCjIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGDYtdMTALbJvj07PYPtd/aenZ4BAA9CXkEGAIDhoIFcVVdU1V1VdeMYe2RVXVtVNy3XJyzjVVWvqKqbq2pfVT1pPOaSZf2bquqSrflxAADgyBzKK8hXJrlgzdiLklzX3WcmuW65nyQXJjlzuVya5PJkFdRJXprka5I8OclLD0Q1AAAcTQ4ayN39tiR3rxm+KMlVy+2rklw8xl/dK9cnOb6qHpPkqUmu7e67u/vjSa7N/aMbAAB23OGeg3xyd9+x3P5okpOX26ckuXWsd9syttH4/VTVpVW1t6r27t+//zCnBwAAh+eI36TX3Z2kN2EuB7b3yu7e3d27TzrppM3aLAAAHJLDDeQ7l1MnslzftYzfnuS0sd6py9hG4wAAcFQ53EC+OsmBT6K4JMkbx/izlk+zODfJvcupGG9Jcn5VnbC8Oe/8ZQwAAI4qB/2ikKp6bZLzkpxYVbdl9WkUP5Xk9VX1nCQfSfL0ZfVrkjwtyc1JPpXk2UnS3XdX1Y8neeey3o9199o3/gEAwI47aCB39zM3WPSUddbtJM/dYDtXJLniAc0OAAC2mW/SAwCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADLt2egIAW2bfnp2ewfY7e89OzwDgQc8ryAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAcESBXFW3VNV7q+o9VbV3GXtkVV1bVTct1ycs41VVr6iqm6tqX1U9aTN+AAAA2Eyb8QryN3X3Od29e7n/oiTXdfeZSa5b7ifJhUnOXC6XJrl8E54bAAA21VacYnFRkquW21cluXiMv7pXrk9yfFU9ZgueHwAADtuRBnIn+a2qeldVXbqMndzddyy3P5rk5OX2KUluHY+9bRn7W6rq0qraW1V79+/ff4TTAwCAB2bXET7+67v79qr60iTXVtUfz4Xd3VXVD2SD3f3KJK9Mkt27dz+gxwIAwJE6oleQu/v25fquJL+e5MlJ7jxw6sRyfdey+u1JThsPP3UZAwCAo8ZhB3JVfXFV/b0Dt5Ocn+TGJFcnuWRZ7ZIkb1xuX53kWcunWZyb5N5xKgYAABwVjuQUi5OT/HpVHdjO/+zuN1fVO5O8vqqek+QjSZ6+rH9NkqcluTnJp5I8+wieGwAAtsRhB3J3fyjJV60z/udJnrLOeCd57uE+HwAAbAffpAcAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMAgkAEAYBDIAAAwCGQAABh27fQEANhE+/bs9Ay219l7dnoGwDHIK8gAADAIZAAAGAQyAAAMAhkAAAaBDAAAg0AGAIBBIAMAwOBzkAF48PpC+9znxGc/wzbwCjIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAADDrp2eAADwAOzbs9Mz2F5n79npGfAFyCvIAAAwCGQAABgEMgAADAIZAAAGgQwAAINABgCAQSADAMDgc5ABgKPXF9rnPic++/ko4BVkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgEEgAwDAIJABAGDYtdMTAABg2Ldnp2ewvc7es9MzuB+vIAMAwCCQAQBg2PZArqoLquqDVXVzVb1ou58fAAA+n20N5Ko6LskvJLkwyVlJnllVZ23nHAAA4PPZ7leQn5zk5u7+UHd/Jsnrkly0zXMAAIANbXcgn5Lk1nH/tmUMAACOCkfdx7xV1aVJLl3ufrKqPvgAN3Fiko9t7qzYgH29fezr7WNfbx/7evvY19vHvn7AfvRwH7gZ+/or1hvc7kC+Pclp4/6py9j/192vTPLKw32Cqtrb3bsP9/EcOvt6+9jX28e+3j729faxr7ePfb19tnJfb/cpFu9McmZVnVFVD03yjCRXb/McAABgQ9v6CnJ331dVz0vyliTHJbmiu9+3nXMAAIDPZ9vPQe7ua5Jcs4VPcdinZ/CA2dfbx77ePvb19rGvt499vX3s6+2zZfu6unurtg0AAA86vmoaAACGYyaQfYX11qmq06rqrVX1/qp6X1U9fxl/ZFVdW1U3Ldcn7PRcjxVVdVxV3VBV/3u5f0ZVvWM5vn9leZMrR6iqjq+qN1TVH1fVB6rqax3XW6Oqvn/5/XFjVb22qr7Icb15quqKqrqrqm4cY+sey7XyimW/76uqJ+3czB98NtjXP7P8HtlXVb9eVcePZZct+/qDVfXUnZn1g9N6+3ose2FVdVWduNzf1OP6mAhkX2G95e5L8sLuPivJuUmeu+zfFyW5rrvPTHLdcp/N8fwkHxj3/3OSl3f3Vyb5eJLn7Misjj3/Ncmbu/sfJPmqrPa543qTVdUpSf5Dkt3d/YSs3qT9jDiuN9OVSS5YM7bRsXxhkjOXy6VJLt+mOR4rrsz99/W1SZ7Q3Wcn+ZMklyXJ8mflM5I8fnnMLy7NwqG5Mvff16mq05Kcn+TPxvCmHtfHRCDHV1hvqe6+o7vfvdz+i6wi4pSs9vFVy2pXJbl4Z2Z4bKmqU5P8syS/vNyvJN+c5A3LKvb1JqiqL0nyT5K8Kkm6+zPdfU8c11tlV5K/W1W7kjw8yR1xXG+a7n5bkrvXDG90LF+U5NW9cn2S46vqMdsz0we/9fZ1d/9Wd9+33L0+q+95SFb7+nXd/enu/nCSm7NqFg7BBsd1krw8yQ8mmW+k29Tj+lgJZF9hvU2q6vQkT0zyjiQnd/cdy6KPJjl5h6Z1rPkvWf2P/zfL/UcluWf88nV8b44zkuxP8j+W01l+uaq+OI7rTdfdtyf52axe7bkjyb1J3hXH9Vbb6Fj2Z+bW+u4kb1pu29ebrKouSnJ7d//RmkWbuq+PlUBmG1TVI5L8apIXdPcn5rJefRyKj0Q5QlX1LUnu6u537fRcvgDsSvKkJJd39xOT/GXWnE7huN4cy7mvF2X1l5IvS/LFWeefTdk6juXtUVUvyeq0xNfs9FyORVX18CQvTvIft/q5jpVAPuhXWHNkquohWcXxa7r715bhOw/888VyfddOze8Y8nVJvrWqbsnqVKFvzuo82eOXf5pOHN+b5bYkt3X3O5b7b8gqmB3Xm++fJvlwd+/v7r9O8mtZHeuO66210bHsz8wtUFXfleRbknx7f+4zdO3rzfW4rP6i/UfLn5OnJnl3VT06m7yvj5VA9hXWW2g5B/ZVST7Q3T8/Fl2d5JLl9iVJ3rjdczvWdPdl3X1qd5+e1XH829397UnemuRfLqvZ15uguz+a5Naq+vvL0FOSvD+O663wZ0nOraqHL79PDuxrx/XW2uhYvjrJs5Z3/Z+b5N5xKgaHoaouyOrUuG/t7k+NRVcneUZVPayqzsjqDWR/uBNzPBZ093u7+0u7+/Tlz8nbkjxp+X2+qcf1MfNFIVX1tKzO3TzwFdYv2+EpHTOq6uuT/G6S9+Zz58W+OKvzkF+f5MuTfCTJ07t7vZPpOQxVdV6SH+jub6mqx2b1ivIjk9yQ5Du6+9M7Ob9jQVWdk9WbIR+a5ENJnp3VCweO601WVT+a5F9n9c/PNyT5nqzOD3Rcb4Kqem2S85KcmOTOJC9N8r+yzrG8/CXlv2V1msunkjy7u/fuxLwfjDbY15cleViSP19Wu767/92y/kuyOi/5vqxOUXzT2m2yvvX2dXe/aiy/JatPx/nYZh/Xx0wgAwDAZjhWTrEAAIBNIZABAGAQyAAAMAhkAAAYBDIAAAwCGQAABoEMAACDQAYAgOH/AVHmmiik99AiAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 720x540 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# 한글이 아닌거 제거(특수 문자, 숫자, 자음, 모음등)\n","* 토크나이징 하기 위해 제거 했으나 해당 과정을 생략하고 학습 시도 해볼 수 있음.\n"],"metadata":{"id":"G81Wsg6HWRAT"}},{"cell_type":"code","source":["train['title'] = train['title'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n","test['title'] = test['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n","train.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"C1pNS16SUXkv","executionInfo":{"status":"ok","timestamp":1645664515628,"user_tz":-540,"elapsed":342,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"82fa9eca-80fc-4837-eddd-8b39ef33e7c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-bb73f1ab-ae8d-45a8-a232-3ef272a9f3e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>섹션 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n","      <td>일본 축구 져라</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰</td>\n","      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb73f1ab-ae8d-45a8-a232-3ef272a9f3e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bb73f1ab-ae8d-45a8-a232-3ef272a9f3e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bb73f1ab-ae8d-45a8-a232-3ef272a9f3e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ...  hate\n","0                미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  ...  none\n","1             현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합  ...  hate\n","2                    손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다  ...  hate\n","3                           섹션 김해숙 허스토리 촬영 후 우울증 얻었다  ...  none\n","4  단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰  ...  none\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["train['comment'] = train['comment'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n","test['comment'] = test['comment'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\", \"\")\n","train.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"invHGi74WOls","executionInfo":{"status":"ok","timestamp":1645664517978,"user_tz":-540,"elapsed":342,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"3c6699c8-b70b-4799-f6af-3f5c34322ff9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n","  \n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-830a6741-1aee-41b3-a322-49a8418d0ff6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길 행복은 머니순이 아니니깐 작은거에 감...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>섹션 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n","      <td>일본 축구 져라</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰</td>\n","      <td>난 절대로 임현주 욕하는인간이랑은 안논다</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-830a6741-1aee-41b3-a322-49a8418d0ff6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-830a6741-1aee-41b3-a322-49a8418d0ff6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-830a6741-1aee-41b3-a322-49a8418d0ff6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ...  hate\n","0                미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  ...  none\n","1             현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합  ...  hate\n","2                    손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다  ...  hate\n","3                           섹션 김해숙 허스토리 촬영 후 우울증 얻었다  ...  none\n","4  단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰  ...  none\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["train.head(5)"],"metadata":{"id":"yh2Vz_IQRNf1","executionInfo":{"status":"ok","timestamp":1645664897411,"user_tz":-540,"elapsed":327,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"e4f60a4d-fd97-488f-b016-adf326e08e02","colab":{"base_uri":"https://localhost:8080/","height":302}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a9ee27e4-b3bb-4e98-87b5-34e3885d287d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길 행복은 머니순이 아니니깐 작은거에 감...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>섹션 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n","      <td>일본 축구 져라</td>\n","      <td>none</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰</td>\n","      <td>난 절대로 임현주 욕하는인간이랑은 안논다</td>\n","      <td>none</td>\n","      <td>none</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9ee27e4-b3bb-4e98-87b5-34e3885d287d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a9ee27e4-b3bb-4e98-87b5-34e3885d287d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a9ee27e4-b3bb-4e98-87b5-34e3885d287d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               title  ... label\n","0                미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  ...     0\n","1             현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합  ...     0\n","2                    손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다  ...     0\n","3                           섹션 김해숙 허스토리 촬영 후 우울증 얻었다  ...     0\n","4  단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면 인터뷰  ...     0\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train['label'] = 0"],"metadata":{"id":"zoZDKHiQPkf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"XAqnJd7xQT5G","executionInfo":{"status":"error","timestamp":1645664825170,"user_tz":-540,"elapsed":711,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"b9191bd5-0d1c-4752-9cb3-22bee47c1b17","colab":{"base_uri":"https://localhost:8080/","height":325}},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-9056e8b7cfd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'none'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."]}]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"vIv-t3KLWrBe"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"On945wBGWdEO","executionInfo":{"status":"ok","timestamp":1645626671089,"user_tz":-540,"elapsed":10922,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"d93d55a5-2541-4d53-9982-669ee3e0a763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 51.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 56.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from transformers import TrainingArguments, Trainer\n","from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer"],"metadata":{"id":"U0Z3LuAnWlqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed 고정, gpu 고정\n","def seed_everything(seed:int = 1004):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything(2022)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fwfpImdWwLZ","executionInfo":{"status":"ok","timestamp":1645617711170,"user_tz":-540,"elapsed":7,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"00dfc600-4bc7-4050-d82c-9aea4ba63ad8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["# Load Tokenizer, Model\n","Hugging Face Hub에 존재하는 Pretrained Tokenizer와 Model 및 Model Config 불러오기\n","\n","이 때, Classification은 num_labels가 2로 Default되어있기 때문에 Model Config의 Parameter를  6으로 변경"],"metadata":{"id":"4eED-rnBXNFt"}},{"cell_type":"code","source":["모델 = 'klue/roberta-large' # 보통 tokenizer도 같은거 씀. 이거만 바꾸면 모델, tokenizer 변경 가능."],"metadata":{"id":"Zl-1CpwF_X5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_NAME = 모델\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","config.num_labels = 3 # other, gender, \n","\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n","\n","print(model)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2865cb4aeacb45a49fb2548799a27416","a916b56399a3456ebaefd7cc6ee3ec05","14962e30ce324e6bb54487cea9b45344","7355b4c4ed3c44fc96420502a0ada722","00516c747e6c404d969f84bdeb3155bb","e9fa58be7bb344c38eb64a7dab857fc4","a7621eb972214fb19b776286994a0226","6a9e3ee9e8984bac95bb002dfffc35f9","fdf18814230f4892a35678c90d140fd8","8a4bea7410cf42528627ed3c73f77602","0b353b0fe55d4980b6b45d05f751c4f9","abd235a1158942e6955f1c98e8373253","bf6204ff03064af9ab2513c71e12c380","d024d61371db45e4b7bbada51e2a74a9","1cf7fae32d2040509bf29f4910c88602","00d01b315d584b02af40294ad35004d7","596ef140c93d426faabaafd52a9012ad","e9365fe7e0184db6a3ef986cd6f7ea5a","c581fd142b3e478286bd153e38d28620","aae9dd27487b422fa6ea57a5399cb123","564308e42f7f432585e986599477b330","d2852007af9941a292206fdef588c391","802923ca8baa4a019b0da040d68b9ff8","fd39f4c10a284dd9a76f6131b828e208","aa0f17a8214c40a6b5c6eccfcf36e5af","8eb52fbba48b412a9692b68a8bf39c59","0666d3cc60cf4699afd772eaaec83fa1","be9d28fe595841be9d530f0a0975041f","840511e242c64706a2d2252edb23c5c8","067ff58f781745f1b013d4330909a928","7a9be92087304c7e99e2a5e509243a27","acaa34475dbc4fef83039e4a70b7d88e","e367890027024b948a2d7d685de26a51","3f74b50e82104dbcb84c96c5820f9b99","5916cb3116c94e339316a7fe9ced336f","872a906a1bad4957b419c30d6335448b","dbc480bd7aed483e8a53a238c1662c19","33953cf3e56a4d3d962508a1e792098a","d42131ca9696453d9f4ab967e92bf7c3","59d56b929e114aa096c8d2fd6b9c513f","72360c6abd0e49d8a4d0b9db8298b581","680f5cc07b064552b5b78d51e2886fde","c48bf92044964de680da0ec2b853e039","2483e61cdea040dc9812fcfcc15da939","1a17a84fb1a6423f8b4068a4d163f9b2","550e1917b11442ba88970395338fca82","dc4bf41c7fa84920875af28ba1856e7b","3ec52688b66547f49038b085272d5fa3","40ad55d90ddd4e648ccc59d079155571","8192228f4c5f4c929166a594ce1d4979","66633ae2c00f4a4690294de4f30345b0","76d8015269ea4d788bdc1111d20f1937","be064cb9c5444196b95a1d4a74c79f5e","b7bc854e01b24793ba68384dc80b809d","d2b09c55be0542de98a1dbd187957f74","6fa50f9ab95a4b77960eb8659ab2e84d","0749ad2437434583b70b121695123215","91b18e9feb6346769de4dd1fbc3ae815","6332b0788753401d8bb12fefe712fa38","fb1e919f7ca5417c9234fb1a50f19471","0e178031ff304a22885a58d882a62153","dcfbdb82e54e42b29a6a57d2fdda4186","52175a19024a4c8e9a822f66029117e8","0f5dcf1641014848a6aa4f06601cbbdb","281b92d2cf6b4d3994379abf68f42fa4","f096905ceb01456a936e55abbd7dee45"]},"id":"Kp9qC9ZaXWh_","executionInfo":{"status":"ok","timestamp":1645626766875,"user_tz":-540,"elapsed":40289,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"c4713537-a341-4c65-a432-0be557f3dc75"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2865cb4aeacb45a49fb2548799a27416","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/375 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abd235a1158942e6955f1c98e8373253","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"802923ca8baa4a019b0da040d68b9ff8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/734k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f74b50e82104dbcb84c96c5820f9b99","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/173 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a17a84fb1a6423f8b4068a4d163f9b2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/547 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fa50f9ab95a4b77960eb8659ab2e84d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n","  )\n",")\n","RobertaConfig {\n","  \"_name_or_path\": \"klue/roberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n"]}]},{"cell_type":"markdown","source":["# Tokenizing"],"metadata":{"id":"b9ScKe5TXsnM"}},{"cell_type":"code","source":["train.rename(columns = {'bias':'label'},inplace=True) # column 명이 label  이 아니면 학습이 안되길래 바꿔줌."],"metadata":{"id":"N6ELIlDljmC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"cKPpYYMqkCiS","executionInfo":{"status":"ok","timestamp":1645617753711,"user_tz":-540,"elapsed":23,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a2875e2c-58e6-4a86-db2f-f413bd71b474"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f9685cc5-2d13-4bbc-926b-9c9b0a03df73\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합</td>\n","      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n","      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길 행복은 머니순이 아니니깐 작은거에 감...</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9685cc5-2d13-4bbc-926b-9c9b0a03df73')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f9685cc5-2d13-4bbc-926b-9c9b0a03df73 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f9685cc5-2d13-4bbc-926b-9c9b0a03df73');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                    title  ...  hate\n","0     미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  ...  none\n","1  현장극사실주의 현실가장 보통의 연애 김래원공효진 16년만의 랑데부종합  ...  hate\n","2         손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다  ...  hate\n","\n","[3 rows x 4 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train_dataset, eval_dataset = train_test_split(train, test_size=0.1, shuffle=True, stratify=train['label'])\n","\n","tokenized_train = tokenizer(\n","    list(train_dataset['title']),\n","    list(train_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128, # Max_Length = 138  tokenizing 하면 길이가 줄어들어서 128로 해도 무관한듯 ?\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","tokenized_eval = tokenizer(\n","    list(eval_dataset['title']),\n","    list(eval_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","print(tokenized_train['input_ids'][0])\n","print(tokenizer.decode(tokenized_train['input_ids'][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vc3OEAEcXkXZ","executionInfo":{"status":"ok","timestamp":1645617764766,"user_tz":-540,"elapsed":2424,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"f9153c86-83a0-4fba-d8b3-65fea4b54957"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([    0,  6095,    24,  2593,  7764,  2156,  2205,  8535,  1284,  2073,\n","         2112,  2052,  2223,  2164,    26,  2019,  2429,  3135,  1432,  2348,\n","            2,  7296,  2164,  3991, 27135,  4920,  2144,  2319,  2062,     2,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1])\n","[CLS] 단독 4살 연상연하 커플 손은서이주승 6개월째 열애 [SEP] 이주승 세상에서 제일부럽다 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["\n","class BERTDataset(torch.utils.data.Dataset):\n","    def __init__(self, pair_dataset, label):\n","        self.pair_dataset = pair_dataset\n","        self.label = label\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n","        item['label'] = torch.tensor(self.label[idx])\n","        \n","        return item\n","\n","    def __len__(self):\n","        return len(self.label)"],"metadata":{"id":"lpyGY8GjdC1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def label_to_num(label): \n","    label_dict = {\"none\": 0, \"others\": 1, \"gender\": 2, \"answer\": 3}  #여기   answer 는 의미 없는거임 참고한 코드에 있어서 그냥 놔둠\n","    num_label = []\n","\n","    for v in label: \n","        num_label.append(label_dict[v])\n","    \n","    return num_label\n","\n","\n","train_label = label_to_num(train_dataset['label'].values)\n","eval_label = label_to_num(eval_dataset['label'].values)"],"metadata":{"id":"uVZRF495dvDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = BERTDataset(tokenized_train, train_label)\n","eval_dataset = BERTDataset(tokenized_eval, eval_label)\n","\n","print(train_dataset.__len__())\n","print(train_dataset.__getitem__(7529))\n","print(tokenizer.decode(train_dataset.__getitem__(7529)['input_ids'])) # 메서드 호출하면 이렇게 생겼구나 .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS6OZupre0v-","executionInfo":{"status":"ok","timestamp":1645617837357,"user_tz":-540,"elapsed":392,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"ae48214f-cbba-4ee3-dad3-b233a1081aa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7530\n","{'input_ids': tensor([    0, 26315, 16307,  2470, 10266,  2332,  2280, 18164,  2068,  3868,\n","         6750,  3996, 11800,  4548,  2372,  2121,     2,  6260,  2306,  2470,\n","         2306,  2259,  4807,  6991,  2113,  2899,  2259, 14167,  2118,     2,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0]), 'label': tensor(2)}\n","[CLS] 지민 앙상한 몸매건강이상설 직접 해명 건강합니다 공식입장 [SEP] 김치녀한녀는 절대 가질수없는 몸무게지 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["def compute_metrics(pred):\n","  \"\"\" validation을 위한 metrics function \"\"\"\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  probs = pred.predictions\n","\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds) # 리더보드 평가에는 포함되지 않습니다.\n","\n","  return {\n","      'accuracy': acc,\n","  }"],"metadata":{"id":"WXoFRpiSe-Zm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_ars = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/AIConnect/NLP_classificaiton/result', # checkpoint 마다 모델이 해당 경로에 저장됨.\n","    num_train_epochs=7,\n","    per_device_train_batch_size=32,\n","    save_total_limit=5, # 성능 상위 5개 모델만 저장.  이거 용량 꽤 커서 제한 해줘야댐.\n","    save_steps=250,\n","    evaluation_strategy='steps',\n","    eval_steps = 250,\n","    load_best_model_at_end = True,  # parameter 의미를 정확히 모름 알아보고 바꿔주면 성능 올라갈듯.\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_ars,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"dV-C0U6vfZSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()\n","model.save_pretrained('/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/best_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":939},"id":"aKdBZZk_gtTy","executionInfo":{"status":"ok","timestamp":1645604524177,"user_tz":-540,"elapsed":1749969,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"81539b3a-e0f8-475d-bded-fb0007aa9abd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 7530\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1652\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1652' max='1652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1652/1652 29:02, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.617400</td>\n","      <td>0.696588</td>\n","      <td>0.761051</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.240900</td>\n","      <td>1.135466</td>\n","      <td>0.784946</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.061900</td>\n","      <td>1.397917</td>\n","      <td>0.770609</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-500 (score: 0.6965883374214172).\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/best_model/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/best_model/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","Tokenizer_NAME = 모델\n","tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n","\n","MODEL_NAME = '/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500'  # checkpoint 마다 미리 지정해둔 경로에 모델 저장됨 ㅇㅇ\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","model.resize_token_embeddings(tokenizer.vocab_size)\n","model.to(device)\n","\n","print(tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2niFtb8Tg7NZ","executionInfo":{"status":"ok","timestamp":1645617880432,"user_tz":-540,"elapsed":23698,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"d969290e-16da-4484-99c8-70ab01184234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/klue/roberta-large/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/4eb906e7d0da2b04e56c7cc31ba068d7c295240a51690153c2ced71c9e4c9fc5.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/360b579947002f14f22331a026821b56f70679f1be1e95fe5dc5a80edc4a59e0.44c30ade4958fcfd446e66025e10a5b380cdd0bbe9b3fb7a794f357e7f0f34c2\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1a24ab4628028ed80dea35ce3334a636dc656fd9a17a09bad377f88f0cbecdac.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8f31ccbd66730704a8400c96db0647b10c47cd0c838ea2cabf0a86ef878f31cf.5b0ba083b234382bb4c99ee0c9f4fca4cadaa053dd17c32dabfe0de2f629af1f\n","loading configuration file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading weights file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500/pytorch_model.bin\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/checkpoint-1500.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"]}]},{"cell_type":"code","source":["test['label'] = 'none'"],"metadata":{"id":"fXwBBjU7eEsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.tail(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"vkSb4mR8eOqM","executionInfo":{"status":"ok","timestamp":1645617950086,"user_tz":-540,"elapsed":443,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"3db4ca51-a219-413c-b715-a76d7af4b612"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-62aed013-2e97-4419-8703-e0404ec46858\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>506</th>\n","      <td>506</td>\n","      <td>이슈 최율 조재현 성추행 의혹 폭로 소속사 상황 파악 중</td>\n","      <td>얜 그냥 봐도 아니다 ㅋ 고소당하면 어마어마한 금액 물어줘야할껄</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>507</td>\n","      <td>해투4 이서진 한지민 대본 리딩 격리설 해명날씨가 좋아서 컷</td>\n","      <td>대박 게스트 꼭 봐야징 컨셉이 바뀌니깐 재미지넹</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>인터뷰박민영 김비서 행복했다열애설엔 당당미소였으니까</td>\n","      <td>성형으로 다 뜯어고쳐놓고 예쁜척 성형 전 니 얼굴 다 알고있다 순자처럼 된장냄새나게...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>이슈사실무근 캐슬 측 위올라이 표절설 부인여전히 핫종합</td>\n","      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>오창석 이채은 웨딩사진순백의 드레스 입고 활짝</td>\n","      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62aed013-2e97-4419-8703-e0404ec46858')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62aed013-2e97-4419-8703-e0404ec46858 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62aed013-2e97-4419-8703-e0404ec46858');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  ... label\n","506  506  ...  none\n","507  507  ...  none\n","508  508  ...  none\n","509  509  ...  none\n","510  510  ...  none\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["test_label = label_to_num(test['label'].values)\n","\n","tokenized_test = tokenizer(\n","    list(test['title']),\n","    list(test['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","test_dataset = BERTDataset(tokenized_test, test_label)\n","\n","print(test_dataset.__len__())\n","print(test_dataset.__getitem__(510))\n","print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ32SmdTr1uB","executionInfo":{"status":"ok","timestamp":1645618045340,"user_tz":-540,"elapsed":436,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a2cd92fe-c7c2-4711-81f9-e569cc75c7e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["511\n","{'input_ids': tensor([    0, 29203,  2055, 21238,  2073, 11925, 19877,  2017,  2353,  2079,\n","         9605,  1511,  2088, 10682,     2,  1511,  2170,  1284,  2116,  2870,\n","         2052,  3633,  2019,  1513,  5882,  1591,  2029,  2319,  2062,     2,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] 리뷰 골목식당 신흥시장 변화 이끈 백종원의 진심 [SEP] 골목살리고 지가하는 체인점 다입점해서 때돈벌고 피디 술사주고 지가 음식점 체인사업을 때려쳐야 진정성이보이는거지 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","model.eval()\n","output_pred = []\n","output_prob = []\n","\n","for i, data in enumerate(tqdm(dataloader)):\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids=data['input_ids'].to(device),\n","            attention_mask=data['attention_mask'].to(device),\n","            token_type_ids=data['token_type_ids'].to(device)\n","        )\n","    logits = outputs[0]\n","    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n","    logits = logits.detach().cpu().numpy()\n","    result = np.argmax(logits, axis=-1)\n","\n","    output_pred.append(result)\n","    output_prob.append(prob)\n","  \n","pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n","print(pred_answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psDdVv-LedCG","executionInfo":{"status":"ok","timestamp":1645618097932,"user_tz":-540,"elapsed":5341,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"86fb2dd0-f3b0-4ab9-855f-0c421c57d7d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 32/32 [00:05<00:00,  6.39it/s]"]},{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def num_to_label(label):\n","    label_dict = {0: \"none\", 1: \"others\", 2: \"gender\"}\n","    str_label = []\n","\n","    for i, v in enumerate(label):\n","        str_label.append([i,label_dict[v]])\n","    \n","    return str_label\n","\n","answer = num_to_label(pred_answer)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3XbTA96e1c-","executionInfo":{"status":"ok","timestamp":1645618214475,"user_tz":-540,"elapsed":393,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"2601474d-09c3-4f84-f9b6-6384eb1254ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 'none'], [1, 'none'], [2, 'none'], [3, 'none'], [4, 'others'], [5, 'none'], [6, 'others'], [7, 'none'], [8, 'gender'], [9, 'none'], [10, 'none'], [11, 'gender'], [12, 'none'], [13, 'others'], [14, 'none'], [15, 'gender'], [16, 'none'], [17, 'none'], [18, 'none'], [19, 'none'], [20, 'gender'], [21, 'none'], [22, 'others'], [23, 'none'], [24, 'none'], [25, 'none'], [26, 'others'], [27, 'none'], [28, 'none'], [29, 'none'], [30, 'others'], [31, 'gender'], [32, 'none'], [33, 'others'], [34, 'none'], [35, 'gender'], [36, 'none'], [37, 'none'], [38, 'none'], [39, 'none'], [40, 'gender'], [41, 'others'], [42, 'others'], [43, 'none'], [44, 'none'], [45, 'none'], [46, 'none'], [47, 'none'], [48, 'none'], [49, 'gender'], [50, 'others'], [51, 'others'], [52, 'none'], [53, 'gender'], [54, 'none'], [55, 'others'], [56, 'gender'], [57, 'none'], [58, 'others'], [59, 'others'], [60, 'others'], [61, 'gender'], [62, 'none'], [63, 'gender'], [64, 'none'], [65, 'others'], [66, 'none'], [67, 'none'], [68, 'none'], [69, 'others'], [70, 'none'], [71, 'none'], [72, 'none'], [73, 'none'], [74, 'gender'], [75, 'none'], [76, 'gender'], [77, 'none'], [78, 'gender'], [79, 'none'], [80, 'none'], [81, 'none'], [82, 'others'], [83, 'none'], [84, 'none'], [85, 'none'], [86, 'none'], [87, 'others'], [88, 'gender'], [89, 'none'], [90, 'none'], [91, 'none'], [92, 'none'], [93, 'none'], [94, 'none'], [95, 'gender'], [96, 'none'], [97, 'others'], [98, 'none'], [99, 'none'], [100, 'none'], [101, 'none'], [102, 'none'], [103, 'none'], [104, 'gender'], [105, 'none'], [106, 'none'], [107, 'none'], [108, 'none'], [109, 'none'], [110, 'none'], [111, 'none'], [112, 'others'], [113, 'none'], [114, 'others'], [115, 'others'], [116, 'others'], [117, 'none'], [118, 'none'], [119, 'none'], [120, 'none'], [121, 'none'], [122, 'none'], [123, 'others'], [124, 'none'], [125, 'none'], [126, 'gender'], [127, 'gender'], [128, 'none'], [129, 'gender'], [130, 'none'], [131, 'none'], [132, 'none'], [133, 'gender'], [134, 'none'], [135, 'none'], [136, 'others'], [137, 'none'], [138, 'none'], [139, 'none'], [140, 'none'], [141, 'none'], [142, 'gender'], [143, 'none'], [144, 'none'], [145, 'none'], [146, 'none'], [147, 'none'], [148, 'none'], [149, 'none'], [150, 'none'], [151, 'none'], [152, 'none'], [153, 'gender'], [154, 'gender'], [155, 'none'], [156, 'others'], [157, 'others'], [158, 'none'], [159, 'none'], [160, 'none'], [161, 'gender'], [162, 'none'], [163, 'others'], [164, 'gender'], [165, 'gender'], [166, 'none'], [167, 'others'], [168, 'none'], [169, 'none'], [170, 'gender'], [171, 'others'], [172, 'none'], [173, 'none'], [174, 'gender'], [175, 'none'], [176, 'gender'], [177, 'none'], [178, 'gender'], [179, 'none'], [180, 'none'], [181, 'others'], [182, 'gender'], [183, 'none'], [184, 'others'], [185, 'none'], [186, 'none'], [187, 'others'], [188, 'none'], [189, 'none'], [190, 'none'], [191, 'others'], [192, 'none'], [193, 'none'], [194, 'none'], [195, 'none'], [196, 'gender'], [197, 'others'], [198, 'none'], [199, 'none'], [200, 'none'], [201, 'none'], [202, 'gender'], [203, 'none'], [204, 'gender'], [205, 'none'], [206, 'none'], [207, 'none'], [208, 'none'], [209, 'none'], [210, 'others'], [211, 'others'], [212, 'none'], [213, 'none'], [214, 'none'], [215, 'gender'], [216, 'gender'], [217, 'none'], [218, 'others'], [219, 'none'], [220, 'none'], [221, 'none'], [222, 'gender'], [223, 'none'], [224, 'none'], [225, 'none'], [226, 'others'], [227, 'none'], [228, 'none'], [229, 'none'], [230, 'gender'], [231, 'none'], [232, 'none'], [233, 'none'], [234, 'gender'], [235, 'none'], [236, 'none'], [237, 'none'], [238, 'none'], [239, 'none'], [240, 'others'], [241, 'others'], [242, 'gender'], [243, 'none'], [244, 'none'], [245, 'none'], [246, 'gender'], [247, 'none'], [248, 'none'], [249, 'none'], [250, 'none'], [251, 'none'], [252, 'none'], [253, 'none'], [254, 'none'], [255, 'none'], [256, 'none'], [257, 'none'], [258, 'gender'], [259, 'gender'], [260, 'none'], [261, 'none'], [262, 'none'], [263, 'none'], [264, 'others'], [265, 'none'], [266, 'others'], [267, 'gender'], [268, 'none'], [269, 'none'], [270, 'others'], [271, 'gender'], [272, 'none'], [273, 'none'], [274, 'others'], [275, 'none'], [276, 'others'], [277, 'none'], [278, 'none'], [279, 'others'], [280, 'none'], [281, 'gender'], [282, 'gender'], [283, 'none'], [284, 'none'], [285, 'none'], [286, 'none'], [287, 'gender'], [288, 'none'], [289, 'none'], [290, 'none'], [291, 'none'], [292, 'others'], [293, 'none'], [294, 'others'], [295, 'none'], [296, 'others'], [297, 'others'], [298, 'none'], [299, 'none'], [300, 'gender'], [301, 'gender'], [302, 'none'], [303, 'none'], [304, 'none'], [305, 'none'], [306, 'none'], [307, 'none'], [308, 'none'], [309, 'none'], [310, 'none'], [311, 'others'], [312, 'gender'], [313, 'gender'], [314, 'gender'], [315, 'none'], [316, 'none'], [317, 'gender'], [318, 'others'], [319, 'none'], [320, 'none'], [321, 'none'], [322, 'none'], [323, 'none'], [324, 'none'], [325, 'others'], [326, 'none'], [327, 'none'], [328, 'others'], [329, 'none'], [330, 'others'], [331, 'none'], [332, 'others'], [333, 'none'], [334, 'others'], [335, 'none'], [336, 'none'], [337, 'gender'], [338, 'none'], [339, 'none'], [340, 'others'], [341, 'none'], [342, 'gender'], [343, 'none'], [344, 'others'], [345, 'none'], [346, 'none'], [347, 'gender'], [348, 'gender'], [349, 'none'], [350, 'none'], [351, 'others'], [352, 'none'], [353, 'none'], [354, 'none'], [355, 'none'], [356, 'none'], [357, 'others'], [358, 'gender'], [359, 'others'], [360, 'none'], [361, 'others'], [362, 'none'], [363, 'none'], [364, 'none'], [365, 'gender'], [366, 'others'], [367, 'none'], [368, 'none'], [369, 'none'], [370, 'none'], [371, 'others'], [372, 'none'], [373, 'none'], [374, 'gender'], [375, 'none'], [376, 'gender'], [377, 'none'], [378, 'none'], [379, 'none'], [380, 'none'], [381, 'none'], [382, 'none'], [383, 'none'], [384, 'none'], [385, 'none'], [386, 'gender'], [387, 'none'], [388, 'gender'], [389, 'none'], [390, 'none'], [391, 'none'], [392, 'none'], [393, 'gender'], [394, 'others'], [395, 'none'], [396, 'gender'], [397, 'none'], [398, 'none'], [399, 'none'], [400, 'others'], [401, 'gender'], [402, 'none'], [403, 'none'], [404, 'others'], [405, 'others'], [406, 'others'], [407, 'gender'], [408, 'none'], [409, 'none'], [410, 'none'], [411, 'none'], [412, 'gender'], [413, 'none'], [414, 'none'], [415, 'none'], [416, 'none'], [417, 'none'], [418, 'none'], [419, 'others'], [420, 'others'], [421, 'others'], [422, 'none'], [423, 'none'], [424, 'none'], [425, 'none'], [426, 'none'], [427, 'none'], [428, 'none'], [429, 'gender'], [430, 'gender'], [431, 'none'], [432, 'gender'], [433, 'none'], [434, 'none'], [435, 'none'], [436, 'none'], [437, 'none'], [438, 'gender'], [439, 'none'], [440, 'others'], [441, 'others'], [442, 'others'], [443, 'gender'], [444, 'none'], [445, 'gender'], [446, 'gender'], [447, 'gender'], [448, 'none'], [449, 'gender'], [450, 'none'], [451, 'gender'], [452, 'none'], [453, 'none'], [454, 'none'], [455, 'gender'], [456, 'none'], [457, 'none'], [458, 'gender'], [459, 'none'], [460, 'none'], [461, 'none'], [462, 'none'], [463, 'none'], [464, 'gender'], [465, 'none'], [466, 'others'], [467, 'none'], [468, 'others'], [469, 'none'], [470, 'gender'], [471, 'gender'], [472, 'none'], [473, 'none'], [474, 'gender'], [475, 'none'], [476, 'gender'], [477, 'others'], [478, 'gender'], [479, 'none'], [480, 'none'], [481, 'none'], [482, 'none'], [483, 'gender'], [484, 'none'], [485, 'none'], [486, 'none'], [487, 'none'], [488, 'none'], [489, 'none'], [490, 'none'], [491, 'others'], [492, 'none'], [493, 'none'], [494, 'others'], [495, 'none'], [496, 'none'], [497, 'none'], [498, 'gender'], [499, 'others'], [500, 'others'], [501, 'others'], [502, 'none'], [503, 'none'], [504, 'others'], [505, 'none'], [506, 'none'], [507, 'none'], [508, 'others'], [509, 'none'], [510, 'none']]\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(answer, columns=['ID', 'bias'])\n","\n","df.to_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/mybaseline_submit01.csv', index=False) # 매번 파일 이름 바꿔주자\n","\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRwDbvC7fTI-","executionInfo":{"status":"ok","timestamp":1645618640746,"user_tz":-540,"elapsed":403,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"1f82d59c-9039-4156-8dee-d2c5b60eec3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      ID    bias\n","0      0    none\n","1      1    none\n","2      2    none\n","3      3    none\n","4      4  others\n","..   ...     ...\n","506  506    none\n","507  507    none\n","508  508  others\n","509  509    none\n","510  510    none\n","\n","[511 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["df.head(7) # 6번 row 제대로 판별 했구만 ?"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"-AqtcuoPgI63","executionInfo":{"status":"ok","timestamp":1645618641156,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"5daa2e73-c971-4baa-975b-59d0c571824a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9d58a9f7-7324-4b98-8b25-c9940e9ab0d4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>bias</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>others</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>others</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d58a9f7-7324-4b98-8b25-c9940e9ab0d4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d58a9f7-7324-4b98-8b25-c9940e9ab0d4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d58a9f7-7324-4b98-8b25-c9940e9ab0d4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   ID    bias\n","0   0    none\n","1   1    none\n","2   2    none\n","3   3    none\n","4   4  others\n","5   5    none\n","6   6  others"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["# bias 끝"],"metadata":{"id":"Z3zDCpTFtXLE"}},{"cell_type":"markdown","source":["# 이제 hate 모델을 만들어 보자\n","bias 와 똑같이 진행 하되, Number of classes 를 2로 바꾸고 label column 을 바꿔주자"],"metadata":{"id":"BoHcitU6g_AT"}},{"cell_type":"code","source":["# tokenizer 는 위에서 이미 load 되어 있으므로 생략 해도됨(아마도)\n","MODEL_NAME = 모델  # 위에 test 할때 MODEL_NAME 변수에 checkpoint-1500 모델로 저장되어 있어서 새로 불러옴 ㅇㅇ\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","config = AutoConfig.from_pretrained(MODEL_NAME)\n","config.num_labels = 2 # 이거 바꿔줘야됨 . hate 는 라벨링이  none, hate 두개니까 \n","\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n","\n","print(model)\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3L9DUf0Ygjby","executionInfo":{"status":"ok","timestamp":1645619113437,"user_tz":-540,"elapsed":10347,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"0c0655da-7c28-4fcb-d503-8fb320e09dad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/klue/roberta-large/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/4eb906e7d0da2b04e56c7cc31ba068d7c295240a51690153c2ced71c9e4c9fc5.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/360b579947002f14f22331a026821b56f70679f1be1e95fe5dc5a80edc4a59e0.44c30ade4958fcfd446e66025e10a5b380cdd0bbe9b3fb7a794f357e7f0f34c2\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1a24ab4628028ed80dea35ce3334a636dc656fd9a17a09bad377f88f0cbecdac.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8f31ccbd66730704a8400c96db0647b10c47cd0c838ea2cabf0a86ef878f31cf.5b0ba083b234382bb4c99ee0c9f4fca4cadaa053dd17c32dabfe0de2f629af1f\n","loading configuration file https://huggingface.co/klue/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/571e05a2160c18c93365862223c4dae92bbd1b41464a4bd5f372ad703dba6097.ae5b7f8d8a28a3ff0b1560b4d08c6c3bd80f627288eee2024e02959dd60380d0\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"klue/roberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading weights file https://huggingface.co/klue/roberta-large/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/fd91c85effc137c99cd14cfe5c3459faa223c005b1577dc2c5aa48f6b2c4fbb1.3d5d467e78cd19d9a87029910ed83289edde0111a75a41e0cc79ad3fc06e4a51\n","Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n","  )\n",")\n","RobertaConfig {\n","  \"_name_or_path\": \"klue/roberta-large\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n"]}]},{"cell_type":"code","source":["train.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"Jdi3gDunjFEz","executionInfo":{"status":"ok","timestamp":1645619325436,"user_tz":-540,"elapsed":553,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"59ea891c-ad91-4df3-8e87-cce95e143e65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0bb90ea7-4395-414f-965a-4f64a2754d2c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bb90ea7-4395-414f-965a-4f64a2754d2c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0bb90ea7-4395-414f-965a-4f64a2754d2c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0bb90ea7-4395-414f-965a-4f64a2754d2c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                 title         comment label  hate\n","0  미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  김태리 정말 연기잘해 진짜  none  none"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["train.rename(columns = {'label':'bias', 'hate':'label'},inplace=True) # label -> bias ,  hate -> label   아니면 train dataset 새로 불러오던가."],"metadata":{"id":"TcCSTjMriRf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"e08WxC-vjg4C","executionInfo":{"status":"ok","timestamp":1645619331960,"user_tz":-540,"elapsed":417,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"545bec6c-fc9c-46b0-b0ec-200a9db2db4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-78b7a565-2cd7-43d4-ba80-d95b61c239ed\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>bias</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n","      <td>김태리 정말 연기잘해 진짜</td>\n","      <td>none</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78b7a565-2cd7-43d4-ba80-d95b61c239ed')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-78b7a565-2cd7-43d4-ba80-d95b61c239ed button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-78b7a565-2cd7-43d4-ba80-d95b61c239ed');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                 title         comment  bias label\n","0  미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는  김태리 정말 연기잘해 진짜  none  none"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["train_dataset, eval_dataset = train_test_split(train, test_size=0.1, shuffle=True, stratify=train['label'])\n","\n","tokenized_train = tokenizer(\n","    list(train_dataset['title']),\n","    list(train_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128, # Max_Length = 138\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","tokenized_eval = tokenizer(\n","    list(eval_dataset['title']),\n","    list(eval_dataset['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","print(tokenized_train['input_ids'][0])\n","print(tokenizer.decode(tokenized_train['input_ids'][0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3EgAkwjjj5K","executionInfo":{"status":"ok","timestamp":1645619431632,"user_tz":-540,"elapsed":1175,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"f26981a3-dcb2-41d0-ad97-f330fa8891f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([    0,   732,  3658,  2444,  2156,  2348,  2079,  1045,  2195, 15350,\n","        13000,  2118,  2170,   852,  2084,  2251,  7473,  4339,     2,  1377,\n","         2546,  3615,  3611,  2031,  1160,  2460, 24006,  2052,  9887,  3725,\n","            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1])\n","[CLS] 내 이상형연애의 맛3 정준 김유지에 돌직구 고백 종합 [SEP] 악플 다는 사람들 보면 제정신이 아님 ㅋㅋ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["# hate label 에 맞게 바꿔주자   # 좀더 깔끔한 방법이 있을거같은데 일단 ㄱ\n","def hate_to_num(label): \n","    label_dict = {\"none\": 0, \"hate\": 1}\n","    num_label = []\n","\n","    for v in label: \n","        num_label.append(label_dict[v])\n","    \n","    return num_label\n","\n","\n","train_label = hate_to_num(train_dataset['label'].values)\n","eval_label = hate_to_num(eval_dataset['label'].values)"],"metadata":{"id":"aUTVAXVFj8C2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = BERTDataset(tokenized_train, train_label)\n","eval_dataset = BERTDataset(tokenized_eval, eval_label)\n","\n","print(train_dataset.__len__())\n","print(train_dataset.__getitem__(7529))\n","print(tokenizer.decode(train_dataset.__getitem__(7529)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGYsPDqikkLe","executionInfo":{"status":"ok","timestamp":1645619632527,"user_tz":-540,"elapsed":399,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"42869ece-584b-47e7-e90a-b93d930cc496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7530\n","{'input_ids': tensor([    0,  3861,  2205,  2232,  1632, 29303,  2288, 18605,  1839,  7285,\n","         1504,  3333,  2264,  1028,  3333,  2264,  8455,  2259,     3, 25740,\n","            2,  8902,  2079,  5581,  2015,  2456,  3797,  3915,  2097,  2178,\n","         2155, 13764,  2125,  2052,  2088, 12813, 28674,  4296,  2855,  2765,\n","         2069,  4296,  4695,  2371,  2075,  4429,  2015,  2456,  6233,  4121,\n","         4538,  4224,  4697,  2443,  2227,  1891, 13911,  2170,  5414,  2456,\n","         2318,  5657, 11187,  3635,  2116,   859,  2259,  8902,  2052,  2529,\n","         2251,  2083,  2042,  2302,  2210,  5414,  2369,  2181,  5261,     2,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0]), 'label': tensor(0)}\n","[CLS] 방송하차 차태현김준호 팬들이 이멤버 리멤버 외치는 [UNK] 레터 [SEP] 도박의 처벌기준부터 확인해보자 상습적이고 고액이다 얼마나큰돈을 얼마나 자주했나 소득기준으로 적용한다 근데 재미삼아 한 내기에 돌려준게 도덕적으로 문제가 되는 도박이냐구1박2일 돌려내라 당장 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["training_ars = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates',\n","    num_train_epochs=7,\n","    per_device_train_batch_size=32,\n","    save_total_limit=5,\n","    save_steps=250,\n","    evaluation_strategy='steps',\n","    eval_steps = 250,\n","    load_best_model_at_end = True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_ars,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tLp8X2zksCs","executionInfo":{"status":"ok","timestamp":1645619827038,"user_tz":-540,"elapsed":1006,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"6d48cd1f-0809-4b68-84f7-6592f515cc00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["trainer.train()\n","model.save_pretrained('/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/best_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_5NB1aQ_lcoD","executionInfo":{"status":"ok","timestamp":1645621694244,"user_tz":-540,"elapsed":1796322,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"b2bb6d7d-2ac7-4d7c-f73a-7ef7c1507da1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 7530\n","  Num Epochs = 7\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1652\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1652' max='1652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1652/1652 29:49, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>250</td>\n","      <td>No log</td>\n","      <td>0.467408</td>\n","      <td>0.789725</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.453600</td>\n","      <td>0.585727</td>\n","      <td>0.787336</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.453600</td>\n","      <td>1.051632</td>\n","      <td>0.789725</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.151500</td>\n","      <td>1.011236</td>\n","      <td>0.807646</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.151500</td>\n","      <td>0.989286</td>\n","      <td>0.816010</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.040300</td>\n","      <td>1.239340</td>\n","      <td>0.801673</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-750\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-750/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-750/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1000/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 837\n","  Batch size = 8\n","Saving model checkpoint to /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1500\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1500/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-500] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-250 (score: 0.4674084186553955).\n","Configuration saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/best_model/config.json\n","Model weights saved in /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/best_model/pytorch_model.bin\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","Tokenizer_NAME = 모델\n","tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n","\n","MODEL_NAME = '/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250'  # checkpoint 마다 미리 지정해둔 경로에 모델 저장됨 ㅇㅇ\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n","model.resize_token_embeddings(tokenizer.vocab_size)\n","model.to(device)\n","\n","print(tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzEze2bTluMI","executionInfo":{"status":"ok","timestamp":1645621943680,"user_tz":-540,"elapsed":14847,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"9c697c18-1fcc-4fb8-e9ee-e1c06c3453aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/klue/roberta-large/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/4eb906e7d0da2b04e56c7cc31ba068d7c295240a51690153c2ced71c9e4c9fc5.d1b86bed49516351c7bb29b19d7e7be2ab53b931bcb1f9b2aacfb71f2124d25a\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/360b579947002f14f22331a026821b56f70679f1be1e95fe5dc5a80edc4a59e0.44c30ade4958fcfd446e66025e10a5b380cdd0bbe9b3fb7a794f357e7f0f34c2\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1a24ab4628028ed80dea35ce3334a636dc656fd9a17a09bad377f88f0cbecdac.70c17d6e4d492c8f24f5bb97ab56c7f272e947112c6faf9dd846da42ba13eb23\n","loading file https://huggingface.co/klue/roberta-large/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8f31ccbd66730704a8400c96db0647b10c47cd0c838ea2cabf0a86ef878f31cf.5b0ba083b234382bb4c99ee0c9f4fca4cadaa053dd17c32dabfe0de2f629af1f\n","loading configuration file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250\",\n","  \"architectures\": [\n","    \"RobertaForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"problem_type\": \"single_label_classification\",\n","  \"tokenizer_class\": \"BertTokenizer\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.16.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","loading weights file /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250/pytorch_model.bin\n","All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n","\n","All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/AIConnect/NLP_classificaiton/result/hates/checkpoint-1250.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"]}]},{"cell_type":"code","source":["test['label'] = 'none' # label column 생성 아무값으로 ㄱ"],"metadata":{"id":"ygUjBUnjteAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"jYisOEXftlKQ","executionInfo":{"status":"ok","timestamp":1645621963427,"user_tz":-540,"elapsed":441,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"0ecbd296-6348-4d53-bad5-dd04b850cde6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-90925341-2848-47a7-90da-55edc6426f7c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>title</th>\n","      <th>comment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>인터뷰박민영 김비서 행복했다열애설엔 당당미소였으니까</td>\n","      <td>성형으로 다 뜯어고쳐놓고 예쁜척 성형 전 니 얼굴 다 알고있다 순자처럼 된장냄새나게...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>이슈사실무근 캐슬 측 위올라이 표절설 부인여전히 핫종합</td>\n","      <td>분위기는 비슷하다만 전혀다른 전개던데 무슨ㅋㅋㄱ 우리나라사람들은 분위기만 비슷하면 ...</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>오창석 이채은 웨딩사진순백의 드레스 입고 활짝</td>\n","      <td>입에 손가릭이 10개 있으니 징그럽다</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90925341-2848-47a7-90da-55edc6426f7c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-90925341-2848-47a7-90da-55edc6426f7c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-90925341-2848-47a7-90da-55edc6426f7c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  ... label\n","508  508  ...  none\n","509  509  ...  none\n","510  510  ...  none\n","\n","[3 rows x 4 columns]"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["test_label = label_to_num(test['label'].values)\n","\n","tokenized_test = tokenizer(\n","    list(test['title']),\n","    list(test['comment']),\n","    return_tensors=\"pt\",\n","    max_length=128,\n","    padding=True,\n","    truncation=True,\n","    add_special_tokens=True\n",")\n","\n","test_dataset = BERTDataset(tokenized_test, test_label)\n","\n","print(test_dataset.__len__())\n","print(test_dataset.__getitem__(510))\n","print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuVzWbwutmXn","executionInfo":{"status":"ok","timestamp":1645621974700,"user_tz":-540,"elapsed":459,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"34213213-a8e0-490c-c2a1-924343dee357"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["511\n","{'input_ids': tensor([    0, 29203,  2055, 21238,  2073, 11925, 19877,  2017,  2353,  2079,\n","         9605,  1511,  2088, 10682,     2,  1511,  2170,  1284,  2116,  2870,\n","         2052,  3633,  2019,  1513,  5882,  1591,  2029,  2319,  2062,     2,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'label': tensor(0)}\n","[CLS] 리뷰 골목식당 신흥시장 변화 이끈 백종원의 진심 [SEP] 골목살리고 지가하는 체인점 다입점해서 때돈벌고 피디 술사주고 지가 음식점 체인사업을 때려쳐야 진정성이보이는거지 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","model.eval()\n","output_pred = []\n","output_prob = []\n","\n","for i, data in enumerate(tqdm(dataloader)):\n","    with torch.no_grad():\n","        outputs = model(\n","            input_ids=data['input_ids'].to(device),\n","            attention_mask=data['attention_mask'].to(device),\n","            token_type_ids=data['token_type_ids'].to(device)\n","        )\n","    logits = outputs[0]\n","    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n","    logits = logits.detach().cpu().numpy()\n","    result = np.argmax(logits, axis=-1)\n","\n","    output_pred.append(result)\n","    output_prob.append(prob)\n","  \n","pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n","print(pred_answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1dKn7gZtpFo","executionInfo":{"status":"ok","timestamp":1645622045593,"user_tz":-540,"elapsed":5134,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"6102ff6f-536f-497d-fd6e-179b920e5679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 32/32 [00:04<00:00,  6.55it/s]"]},{"output_type":"stream","name":"stdout","text":["[0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["print(output_prob) # 오.. 이거 확률값.. threshold 가능 할듯 ?"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsR_LdYtt5Of","executionInfo":{"status":"ok","timestamp":1645622054830,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"8a306942-6b71-4c32-f614-91836299c8fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.9991170763969421, 0.0008829247672110796], [0.9991083741188049, 0.0008915908401831985], [0.005740121938288212, 0.9942598342895508], [0.001996200531721115, 0.9980037808418274], [0.10336023569107056, 0.8966397047042847], [0.009613646194338799, 0.9903863668441772], [0.002178217051550746, 0.9978218078613281], [0.0021807036828249693, 0.9978193044662476], [0.0025114610325545073, 0.9974884986877441], [0.9991784691810608, 0.0008215216803364456], [0.9989328980445862, 0.0010671279160305858], [0.0024257157929241657, 0.9975742697715759], [0.999099612236023, 0.0009004544117487967], [0.0024377668742090464, 0.9975622892379761], [0.9990532994270325, 0.0009466661140322685], [0.0024462358560413122, 0.9975537657737732], [0.007877831347286701, 0.9921221137046814], [0.004515606444329023, 0.995484471321106], [0.0027138672303408384, 0.9972860813140869], [0.9991201758384705, 0.000879871950019151], [0.001997800078243017, 0.9980022311210632], [0.9990386962890625, 0.0009612852591089904], [0.0025519756600260735, 0.9974480867385864], [0.0033760671503841877, 0.9966239929199219], [0.3210553526878357, 0.6789446473121643], [0.9990531802177429, 0.0009467864874750376], [0.0019930133130401373, 0.9980069994926453], [0.9988424181938171, 0.0011576461838558316], [0.999052107334137, 0.0009478723513893783], [0.9945859909057617, 0.005413992330431938], [0.002050118986517191, 0.9979498982429504], [0.0023966259323060513, 0.9976033568382263], [0.002520263660699129, 0.9974797368049622], [0.5997610092163086, 0.40023893117904663], [0.9986528158187866, 0.0013471627607941628], [0.0021568017546087503, 0.9978431463241577], [0.0026196062099188566, 0.9973803162574768], [0.003838583594188094, 0.9961614608764648], [0.9162760376930237, 0.08372389525175095], [0.9989707469940186, 0.0010293233208358288], [0.0022126282565295696, 0.997787356376648], [0.0034828102216124535, 0.9965171813964844], [0.002397095551714301, 0.9976028800010681], [0.004294155165553093, 0.9957059025764465], [0.9991948008537292, 0.0008052342454902828], [0.9581207633018494, 0.04187920689582825], [0.002289021387696266, 0.9977109432220459], [0.00321008637547493, 0.9967898726463318], [0.923902690410614, 0.0760972797870636], [0.002177957911044359, 0.9978220462799072], [0.0033477337565273046, 0.9966523051261902], [0.9991787075996399, 0.0008212884422391653], [0.0026561422273516655, 0.9973438382148743], [0.0020084527786821127, 0.9979915618896484], [0.9987977743148804, 0.0012021614238619804], [0.0026292921975255013, 0.997370719909668], [0.0021547095384448767, 0.9978452920913696], [0.9992111921310425, 0.0007887720130383968], [0.9979174733161926, 0.002082576509565115], [0.0021294865291565657, 0.9978704452514648], [0.001969781704246998, 0.9980302453041077], [0.0024009940680116415, 0.9975990653038025], [0.9986191987991333, 0.0013808583607897162], [0.0024648327380418777, 0.9975351095199585], [0.004330132622271776, 0.9956698417663574], [0.0043168640695512295, 0.9956831932067871], [0.01553285215049982, 0.9844671487808228], [0.002284439280629158, 0.9977155923843384], [0.998806357383728, 0.0011936710216104984], [0.002051959978416562, 0.9979481101036072], [0.9992051720619202, 0.0007949084974825382], [0.002633179072290659, 0.9973668456077576], [0.039978161454200745, 0.9600217938423157], [0.0028223670087754726, 0.9971776008605957], [0.0023685304913669825, 0.9976314306259155], [0.9989597797393799, 0.0010401871986687183], [0.05435005575418472, 0.9456499218940735], [0.003961459267884493, 0.996038556098938], [0.0044537680223584175, 0.9955462217330933], [0.004658650606870651, 0.9953413009643555], [0.002350668655708432, 0.9976493716239929], [0.0052336654625833035, 0.994766354560852], [0.9973655343055725, 0.0026345294900238514], [0.9991260170936584, 0.0008739870390854776], [0.0045135668478906155, 0.9954864382743835], [0.9991331696510315, 0.0008668685331940651], [0.009827516973018646, 0.9901725053787231], [0.0018946697236970067, 0.9981052875518799], [0.0024993359111249447, 0.9975007176399231], [0.9992290735244751, 0.000770951563026756], [0.999182403087616, 0.0008176137926056981], [0.0028309356421232224, 0.9971690773963928], [0.0030250237323343754, 0.9969749450683594], [0.0028148635756224394, 0.9971851706504822], [0.9962173104286194, 0.003782638581469655], [0.0021377329248934984, 0.9978622794151306], [0.003942757844924927, 0.9960572719573975], [0.4848281145095825, 0.5151718854904175], [0.2999598979949951, 0.7000401020050049], [0.002158541465178132, 0.997841477394104], [0.9984253644943237, 0.0015746549470350146], [0.002832297934219241, 0.9971676468849182], [0.999001681804657, 0.000998285016976297], [0.9991256594657898, 0.0008742964710108936], [0.0021460349671542645, 0.9978539347648621], [0.9987032413482666, 0.0012967130169272423], [0.05649862065911293, 0.943501353263855], [0.002654612995684147, 0.9973453879356384], [0.993081271648407, 0.0069187721237540245], [0.9987290501594543, 0.0012709832517430186], [0.999221920967102, 0.0007781224558129907], [0.002862097229808569, 0.9971379041671753], [0.0028447324875742197, 0.9971553087234497], [0.06896670907735825, 0.9310332536697388], [0.7124699950218201, 0.2875300347805023], [0.004936792887747288, 0.9950632452964783], [0.0023527874145656824, 0.997647225856781], [0.9594645500183105, 0.040535423904657364], [0.05528794229030609, 0.9447119832038879], [0.9991430044174194, 0.000856917817145586], [0.998939573764801, 0.0010604499839246273], [0.9982911944389343, 0.0017087545711547136], [0.15352250635623932, 0.8464775085449219], [0.0044831507839262486, 0.995516836643219], [0.00394836813211441, 0.9960516095161438], [0.0024804214481264353, 0.9975195527076721], [0.0021014022640883923, 0.9978985786437988], [0.0025767290499061346, 0.9974232912063599], [0.9992140531539917, 0.0007859157049097121], [0.0027372753247618675, 0.997262716293335], [0.01400022953748703, 0.9859997630119324], [0.0023387556429952383, 0.9976612329483032], [0.9992102384567261, 0.0007896834868006408], [0.0024894587695598602, 0.997510552406311], [0.0567191019654274, 0.9432808756828308], [0.0038385342340916395, 0.9961614608764648], [0.002591322176158428, 0.9974086880683899], [0.9991651773452759, 0.0008348225383087993], [0.9988813996315002, 0.001118563232012093], [0.003503495128825307, 0.9964964985847473], [0.9986498951911926, 0.0013501381035894156], [0.002003176137804985, 0.9979967474937439], [0.0020505348220467567, 0.9979495406150818], [0.9602662920951843, 0.03973374143242836], [0.9988511800765991, 0.0011487735901027918], [0.9987248778343201, 0.0012751154135912657], [0.9989173412322998, 0.0010826854268088937], [0.9960659146308899, 0.003934095147997141], [0.9980854988098145, 0.0019145483383908868], [0.04108009487390518, 0.958919882774353], [0.002468792023137212, 0.9975312352180481], [0.9990665316581726, 0.0009334351634606719], [0.9991282820701599, 0.0008717153104953468], [0.0031784684397280216, 0.9968215227127075], [0.0025387010537087917, 0.9974613189697266], [0.9979137778282166, 0.0020862065721303225], [0.0021597635932266712, 0.997840166091919], [0.001874385285191238, 0.9981256127357483], [0.0029898881912231445, 0.9970101118087769], [0.9992488026618958, 0.0007511972216889262], [0.998784601688385, 0.001215385040268302], [0.0020228608045727015, 0.9979771971702576], [0.9988117218017578, 0.0011882460676133633], [0.002686555264517665, 0.9973134398460388], [0.002323844702914357, 0.9976761937141418], [0.002229222096502781, 0.9977707862854004], [0.9958568215370178, 0.004143161699175835], [0.002878860104829073, 0.9971211552619934], [0.002347321715205908, 0.9976527094841003], [0.9988901019096375, 0.0011098860995844007], [0.002327630529180169, 0.9976723790168762], [0.002505161566659808, 0.9974948167800903], [0.9986006617546082, 0.0013993692118674517], [0.999097466468811, 0.0009025390609167516], [0.0027553963009268045, 0.9972445964813232], [0.002601690124720335, 0.9973983764648438], [0.0019958901684731245, 0.998004138469696], [0.9990725517272949, 0.000927418121136725], [0.001947705284692347, 0.9980523586273193], [0.998672366142273, 0.0013276877580210567], [0.999148964881897, 0.0008509880281053483], [0.9030505418777466, 0.0969494953751564], [0.005825582426041365, 0.9941744208335876], [0.9990859031677246, 0.0009140517795458436], [0.001948159420862794, 0.9980518817901611], [0.003662337316200137, 0.9963376522064209], [0.9989383816719055, 0.0010616149520501494], [0.0026856944896280766, 0.9973142743110657], [0.011211346834897995, 0.9887886643409729], [0.004264784045517445, 0.9957351684570312], [0.9986781477928162, 0.0013218007516115904], [0.002152983797714114, 0.9978469610214233], [0.0021363685373216867, 0.9978635907173157], [0.0024998863227665424, 0.9975001215934753], [0.9988110065460205, 0.001189053407870233], [0.9980410933494568, 0.00195888034068048], [0.003119980450719595, 0.996880054473877], [0.003143408102914691, 0.9968565702438354], [0.002672566333785653, 0.997327446937561], [0.9989584684371948, 0.0010415586875751615], [0.009095689281821251, 0.9909042716026306], [0.021291492506861687, 0.9787084460258484], [0.0022329979110509157, 0.9977669715881348], [0.12593086063861847, 0.8740691542625427], [0.0022187004797160625, 0.9977813363075256], [0.006045146379619837, 0.9939548373222351], [0.9991063475608826, 0.0008936056401580572], [0.15383069217205048, 0.8461693525314331], [0.0027258519548922777, 0.9972741007804871], [0.003511102870106697, 0.9964889287948608], [0.9452925324440002, 0.05470745638012886], [0.00246409815736115, 0.9975359439849854], [0.9989593029022217, 0.0010407428489997983], [0.9948518872261047, 0.0051481518894433975], [0.9990854263305664, 0.0009145265794359148], [0.00945377815514803, 0.9905462265014648], [0.13728199899196625, 0.8627179861068726], [0.9699992537498474, 0.030000697821378708], [0.0020627230405807495, 0.9979373216629028], [0.0038403086364269257, 0.9961596727371216], [0.005194658413529396, 0.9948053956031799], [0.0031064588110893965, 0.9968935251235962], [0.9962867498397827, 0.003713206620886922], [0.0020624774042516947, 0.9979375600814819], [0.0022185323759913445, 0.9977814555168152], [0.9989598989486694, 0.0010400534374639392], [0.002535125706344843, 0.9974648952484131], [0.9992363452911377, 0.0007637077942490578], [0.005856586620211601, 0.9941434264183044], [0.003655875800177455, 0.9963441491127014], [0.0024172740522772074, 0.9975826740264893], [0.9990078806877136, 0.0009921119781211019], [0.0042679887264966965, 0.9957320094108582], [0.0028392584063112736, 0.997160792350769], [0.002254956169053912, 0.9977450370788574], [0.09613856673240662, 0.9038614630699158], [0.9986885190010071, 0.001311439205892384], [0.9989500641822815, 0.0010499386116862297], [0.998918890953064, 0.0010810754029080272], [0.0028155192267149687, 0.9971844553947449], [0.0022416221909224987, 0.9977583885192871], [0.0034423801116645336, 0.9965575933456421], [0.04270513728260994, 0.9572948217391968], [0.9990240335464478, 0.000975990085862577], [0.9991437196731567, 0.0008562554721720517], [0.4909833073616028, 0.5090166926383972], [0.002224493771791458, 0.9977754950523376], [0.004017981700599194, 0.9959820508956909], [0.9575501084327698, 0.042449936270713806], [0.025133727118372917, 0.9748662710189819], [0.9857974648475647, 0.014202517457306385], [0.9989838004112244, 0.0010161937680095434], [0.002915561432018876, 0.9970844388008118], [0.0037375858519226313, 0.9962623715400696], [0.002369802910834551, 0.9976301193237305], [0.9991685152053833, 0.0008315480081364512], [0.5045309662818909, 0.4954690933227539], [0.9785030484199524, 0.021496890112757683], [0.001824989914894104, 0.9981750249862671], [0.00729840574786067, 0.992701530456543], [0.0034995204769074917, 0.9965004920959473], [0.042946554720401764, 0.9570534825325012], [0.002323042368516326, 0.9976770281791687], [0.9953296184539795, 0.0046704597771167755], [0.9955684542655945, 0.004431606270372868], [0.999239444732666, 0.0007605557912029326], [0.00232878141105175, 0.9976711869239807], [0.0029136380180716515, 0.9970863461494446], [0.002732306020334363, 0.9972677230834961], [0.999152421951294, 0.000847565708681941], [0.0019207040313631296, 0.9980792999267578], [0.002608146984130144, 0.9973918199539185], [0.9988663196563721, 0.001133727841079235], [0.9989595413208008, 0.001040480099618435], [0.010252689942717552, 0.9897472858428955], [0.9991244673728943, 0.0008754834998399019], [0.004464093595743179, 0.9955359697341919], [0.003206492168828845, 0.9967934489250183], [0.003258539829403162, 0.9967414736747742], [0.8288763761520386, 0.17112357914447784], [0.9955427050590515, 0.004457283299416304], [0.002879213308915496, 0.9971207976341248], [0.0019233960192650557, 0.9980765581130981], [0.9992050528526306, 0.000794996740296483], [0.9959291815757751, 0.004070831462740898], [0.9988570213317871, 0.0011430123122408986], [0.0024848179891705513, 0.9975152015686035], [0.003521555569022894, 0.9964784979820251], [0.9992376565933228, 0.000762332056183368], [0.025226721540093422, 0.9747732281684875], [0.9865684509277344, 0.013431547209620476], [0.002983794780448079, 0.997016191482544], [0.0031194700859487057, 0.9968805313110352], [0.998954176902771, 0.0010458091273903847], [0.0019018376478925347, 0.9980981945991516], [0.9990969896316528, 0.0009030372020788491], [0.0023624238092452288, 0.9976376295089722], [0.0020720777101814747, 0.9979279041290283], [0.9991793036460876, 0.0008206508355215192], [0.9989989399909973, 0.0010011147242039442], [0.0022918067406862974, 0.9977082014083862], [0.9988921284675598, 0.0011078548850491643], [0.9983643889427185, 0.001635618507862091], [0.001974677899852395, 0.9980252981185913], [0.002921842038631439, 0.9970781803131104], [0.9547002911567688, 0.0452997200191021], [0.9990382194519043, 0.0009618656476959586], [0.0029931801836937666, 0.9970068335533142], [0.9978410005569458, 0.0021590199321508408], [0.002357696881517768, 0.9976422190666199], [0.9989435076713562, 0.0010565449483692646], [0.008590154349803925, 0.9914098381996155], [0.0018819100223481655, 0.9981181621551514], [0.002135541057214141, 0.9978644251823425], [0.0022165183909237385, 0.9977834820747375], [0.024057436734437943, 0.9759425520896912], [0.9982044696807861, 0.0017954986542463303], [0.002226589946076274, 0.9977733492851257], [0.002833515638485551, 0.9971664547920227], [0.2531297206878662, 0.7468702793121338], [0.9982566237449646, 0.001743412809446454], [0.003091926919296384, 0.9969081282615662], [0.020872334018349648, 0.9791277050971985], [0.9363684058189392, 0.06363154947757721], [0.9988986253738403, 0.0011013224720954895], [0.0020409072749316692, 0.9979591369628906], [0.7872309684753418, 0.212769016623497], [0.9986422657966614, 0.001357720117084682], [0.002502496587112546, 0.9974974989891052], [0.2628989815711975, 0.7371009588241577], [0.0021028004121035337, 0.9978971481323242], [0.9990686774253845, 0.0009313120390288532], [0.003130352357402444, 0.9968696236610413], [0.9850515127182007, 0.014948482625186443], [0.002904346678406, 0.9970957040786743], [0.9974530339241028, 0.0025470100808888674], [0.0023623472079634666, 0.9976376295089722], [0.002347344998270273, 0.9976527094841003], [0.9802013039588928, 0.019798675552010536], [0.00511319562792778, 0.9948868155479431], [0.0017958396347239614, 0.9982041120529175], [0.002350057940930128, 0.9976499676704407], [0.0020452830940485, 0.9979547262191772], [0.8781051635742188, 0.12189480662345886], [0.028622018173336983, 0.9713780283927917], [0.0021033738739788532, 0.9978965520858765], [0.9986377358436584, 0.0013622778933495283], [0.0029639361891895533, 0.9970360994338989], [0.002656781580299139, 0.9973432421684265], [0.003940196707844734, 0.996059775352478], [0.9991926550865173, 0.0008073174394667149], [0.0033504744060337543, 0.9966495633125305], [0.0020502498373389244, 0.9979497790336609], [0.003498865058645606, 0.996501088142395], [0.9991776347160339, 0.0008222899050451815], [0.0023935483768582344, 0.9976063966751099], [0.9992300271987915, 0.0007699541747570038], [0.9990200996398926, 0.0009799303952604532], [0.002927646040916443, 0.9970723390579224], [0.0021756740752607584, 0.9978243112564087], [0.9991773962974548, 0.0008225277997553349], [0.004910391755402088, 0.995089590549469], [0.9967922568321228, 0.0032077389769256115], [0.49769389629364014, 0.5023061037063599], [0.046757686883211136, 0.9532423615455627], [0.002057225676253438, 0.9979427456855774], [0.0046487972140312195, 0.9953511953353882], [0.0024208237882703543, 0.9975791573524475], [0.0023934675846248865, 0.9976065158843994], [0.9989402890205383, 0.001059756730683148], [0.002503747586160898, 0.9974961876869202], [0.043412577360868454, 0.9565874338150024], [0.9989281296730042, 0.001071857986971736], [0.9984633922576904, 0.0015365880681201816], [0.002078040735796094, 0.9979220032691956], [0.002639731392264366, 0.9973602890968323], [0.002275231759995222, 0.997724711894989], [0.9990596175193787, 0.0009404008160345256], [0.8061757683753967, 0.19382426142692566], [0.002287250244989991, 0.9977127313613892], [0.9990525841712952, 0.0009474534308537841], [0.9987807869911194, 0.0012192496797069907], [0.9989805817604065, 0.0010194260394200683], [0.9990241527557373, 0.0009758067899383605], [0.9991463422775269, 0.0008536893874406815], [0.038784172385931015, 0.9612157940864563], [0.002892114454880357, 0.9971079230308533], [0.9990806579589844, 0.000919298327062279], [0.0037190187722444534, 0.9962809681892395], [0.004674225114285946, 0.9953258037567139], [0.0020431603770703077, 0.9979568719863892], [0.023699695244431496, 0.9763002395629883], [0.9990596175193787, 0.0009403909207321703], [0.9870102405548096, 0.012989714741706848], [0.0025912171695381403, 0.9974088072776794], [0.9531720280647278, 0.04682791605591774], [0.0024045396130532026, 0.997595489025116], [0.999076247215271, 0.0009237388730980456], [0.9989271759986877, 0.0010728294728323817], [0.0036951396614313126, 0.9963048696517944], [0.018098322674632072, 0.9819017052650452], [0.0025705453008413315, 0.9974294304847717], [0.9991008043289185, 0.000899182865396142], [0.5299737453460693, 0.4700262248516083], [0.003927989862859249, 0.9960720539093018], [0.015458277426660061, 0.9845417737960815], [0.0023405442479997873, 0.99765944480896], [0.0025431520771235228, 0.9974568486213684], [0.004761240445077419, 0.9952387809753418], [0.9991058707237244, 0.0008941478445194662], [0.9989866614341736, 0.0010133238974958658], [0.005660777911543846, 0.9943392872810364], [0.0020825795363634825, 0.9979174733161926], [0.8014575839042664, 0.19854243099689484], [0.9986631870269775, 0.0013368617510423064], [0.003977276384830475, 0.9960227012634277], [0.9986446499824524, 0.0013553791213780642], [0.9990217685699463, 0.0009781840490177274], [0.003545032348483801, 0.9964549541473389], [0.002190652769058943, 0.9978093504905701], [0.0033890570048242807, 0.9966109395027161], [0.9981040954589844, 0.0018958767177537084], [0.9990315437316895, 0.0009684251272119582], [0.0022322277072817087, 0.9977678060531616], [0.004673038609325886, 0.9953269958496094], [0.002303721848875284, 0.9976962208747864], [0.0020515979267656803, 0.9979484677314758], [0.0019257996464148164, 0.9980741739273071], [0.9989814162254333, 0.00101850728970021], [0.002873861463740468, 0.9971261620521545], [0.0020524715073406696, 0.9979475140571594], [0.9990088939666748, 0.00099108275026083], [0.002190629718825221, 0.9978093504905701], [0.9991163611412048, 0.0008836620254442096], [0.550006091594696, 0.44999387860298157], [0.006192588247358799, 0.9938073754310608], [0.9989863038063049, 0.0010136603377759457], [0.9992057681083679, 0.0007942371885292232], [0.0019029078539460897, 0.9980971217155457], [0.0028599766083061695, 0.9971400499343872], [0.01492270827293396, 0.9850773215293884], [0.9959172606468201, 0.004082732368260622], [0.002757048001512885, 0.9972429275512695], [0.0036803530529141426, 0.9963196516036987], [0.998920202255249, 0.0010798274306580424], [0.0018099491717293859, 0.9981901049613953], [0.002594809513539076, 0.9974052309989929], [0.002082899445667863, 0.997917115688324], [0.9992035031318665, 0.000796481326688081], [0.0024406721349805593, 0.9975593090057373], [0.9990803003311157, 0.0009197092731483281], [0.9989935755729675, 0.0010064542293548584], [0.9981368780136108, 0.001863145618699491], [0.0029832615982741117, 0.9970167875289917], [0.9980387091636658, 0.001961339730769396], [0.003484344808384776, 0.9965156316757202], [0.9912229776382446, 0.008777067996561527], [0.014142093248665333, 0.9858579635620117], [0.0018203079234808683, 0.9981796741485596], [0.002426987746730447, 0.9975729584693909], [0.9990598559379578, 0.0009401284041814506], [0.998634397983551, 0.0013655994553118944], [0.00272823846898973, 0.997271716594696], [0.002710815751925111, 0.9972891807556152], [0.003460419364273548, 0.9965395927429199], [0.0038490600418299437, 0.9961509704589844], [0.002415470778942108, 0.9975845813751221], [0.9991267323493958, 0.0008733327267691493], [0.0026605622842907906, 0.9973394274711609], [0.9610244035720825, 0.03897557035088539], [0.0019948710687458515, 0.9980050921440125], [0.0021673524752259254, 0.9978325963020325], [0.007534589618444443, 0.9924653768539429], [0.0025699781253933907, 0.9974300265312195], [0.002291387878358364, 0.9977085590362549], [0.9981316924095154, 0.0018682824447751045], [0.0030596647411584854, 0.9969403743743896], [0.005362022202461958, 0.9946380257606506], [0.0023414266761392355, 0.9976586103439331], [0.010253608226776123, 0.9897463321685791], [0.002936130855232477, 0.9970638155937195], [0.9646403789520264, 0.035359643399715424], [0.0017998266266658902, 0.9982001781463623], [0.002520723966881633, 0.997479259967804], [0.9984293580055237, 0.0015706336125731468], [0.0039629386737942696, 0.9960370659828186], [0.9990173578262329, 0.0009825722081586719], [0.00314905378036201, 0.9968509078025818], [0.9989117383956909, 0.0010882401838898659], [0.9853444695472717, 0.01465558260679245], [0.9991908669471741, 0.0008091265335679054], [0.0028702877461910248, 0.9971297383308411], [0.004419377073645592, 0.9955806136131287], [0.9976990818977356, 0.0023009597789496183], [0.9991530179977417, 0.0008470236789435148], [0.0023455279879271984, 0.9976544976234436], [0.9988253712654114, 0.0011746136005967855], [0.9991175532341003, 0.0008825008408166468], [0.0021325142588466406, 0.9978674650192261], [0.003593872534111142, 0.9964061379432678], [0.00285733281634748, 0.9971426129341125], [0.003185799578204751, 0.9968141913414001], [0.9981212019920349, 0.001878758892416954], [0.0026846574619412422, 0.9973153471946716], [0.0021897824481129646, 0.9978101849555969], [0.9937198162078857, 0.006280166562646627], [0.998995840549469, 0.001004114979878068], [0.999152421951294, 0.000847591261845082], [0.001982006710022688, 0.9980180263519287], [0.010279502719640732, 0.9897205233573914], [0.00257480819709599, 0.9974251985549927]]\n"]}]},{"cell_type":"code","source":["def num_to_hate(label):\n","    label_dict = {0: \"none\", 1: \"hate\"}\n","    str_label = []\n","\n","    for i, v in enumerate(label):\n","        str_label.append([i,label_dict[v]])\n","    \n","    return str_label\n","\n","answer = num_to_hate(pred_answer)\n","print(answer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iYsIvdnUvVze","executionInfo":{"status":"ok","timestamp":1645622497122,"user_tz":-540,"elapsed":402,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"cee0e665-627d-4b2d-b355-b709d962a1ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0, 'none'], [1, 'none'], [2, 'hate'], [3, 'hate'], [4, 'hate'], [5, 'hate'], [6, 'hate'], [7, 'hate'], [8, 'hate'], [9, 'none'], [10, 'none'], [11, 'hate'], [12, 'none'], [13, 'hate'], [14, 'none'], [15, 'hate'], [16, 'hate'], [17, 'hate'], [18, 'hate'], [19, 'none'], [20, 'hate'], [21, 'none'], [22, 'hate'], [23, 'hate'], [24, 'hate'], [25, 'none'], [26, 'hate'], [27, 'none'], [28, 'none'], [29, 'none'], [30, 'hate'], [31, 'hate'], [32, 'hate'], [33, 'none'], [34, 'none'], [35, 'hate'], [36, 'hate'], [37, 'hate'], [38, 'none'], [39, 'none'], [40, 'hate'], [41, 'hate'], [42, 'hate'], [43, 'hate'], [44, 'none'], [45, 'none'], [46, 'hate'], [47, 'hate'], [48, 'none'], [49, 'hate'], [50, 'hate'], [51, 'none'], [52, 'hate'], [53, 'hate'], [54, 'none'], [55, 'hate'], [56, 'hate'], [57, 'none'], [58, 'none'], [59, 'hate'], [60, 'hate'], [61, 'hate'], [62, 'none'], [63, 'hate'], [64, 'hate'], [65, 'hate'], [66, 'hate'], [67, 'hate'], [68, 'none'], [69, 'hate'], [70, 'none'], [71, 'hate'], [72, 'hate'], [73, 'hate'], [74, 'hate'], [75, 'none'], [76, 'hate'], [77, 'hate'], [78, 'hate'], [79, 'hate'], [80, 'hate'], [81, 'hate'], [82, 'none'], [83, 'none'], [84, 'hate'], [85, 'none'], [86, 'hate'], [87, 'hate'], [88, 'hate'], [89, 'none'], [90, 'none'], [91, 'hate'], [92, 'hate'], [93, 'hate'], [94, 'none'], [95, 'hate'], [96, 'hate'], [97, 'hate'], [98, 'hate'], [99, 'hate'], [100, 'none'], [101, 'hate'], [102, 'none'], [103, 'none'], [104, 'hate'], [105, 'none'], [106, 'hate'], [107, 'hate'], [108, 'none'], [109, 'none'], [110, 'none'], [111, 'hate'], [112, 'hate'], [113, 'hate'], [114, 'none'], [115, 'hate'], [116, 'hate'], [117, 'none'], [118, 'hate'], [119, 'none'], [120, 'none'], [121, 'none'], [122, 'hate'], [123, 'hate'], [124, 'hate'], [125, 'hate'], [126, 'hate'], [127, 'hate'], [128, 'none'], [129, 'hate'], [130, 'hate'], [131, 'hate'], [132, 'none'], [133, 'hate'], [134, 'hate'], [135, 'hate'], [136, 'hate'], [137, 'none'], [138, 'none'], [139, 'hate'], [140, 'none'], [141, 'hate'], [142, 'hate'], [143, 'none'], [144, 'none'], [145, 'none'], [146, 'none'], [147, 'none'], [148, 'none'], [149, 'hate'], [150, 'hate'], [151, 'none'], [152, 'none'], [153, 'hate'], [154, 'hate'], [155, 'none'], [156, 'hate'], [157, 'hate'], [158, 'hate'], [159, 'none'], [160, 'none'], [161, 'hate'], [162, 'none'], [163, 'hate'], [164, 'hate'], [165, 'hate'], [166, 'none'], [167, 'hate'], [168, 'hate'], [169, 'none'], [170, 'hate'], [171, 'hate'], [172, 'none'], [173, 'none'], [174, 'hate'], [175, 'hate'], [176, 'hate'], [177, 'none'], [178, 'hate'], [179, 'none'], [180, 'none'], [181, 'none'], [182, 'hate'], [183, 'none'], [184, 'hate'], [185, 'hate'], [186, 'none'], [187, 'hate'], [188, 'hate'], [189, 'hate'], [190, 'none'], [191, 'hate'], [192, 'hate'], [193, 'hate'], [194, 'none'], [195, 'none'], [196, 'hate'], [197, 'hate'], [198, 'hate'], [199, 'none'], [200, 'hate'], [201, 'hate'], [202, 'hate'], [203, 'hate'], [204, 'hate'], [205, 'hate'], [206, 'none'], [207, 'hate'], [208, 'hate'], [209, 'hate'], [210, 'none'], [211, 'hate'], [212, 'none'], [213, 'none'], [214, 'none'], [215, 'hate'], [216, 'hate'], [217, 'none'], [218, 'hate'], [219, 'hate'], [220, 'hate'], [221, 'hate'], [222, 'none'], [223, 'hate'], [224, 'hate'], [225, 'none'], [226, 'hate'], [227, 'none'], [228, 'hate'], [229, 'hate'], [230, 'hate'], [231, 'none'], [232, 'hate'], [233, 'hate'], [234, 'hate'], [235, 'hate'], [236, 'none'], [237, 'none'], [238, 'none'], [239, 'hate'], [240, 'hate'], [241, 'hate'], [242, 'hate'], [243, 'none'], [244, 'none'], [245, 'hate'], [246, 'hate'], [247, 'hate'], [248, 'none'], [249, 'hate'], [250, 'none'], [251, 'none'], [252, 'hate'], [253, 'hate'], [254, 'hate'], [255, 'none'], [256, 'none'], [257, 'none'], [258, 'hate'], [259, 'hate'], [260, 'hate'], [261, 'hate'], [262, 'hate'], [263, 'none'], [264, 'none'], [265, 'none'], [266, 'hate'], [267, 'hate'], [268, 'hate'], [269, 'none'], [270, 'hate'], [271, 'hate'], [272, 'none'], [273, 'none'], [274, 'hate'], [275, 'none'], [276, 'hate'], [277, 'hate'], [278, 'hate'], [279, 'none'], [280, 'none'], [281, 'hate'], [282, 'hate'], [283, 'none'], [284, 'none'], [285, 'none'], [286, 'hate'], [287, 'hate'], [288, 'none'], [289, 'hate'], [290, 'none'], [291, 'hate'], [292, 'hate'], [293, 'none'], [294, 'hate'], [295, 'none'], [296, 'hate'], [297, 'hate'], [298, 'none'], [299, 'none'], [300, 'hate'], [301, 'none'], [302, 'none'], [303, 'hate'], [304, 'hate'], [305, 'none'], [306, 'none'], [307, 'hate'], [308, 'none'], [309, 'hate'], [310, 'none'], [311, 'hate'], [312, 'hate'], [313, 'hate'], [314, 'hate'], [315, 'hate'], [316, 'none'], [317, 'hate'], [318, 'hate'], [319, 'hate'], [320, 'none'], [321, 'hate'], [322, 'hate'], [323, 'none'], [324, 'none'], [325, 'hate'], [326, 'none'], [327, 'none'], [328, 'hate'], [329, 'hate'], [330, 'hate'], [331, 'none'], [332, 'hate'], [333, 'none'], [334, 'hate'], [335, 'none'], [336, 'hate'], [337, 'hate'], [338, 'none'], [339, 'hate'], [340, 'hate'], [341, 'hate'], [342, 'hate'], [343, 'none'], [344, 'hate'], [345, 'hate'], [346, 'none'], [347, 'hate'], [348, 'hate'], [349, 'hate'], [350, 'none'], [351, 'hate'], [352, 'hate'], [353, 'hate'], [354, 'none'], [355, 'hate'], [356, 'none'], [357, 'none'], [358, 'hate'], [359, 'hate'], [360, 'none'], [361, 'hate'], [362, 'none'], [363, 'hate'], [364, 'hate'], [365, 'hate'], [366, 'hate'], [367, 'hate'], [368, 'hate'], [369, 'none'], [370, 'hate'], [371, 'hate'], [372, 'none'], [373, 'none'], [374, 'hate'], [375, 'hate'], [376, 'hate'], [377, 'none'], [378, 'none'], [379, 'hate'], [380, 'none'], [381, 'none'], [382, 'none'], [383, 'none'], [384, 'none'], [385, 'hate'], [386, 'hate'], [387, 'none'], [388, 'hate'], [389, 'hate'], [390, 'hate'], [391, 'hate'], [392, 'none'], [393, 'none'], [394, 'hate'], [395, 'none'], [396, 'hate'], [397, 'none'], [398, 'none'], [399, 'hate'], [400, 'hate'], [401, 'hate'], [402, 'none'], [403, 'none'], [404, 'hate'], [405, 'hate'], [406, 'hate'], [407, 'hate'], [408, 'hate'], [409, 'none'], [410, 'none'], [411, 'hate'], [412, 'hate'], [413, 'none'], [414, 'none'], [415, 'hate'], [416, 'none'], [417, 'none'], [418, 'hate'], [419, 'hate'], [420, 'hate'], [421, 'none'], [422, 'none'], [423, 'hate'], [424, 'hate'], [425, 'hate'], [426, 'hate'], [427, 'hate'], [428, 'none'], [429, 'hate'], [430, 'hate'], [431, 'none'], [432, 'hate'], [433, 'none'], [434, 'none'], [435, 'hate'], [436, 'none'], [437, 'none'], [438, 'hate'], [439, 'hate'], [440, 'hate'], [441, 'none'], [442, 'hate'], [443, 'hate'], [444, 'none'], [445, 'hate'], [446, 'hate'], [447, 'hate'], [448, 'none'], [449, 'hate'], [450, 'none'], [451, 'none'], [452, 'none'], [453, 'hate'], [454, 'none'], [455, 'hate'], [456, 'none'], [457, 'hate'], [458, 'hate'], [459, 'hate'], [460, 'none'], [461, 'none'], [462, 'hate'], [463, 'hate'], [464, 'hate'], [465, 'hate'], [466, 'hate'], [467, 'none'], [468, 'hate'], [469, 'none'], [470, 'hate'], [471, 'hate'], [472, 'hate'], [473, 'hate'], [474, 'hate'], [475, 'none'], [476, 'hate'], [477, 'hate'], [478, 'hate'], [479, 'hate'], [480, 'hate'], [481, 'none'], [482, 'hate'], [483, 'hate'], [484, 'none'], [485, 'hate'], [486, 'none'], [487, 'hate'], [488, 'none'], [489, 'none'], [490, 'none'], [491, 'hate'], [492, 'hate'], [493, 'none'], [494, 'none'], [495, 'hate'], [496, 'none'], [497, 'none'], [498, 'hate'], [499, 'hate'], [500, 'hate'], [501, 'hate'], [502, 'none'], [503, 'hate'], [504, 'hate'], [505, 'none'], [506, 'none'], [507, 'none'], [508, 'hate'], [509, 'hate'], [510, 'hate']]\n"]}]},{"cell_type":"code","source":["df_hate = pd.DataFrame(answer, columns=['ID', 'hate'])\n","df_hate.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"actbhBCbt8vG","executionInfo":{"status":"ok","timestamp":1645622500521,"user_tz":-540,"elapsed":471,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"a8eecb16-e025-48a6-e918-532b651e477b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-15d131cb-95dc-4635-8777-ca457252393c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15d131cb-95dc-4635-8777-ca457252393c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-15d131cb-95dc-4635-8777-ca457252393c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-15d131cb-95dc-4635-8777-ca457252393c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID  hate\n","508  508  hate\n","509  509  hate\n","510  510  hate"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/mybaseline_submit01.csv') # 아까 저장한 bias csv 파일 load\n","df.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"rfmH140OvK51","executionInfo":{"status":"ok","timestamp":1645622610961,"user_tz":-540,"elapsed":574,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"6117175e-4908-47af-9481-48f530d6ae68"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-5513374f-e0f3-4c09-b641-51e48143ded5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>bias</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>others</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>none</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>none</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5513374f-e0f3-4c09-b641-51e48143ded5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5513374f-e0f3-4c09-b641-51e48143ded5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5513374f-e0f3-4c09-b641-51e48143ded5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID    bias\n","508  508  others\n","509  509    none\n","510  510    none"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["df['hate'] = df_hate['hate']  # df 에 hate column 을 만들어서 hate 값 추가\n","df.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"jNJIbhMfvuVV","executionInfo":{"status":"ok","timestamp":1645622682959,"user_tz":-540,"elapsed":581,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"5cbb02d7-a409-46a0-eb51-ebf2da30b26e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-041ed7f5-9e78-446b-a43a-5078d0f8bb29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>bias</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>others</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>509</th>\n","      <td>509</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","    <tr>\n","      <th>510</th>\n","      <td>510</td>\n","      <td>none</td>\n","      <td>hate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-041ed7f5-9e78-446b-a43a-5078d0f8bb29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-041ed7f5-9e78-446b-a43a-5078d0f8bb29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-041ed7f5-9e78-446b-a43a-5078d0f8bb29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      ID    bias  hate\n","508  508  others  hate\n","509  509    none  hate\n","510  510    none  hate"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["# bias, hate 값이 들어간 최종 csv 파일 \n","df.to_csv('/content/drive/MyDrive/AIConnect/NLP_classificaiton/mybaseline_submit01.csv', index=False) # 매번 파일 이름 바꿔주자\n","\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9od45aJwV-U","executionInfo":{"status":"ok","timestamp":1645622766652,"user_tz":-540,"elapsed":451,"user":{"displayName":"김태정","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13554148649959058019"}},"outputId":"8986fab7-9292-427d-c40f-5c24bb828cfb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      ID    bias  hate\n","0      0    none  none\n","1      1    none  none\n","2      2    none  hate\n","3      3    none  hate\n","4      4  others  hate\n","..   ...     ...   ...\n","506  506    none  none\n","507  507    none  none\n","508  508  others  hate\n","509  509    none  hate\n","510  510    none  hate\n","\n","[511 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["# 이제 제출하러 ㄱㄱ "],"metadata":{"id":"uMdnneJHwqbv"},"execution_count":null,"outputs":[]}]}